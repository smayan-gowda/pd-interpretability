{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wav2vec2 training for pd classification\n",
    "\n",
    "fine-tune wav2vec2-base on parkinson's disease voice detection.\n",
    "this notebook requires gpu runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. setup and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "print(f\"running in colab: {in_colab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    project_path = '/content/drive/MyDrive/pd-interpretability'\n",
    "    \n",
    "    !pip install -q -r {project_path}/requirements-colab.txt\n",
    "else:\n",
    "    project_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(project_path)\n",
    "sys.path.insert(0, project_path)\n",
    "\n",
    "print(f\"working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data import ItalianPVSDataset, MDVRKCLDataset\n",
    "from src.models import (\n",
    "    Wav2Vec2PDClassifier,\n",
    "    PDClassifierTrainer,\n",
    "    DataCollatorWithPadding,\n",
    "    create_training_args,\n",
    "    evaluate_model_on_dataset\n",
    ")\n",
    "\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"cuda device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. configure experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'facebook/wav2vec2-base-960h',\n",
    "    'dataset': 'italian_pvs',\n",
    "    'task': 'vowel_a',\n",
    "    'max_duration': 10.0,\n",
    "    'target_sr': 16000,\n",
    "    \n",
    "    'freeze_feature_extractor': True,\n",
    "    'freeze_encoder_layers': None,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    'num_epochs': 20,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 1e-4,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    \n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "experiment_name = f\"wav2vec2_{config['dataset']}_{config['task']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "output_dir = Path('results/checkpoints') / experiment_name\n",
    "\n",
    "print(f\"experiment: {experiment_name}\")\n",
    "print(f\"output dir: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('data/raw')\n",
    "\n",
    "if config['dataset'] == 'italian_pvs':\n",
    "    dataset = ItalianPVSDataset(\n",
    "        root_dir=data_root / 'italian_pvs',\n",
    "        task=config['task'],\n",
    "        target_sr=config['target_sr'],\n",
    "        max_duration=config['max_duration'],\n",
    "        normalize_audio=True\n",
    "    )\n",
    "elif config['dataset'] == 'mdvr_kcl':\n",
    "    dataset = MDVRKCLDataset(\n",
    "        root_dir=data_root / 'mdvr_kcl',\n",
    "        target_sr=config['target_sr'],\n",
    "        max_duration=config['max_duration'],\n",
    "        normalize_audio=True\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"unknown dataset: {config['dataset']}\")\n",
    "\n",
    "print(f\"total samples: {len(dataset)}\")\n",
    "print(f\"subjects: {dataset.get_subject_count()}\")\n",
    "print(f\"label distribution: {dataset.get_label_distribution()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset.get_subject_split(\n",
    "    test_size=config['test_size'],\n",
    "    val_size=config['val_size'],\n",
    "    random_state=config['random_seed'],\n",
    "    stratify=True\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_dataset)} samples\")\n",
    "print(f\"val: {len(val_dataset)} samples\")\n",
    "print(f\"test: {len(test_dataset)} samples\")\n",
    "\n",
    "train_labels = [dataset[i]['label'] for i in train_dataset.indices]\n",
    "print(f\"\\ntrain pd ratio: {sum(train_labels)/len(train_labels):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2PDClassifier(\n",
    "    model_name=config['model_name'],\n",
    "    num_labels=2,\n",
    "    freeze_feature_extractor=config['freeze_feature_extractor'],\n",
    "    freeze_encoder_layers=config['freeze_encoder_layers'],\n",
    "    dropout=config['dropout'],\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "param_counts = model.count_parameters()\n",
    "print(f\"total parameters: {param_counts['total']:,}\")\n",
    "print(f\"trainable parameters: {param_counts['trainable']:,}\")\n",
    "print(f\"frozen parameters: {param_counts['frozen']:,}\")\n",
    "print(f\"trainable: {param_counts['trainable_percent']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = create_training_args(\n",
    "    output_dir=output_dir,\n",
    "    num_epochs=config['num_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    warmup_ratio=config['warmup_ratio'],\n",
    "    gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    seed=config['random_seed']\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    feature_extractor=model.feature_extractor\n",
    ")\n",
    "\n",
    "trainer = PDClassifierTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    training_args=training_args,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(\"trainer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_path = output_dir / 'config.json'\n",
    "config_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"starting training...\")\n",
    "train_metrics = trainer.train()\n",
    "\n",
    "print(\"\\ntraining complete!\")\n",
    "print(f\"train loss: {train_metrics['train_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = trainer.evaluate(val_dataset)\n",
    "\n",
    "print(\"validation metrics:\")\n",
    "for key, value in val_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluate_model_on_dataset(\n",
    "    model,\n",
    "    test_dataset,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(\"test metrics:\")\n",
    "for key, value in test_metrics.items():\n",
    "    if isinstance(value, (float, int)):\n",
    "        print(f\"  {key}: {value:.4f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = {\n",
    "    'config': config,\n",
    "    'train_metrics': train_metrics,\n",
    "    'val_metrics': val_metrics,\n",
    "    'test_metrics': {k: v for k, v in test_metrics.items() if k != 'confusion_matrix'}\n",
    "}\n",
    "\n",
    "results_path = output_dir / 'results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cm = np.array(test_metrics['confusion_matrix'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_xlabel('predicted')\n",
    "ax1.set_ylabel('actual')\n",
    "ax1.set_title('confusion matrix (test set)')\n",
    "ax1.set_xticklabels(['healthy', 'parkinson'])\n",
    "ax1.set_yticklabels(['healthy', 'parkinson'])\n",
    "\n",
    "metrics_names = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "metrics_values = [test_metrics[m] for m in metrics_names]\n",
    "\n",
    "ax2.barh(metrics_names, metrics_values)\n",
    "ax2.set_xlabel('score')\n",
    "ax2.set_title('test set metrics')\n",
    "ax2.set_xlim(0, 1)\n",
    "\n",
    "for i, v in enumerate(metrics_values):\n",
    "    ax2.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'evaluation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = output_dir / 'final_model'\n",
    "model.save(final_model_path)\n",
    "\n",
    "print(f\"model saved to {final_model_path}\")\n",
    "print(f\"\\nto load this model later:\")\n",
    "print(f\"  from src.models import Wav2Vec2PDClassifier\")\n",
    "print(f\"  model = Wav2Vec2PDClassifier.load('{final_model_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. training complete\n",
    "\n",
    "next steps:\n",
    "- extract activations from all layers for interpretability analysis\n",
    "- run probing experiments to identify clinical feature encoding  \n",
    "- perform activation patching to find causal circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training complete!\")\n",
    "print(f\"\\ntest accuracy: {test_metrics['accuracy']:.1%}\")\n",
    "print(f\"test f1: {test_metrics['f1']:.3f}\")\n",
    "print(f\"test auc: {test_metrics['auc']:.3f}\")\n",
    "print(f\"\\nmodel checkpoint: {final_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
