{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a02e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive and setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/pd-interpretability'\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "!pip install -q -r requirements-colab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd400b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.datasets import ItalianPVSDataset, MDVRKCLDataset\n",
    "from src.models.classifier import Wav2Vec2PDClassifier\n",
    "from src.interpretability.extraction import (\n",
    "    Wav2Vec2ActivationExtractor,\n",
    "    extract_activations_from_dataset,\n",
    "    load_activations_memmap,\n",
    "    AttentionExtractor\n",
    ")\n",
    "\n",
    "print(f'pytorch: {torch.__version__}')\n",
    "print(f'cuda: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf246bf0",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed25763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'model_checkpoint': 'results/checkpoints/wav2vec2_pd_italian_v1/final_model',\n",
    "    'dataset': 'italian_pvs',\n",
    "    'max_duration': 10.0,\n",
    "    'target_sr': 16000,\n",
    "    'pooling': 'mean',\n",
    "    'batch_size': 8,\n",
    "    'extract_attention': True\n",
    "}\n",
    "\n",
    "# find latest checkpoint if default doesn't exist\n",
    "checkpoint_path = Path(PROJECT_ROOT) / config['model_checkpoint']\n",
    "if not checkpoint_path.exists():\n",
    "    checkpoints_dir = Path(PROJECT_ROOT) / 'results' / 'checkpoints'\n",
    "    if checkpoints_dir.exists():\n",
    "        checkpoints = sorted(checkpoints_dir.glob('wav2vec2_pd_*'))\n",
    "        if checkpoints:\n",
    "            latest = checkpoints[-1]\n",
    "            checkpoint_path = latest / 'final_model'\n",
    "            if not checkpoint_path.exists():\n",
    "                checkpoint_path = latest\n",
    "            config['model_checkpoint'] = str(checkpoint_path.relative_to(PROJECT_ROOT))\n",
    "            print(f'using checkpoint: {checkpoint_path}')\n",
    "\n",
    "# output paths\n",
    "output_dir = Path(PROJECT_ROOT) / 'data' / 'activations'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "activations_path = output_dir / f\"activations_{config['dataset']}_{timestamp}.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c063f6",
   "metadata": {},
   "source": [
    "## load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine-tuned model\n",
    "model_path = Path(PROJECT_ROOT) / config['model_checkpoint']\n",
    "\n",
    "classifier = Wav2Vec2PDClassifier.load(\n",
    "    checkpoint_dir=model_path,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "print(f'model loaded from {model_path}')\n",
    "print(f'number of layers: {len(classifier.model.wav2vec2.encoder.layers)}')\n",
    "print(f'hidden size: {classifier.model.config.hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d02771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_root = Path(PROJECT_ROOT) / 'data' / 'raw'\n",
    "\n",
    "dataset = ItalianPVSDataset(\n",
    "    root_dir=str(data_root / 'italian_pvs'),\n",
    "    task=None,\n",
    "    max_duration=config['max_duration'],\n",
    "    target_sr=config['target_sr']\n",
    ")\n",
    "\n",
    "print(f'dataset loaded: {len(dataset)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7041475",
   "metadata": {},
   "source": [
    "## extract activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create extractor\n",
    "extractor = Wav2Vec2ActivationExtractor(\n",
    "    model=classifier.model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "print(f'extractor initialized')\n",
    "print(f'  layers: {extractor.num_layers}')\n",
    "print(f'  hidden size: {extractor.hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0442252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test extraction on single sample\n",
    "sample = dataset[0]\n",
    "test_activations = extractor.extract(\n",
    "    sample['input_values'],\n",
    "    pooling=config['pooling']\n",
    ")\n",
    "\n",
    "print('test extraction:')\n",
    "for name, act in test_activations.items():\n",
    "    if name.startswith('layer_'):\n",
    "        print(f'  {name}: shape {act.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2108ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract activations for all samples\n",
    "print(f'extracting activations for {len(dataset)} samples...')\n",
    "print(f'output path: {activations_path}')\n",
    "\n",
    "# prepare input values list\n",
    "input_values_list = []\n",
    "sample_metadata = []\n",
    "\n",
    "for i in tqdm(range(len(dataset)), desc='loading samples'):\n",
    "    sample = dataset[i]\n",
    "    input_values_list.append(sample['input_values'])\n",
    "    sample_metadata.append({\n",
    "        'idx': i,\n",
    "        'label': sample['label'],\n",
    "        'subject_id': sample['subject_id'],\n",
    "        'path': sample['path']\n",
    "    })\n",
    "\n",
    "print(f'loaded {len(input_values_list)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b358fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract to memmap\n",
    "activations_memmap = extractor.extract_to_memmap(\n",
    "    input_values_list=input_values_list,\n",
    "    output_path=str(activations_path),\n",
    "    pooling=config['pooling'],\n",
    "    batch_size=config['batch_size']\n",
    ")\n",
    "\n",
    "print(f'\\nactivations extracted')\n",
    "print(f'  shape: {activations_memmap.shape}')\n",
    "print(f'  size: {activations_memmap.nbytes / 1e6:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save enhanced metadata\n",
    "metadata_path = str(activations_path).replace('.dat', '_metadata.json')\n",
    "\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# add sample info\n",
    "metadata['samples'] = sample_metadata\n",
    "metadata['labels'] = [s['label'] for s in sample_metadata]\n",
    "metadata['subject_ids'] = [s['subject_id'] for s in sample_metadata]\n",
    "metadata['config'] = config\n",
    "metadata['timestamp'] = timestamp\n",
    "metadata['model_checkpoint'] = config['model_checkpoint']\n",
    "\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'metadata saved to {metadata_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772923d",
   "metadata": {},
   "source": [
    "## extract attention weights (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['extract_attention']:\n",
    "    print('extracting attention weights...')\n",
    "    \n",
    "    attention_extractor = AttentionExtractor(\n",
    "        model=classifier.model,\n",
    "        device='cuda'\n",
    "    )\n",
    "    \n",
    "    # extract for subset of samples (attention is memory intensive)\n",
    "    n_attention_samples = min(50, len(dataset))\n",
    "    attention_data = []\n",
    "    \n",
    "    for i in tqdm(range(n_attention_samples), desc='extracting attention'):\n",
    "        sample = dataset[i]\n",
    "        \n",
    "        try:\n",
    "            attentions = attention_extractor.extract_attention(\n",
    "                sample['input_values'],\n",
    "                layer_idx=None\n",
    "            )\n",
    "            \n",
    "            # store summary stats (full attention matrices are too large)\n",
    "            attention_summary = {\n",
    "                'idx': i,\n",
    "                'label': sample['label'],\n",
    "                'layer_entropy': [],\n",
    "                'layer_max_attention': []\n",
    "            }\n",
    "            \n",
    "            for layer_att in attentions:\n",
    "                # average over heads\n",
    "                avg_att = layer_att.mean(axis=0)\n",
    "                \n",
    "                # compute entropy (measure of attention spread)\n",
    "                att_probs = avg_att / (avg_att.sum(axis=-1, keepdims=True) + 1e-9)\n",
    "                entropy = -np.sum(att_probs * np.log(att_probs + 1e-9), axis=-1).mean()\n",
    "                \n",
    "                # max attention weight\n",
    "                max_att = avg_att.max()\n",
    "                \n",
    "                attention_summary['layer_entropy'].append(float(entropy))\n",
    "                attention_summary['layer_max_attention'].append(float(max_att))\n",
    "            \n",
    "            attention_data.append(attention_summary)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'failed on sample {i}: {e}')\n",
    "    \n",
    "    # save attention summaries\n",
    "    attention_path = output_dir / f\"attention_summary_{config['dataset']}_{timestamp}.json\"\n",
    "    with open(attention_path, 'w') as f:\n",
    "        json.dump(attention_data, f, indent=2)\n",
    "    \n",
    "    print(f'attention summaries saved to {attention_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3fd19",
   "metadata": {},
   "source": [
    "## verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify saved activations\n",
    "loaded_activations, loaded_metadata = load_activations_memmap(activations_path)\n",
    "\n",
    "print('verification:')\n",
    "print(f'  loaded shape: {loaded_activations.shape}')\n",
    "print(f'  n_samples: {loaded_metadata[\"n_samples\"]}')\n",
    "print(f'  n_layers: {loaded_metadata[\"n_layers\"]}')\n",
    "print(f'  hidden_size: {loaded_metadata[\"hidden_size\"]}')\n",
    "\n",
    "# check for nan/inf values\n",
    "n_nan = np.isnan(loaded_activations).sum()\n",
    "n_inf = np.isinf(loaded_activations).sum()\n",
    "print(f'  nan values: {n_nan}')\n",
    "print(f'  inf values: {n_inf}')\n",
    "\n",
    "if n_nan > 0 or n_inf > 0:\n",
    "    print('  warning: invalid values detected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic statistics\n",
    "print('activation statistics by layer:')\n",
    "print('-' * 50)\n",
    "\n",
    "for layer_idx in range(loaded_metadata['n_layers']):\n",
    "    layer_acts = loaded_activations[:, layer_idx, :]\n",
    "    \n",
    "    print(f'layer {layer_idx:2d}: '\n",
    "          f'mean={layer_acts.mean():.4f}, '\n",
    "          f'std={layer_acts.std():.4f}, '\n",
    "          f'min={layer_acts.min():.4f}, '\n",
    "          f'max={layer_acts.max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class separability (quick sanity check)\n",
    "labels = np.array(loaded_metadata['labels'])\n",
    "\n",
    "print('\\nclass separability (cosine similarity within vs between classes):')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for layer_idx in [0, 5, 11]:\n",
    "    layer_acts = loaded_activations[:, layer_idx, :]\n",
    "    \n",
    "    pd_acts = layer_acts[labels == 1]\n",
    "    hc_acts = layer_acts[labels == 0]\n",
    "    \n",
    "    # within-class similarity\n",
    "    pd_sim = cosine_similarity(pd_acts).mean()\n",
    "    hc_sim = cosine_similarity(hc_acts).mean()\n",
    "    \n",
    "    # between-class similarity\n",
    "    cross_sim = cosine_similarity(pd_acts, hc_acts).mean()\n",
    "    \n",
    "    print(f'layer {layer_idx:2d}: '\n",
    "          f'pd-pd={pd_sim:.3f}, '\n",
    "          f'hc-hc={hc_sim:.3f}, '\n",
    "          f'pd-hc={cross_sim:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9b677",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('EXTRACTION SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'model: {config[\"model_checkpoint\"]}')\n",
    "print(f'dataset: {config[\"dataset\"]} ({len(dataset)} samples)')\n",
    "print(f'pooling: {config[\"pooling\"]}')\n",
    "print()\n",
    "print(f'activations shape: {loaded_activations.shape}')\n",
    "print(f'activations size: {loaded_activations.nbytes / 1e6:.2f} MB')\n",
    "print()\n",
    "print('output files:')\n",
    "print(f'  {activations_path}')\n",
    "print(f'  {metadata_path}')\n",
    "if config['extract_attention']:\n",
    "    print(f'  {attention_path}')\n",
    "print('=' * 60)\n",
    "print()\n",
    "print('next steps:')\n",
    "print('1. download activations to local machine')\n",
    "print('2. run probing experiments (notebooks/local/03_probing_analysis.ipynb)')\n",
    "print('3. run patching experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc38027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('memory cleared')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
