{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/pd-interpretability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db82f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -q transformers datasets librosa scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa334f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# verify gpu\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0408b82",
   "metadata": {},
   "source": [
    "## 1. Load Fine-tuned Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da029d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "CONFIG = {\n",
    "    'model_path': '/content/drive/MyDrive/pd-interpretability/results/checkpoints/best_model',\n",
    "    'data_path': '/content/drive/MyDrive/pd-interpretability/data',\n",
    "    'output_path': '/content/drive/MyDrive/pd-interpretability/results/patching',\n",
    "    'n_pairs': 100,  # number of (HC, PD) pairs for patching\n",
    "    'batch_size': 8,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# create output directory\n",
    "output_path = Path(CONFIG['output_path'])\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import Wav2Vec2PDClassifier\n",
    "from src.data import ItalianPVSDataset\n",
    "\n",
    "# load fine-tuned model\n",
    "model_path = Path(CONFIG['model_path'])\n",
    "\n",
    "if model_path.exists():\n",
    "    classifier = Wav2Vec2PDClassifier.load(model_path)\n",
    "    print(f\"loaded model from {model_path}\")\n",
    "else:\n",
    "    # load base model for testing\n",
    "    print(\"fine-tuned model not found, loading base model\")\n",
    "    classifier = Wav2Vec2PDClassifier(num_labels=2)\n",
    "\n",
    "# load dataset\n",
    "dataset = ItalianPVSDataset(\n",
    "    root_dir=Path(CONFIG['data_path']) / 'raw' / 'italian_pvs',\n",
    "    max_duration=10.0\n",
    ")\n",
    "\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(f\"model layers: {len(classifier.model.wav2vec2.encoder.layers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c141eb",
   "metadata": {},
   "source": [
    "## 2. Create Minimal Pairs for Patching\n",
    "\n",
    "Match HC samples with acoustically similar PD samples using MFCC distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interpretability import create_mfcc_matched_pairs, create_minimal_pairs\n",
    "\n",
    "# create mfcc-matched pairs\n",
    "print(\"creating mfcc-matched minimal pairs...\")\n",
    "pairs = create_mfcc_matched_pairs(\n",
    "    dataset,\n",
    "    n_pairs=CONFIG['n_pairs'],\n",
    "    same_task=True\n",
    ")\n",
    "\n",
    "if len(pairs) < CONFIG['n_pairs'] // 2:\n",
    "    print(\"falling back to random matching\")\n",
    "    pairs = create_minimal_pairs(dataset, n_pairs=CONFIG['n_pairs'])\n",
    "\n",
    "print(f\"created {len(pairs)} minimal pairs\")\n",
    "\n",
    "# separate components\n",
    "clean_inputs = [p[0] for p in pairs]\n",
    "corrupted_inputs = [p[1] for p in pairs]\n",
    "labels = [p[2] for p in pairs]\n",
    "\n",
    "# show distance distribution if available\n",
    "if len(pairs[0]) > 3:\n",
    "    distances = [p[3] for p in pairs]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(distances, bins=30, edgecolor='black')\n",
    "    plt.xlabel('MFCC Distance')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of MFCC Distances in Minimal Pairs')\n",
    "    plt.savefig(output_path / 'mfcc_distances.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51247b0",
   "metadata": {},
   "source": [
    "## 3. Layer-Level Patching\n",
    "\n",
    "For each layer (1-12):\n",
    "- Run model on HC sample, cache layer activations\n",
    "- Run model on matched PD sample with patched HC activations\n",
    "- Measure: Does prediction shift toward HC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interpretability import ActivationPatcher\n",
    "\n",
    "# initialize patcher\n",
    "patcher = ActivationPatcher(classifier.model, device=device)\n",
    "\n",
    "print(f\"number of layers: {patcher.num_layers}\")\n",
    "print(f\"number of attention heads: {patcher.num_heads}\")\n",
    "print(f\"hidden size: {patcher.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98110c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run layer-level patching\n",
    "print(\"running layer-level patching...\")\n",
    "\n",
    "patching_results = patcher.run_batch_patching(\n",
    "    clean_inputs,\n",
    "    corrupted_inputs,\n",
    "    labels,\n",
    "    include_heads=False  # layer-level only first\n",
    ")\n",
    "\n",
    "layer_patching = patching_results['layer_patching']\n",
    "\n",
    "# display results\n",
    "print(\"\\nlayer-level patching results:\")\n",
    "print(\"-\" * 50)\n",
    "for layer_idx in range(patcher.num_layers):\n",
    "    stats = layer_patching[layer_idx]\n",
    "    print(f\"layer {layer_idx:2d}: mean recovery = {stats['mean_recovery']:.3f} ± {stats['std_recovery']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize layer-level patching results\n",
    "layers = list(range(patcher.num_layers))\n",
    "mean_recoveries = [layer_patching[l]['mean_recovery'] for l in layers]\n",
    "std_recoveries = [layer_patching[l]['std_recovery'] for l in layers]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars = ax.bar(layers, mean_recoveries, yerr=std_recoveries, capsize=3,\n",
    "              color='steelblue', edgecolor='black', alpha=0.8)\n",
    "\n",
    "# highlight important layers (recovery > 0.1)\n",
    "for i, (layer, recovery) in enumerate(zip(layers, mean_recoveries)):\n",
    "    if recovery > 0.1:\n",
    "        bars[i].set_color('darkred')\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.axhline(y=0.1, color='red', linestyle='--', linewidth=1, alpha=0.7, label='importance threshold')\n",
    "\n",
    "ax.set_xlabel('Layer', fontsize=12)\n",
    "ax.set_ylabel('Logit Difference Recovery', fontsize=12)\n",
    "ax.set_title('Layer-Level Activation Patching Results\\n(HC → PD)', fontsize=14)\n",
    "ax.set_xticks(layers)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'layer_patching_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# identify important layers\n",
    "important_layers = [l for l, r in zip(layers, mean_recoveries) if r > 0.1]\n",
    "print(f\"\\nimportant layers (recovery > 0.1): {important_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad563b",
   "metadata": {},
   "source": [
    "## 4. Attention Head-Level Patching\n",
    "\n",
    "For layers identified as important, patch each attention head individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d04791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run head-level patching on important layers\n",
    "print(f\"running head-level patching on layers: {important_layers}\")\n",
    "\n",
    "head_results = []\n",
    "\n",
    "for clean, corrupted, label in zip(clean_inputs[:50], corrupted_inputs[:50], labels[:50]):\n",
    "    try:\n",
    "        result = patcher.run_head_patching(\n",
    "            clean, corrupted, label,\n",
    "            target_layers=important_layers if important_layers else None\n",
    "        )\n",
    "        head_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"head patching failed: {e}\")\n",
    "\n",
    "print(f\"completed {len(head_results)} head patching experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b764bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interpretability import HeadImportanceRanking\n",
    "\n",
    "# create head importance ranking\n",
    "head_ranking = HeadImportanceRanking.from_patching_results(\n",
    "    head_results,\n",
    "    top_k=20,\n",
    "    threshold=0.05\n",
    ")\n",
    "\n",
    "print(\"\\ntop 20 important attention heads:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (layer, head, score) in enumerate(head_ranking.head_rankings[:20]):\n",
    "    print(f\"{i+1:2d}. Layer {layer:2d}, Head {head:2d}: recovery = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nidentified {len(head_ranking.important_heads)} important heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c91512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize head importance as heatmap\n",
    "n_layers = patcher.num_layers\n",
    "n_heads = patcher.num_heads\n",
    "\n",
    "head_matrix = np.zeros((n_layers, n_heads))\n",
    "\n",
    "for (layer, head), score in head_ranking.head_scores.items():\n",
    "    head_matrix[layer, head] = score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(head_matrix, cmap='RdBu_r', aspect='auto', vmin=-0.2, vmax=0.2)\n",
    "\n",
    "ax.set_xlabel('Attention Head', fontsize=12)\n",
    "ax.set_ylabel('Layer', fontsize=12)\n",
    "ax.set_title('Attention Head Patching Results\\n(Logit Difference Recovery)', fontsize=14)\n",
    "\n",
    "ax.set_xticks(range(n_heads))\n",
    "ax.set_yticks(range(n_layers))\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Recovery Score', fontsize=11)\n",
    "\n",
    "# mark important heads\n",
    "for layer, head in head_ranking.important_heads:\n",
    "    ax.add_patch(plt.Rectangle((head-0.5, layer-0.5), 1, 1, \n",
    "                               fill=False, edgecolor='black', linewidth=2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'head_patching_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55513f2e",
   "metadata": {},
   "source": [
    "## 5. Mean Ablation Validation\n",
    "\n",
    "Complement patching with ablation: replace target component activations with dataset mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean activations across dataset\n",
    "print(\"computing mean activations for ablation...\")\n",
    "mean_acts = patcher.compute_mean_activations(dataset, max_samples=200)\n",
    "print(f\"computed mean activations for {len(mean_acts)} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ablation validation\n",
    "print(\"\\nvalidating with mean ablation...\")\n",
    "\n",
    "ablation_results = patcher.validate_with_ablation(\n",
    "    dataset,\n",
    "    patching_results,\n",
    "    max_samples=100\n",
    ")\n",
    "\n",
    "print(\"\\nablation effects per layer:\")\n",
    "print(\"-\" * 50)\n",
    "for layer_idx, stats in ablation_results['ablation_effects'].items():\n",
    "    print(f\"layer {layer_idx:2d}: mean effect = {stats['mean_effect']:.4f} ± {stats['std_effect']:.4f}\")\n",
    "\n",
    "print(\"\\nconcordance analysis:\")\n",
    "print(f\"  spearman correlation: {ablation_results['concordance']['spearman_correlation']:.3f}\")\n",
    "print(f\"  p-value: {ablation_results['concordance']['p_value']:.4f}\")\n",
    "print(f\"  interpretation: {ablation_results['concordance']['interpretation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538878a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize patching vs ablation concordance\n",
    "patching_scores = [layer_patching[l]['mean_recovery'] for l in range(n_layers)]\n",
    "ablation_scores = [ablation_results['ablation_effects'].get(l, {}).get('mean_effect', 0) \n",
    "                   for l in range(n_layers)]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# comparison bar plot\n",
    "x = np.arange(n_layers)\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, patching_scores, width, label='Patching Recovery', color='steelblue')\n",
    "ax1.bar(x + width/2, ablation_scores, width, label='Ablation Effect', color='coral')\n",
    "\n",
    "ax1.set_xlabel('Layer')\n",
    "ax1.set_ylabel('Effect Size')\n",
    "ax1.set_title('Patching vs. Ablation Effects')\n",
    "ax1.set_xticks(x)\n",
    "ax1.legend()\n",
    "\n",
    "# scatter plot for correlation\n",
    "ax2.scatter(patching_scores, ablation_scores, s=100, c='darkgreen', alpha=0.7)\n",
    "\n",
    "for i, (p, a) in enumerate(zip(patching_scores, ablation_scores)):\n",
    "    ax2.annotate(f'L{i}', (p, a), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# add trend line\n",
    "z = np.polyfit(patching_scores, ablation_scores, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(min(patching_scores), max(patching_scores), 100)\n",
    "ax2.plot(x_line, p(x_line), 'r--', alpha=0.7, label='trend')\n",
    "\n",
    "ax2.set_xlabel('Patching Recovery')\n",
    "ax2.set_ylabel('Ablation Effect')\n",
    "ax2.set_title(f'Concordance (r = {ablation_results[\"concordance\"][\"spearman_correlation\"]:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'patching_ablation_concordance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbf634",
   "metadata": {},
   "source": [
    "## 6. Clinical Feature Path Patching\n",
    "\n",
    "Test if heads with high clinical feature probing accuracy are the same heads that causally affect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clinical features if available\n",
    "clinical_path = Path(CONFIG['data_path']) / 'clinical_features' / 'italian_pvs_features.json'\n",
    "\n",
    "if clinical_path.exists():\n",
    "    with open(clinical_path, 'r') as f:\n",
    "        clinical_data = json.load(f)\n",
    "    \n",
    "    clinical_features = {\n",
    "        name: np.array(values) for name, values in clinical_data['features'].items()\n",
    "    }\n",
    "    sample_ids = clinical_data['sample_ids']\n",
    "    \n",
    "    print(f\"loaded clinical features: {list(clinical_features.keys())}\")\n",
    "else:\n",
    "    print(\"clinical features not found, skipping stratified analysis\")\n",
    "    clinical_features = None\n",
    "    sample_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if clinical_features is not None:\n",
    "    from src.interpretability import ClinicalStratifiedPatcher\n",
    "    \n",
    "    stratified_patcher = ClinicalStratifiedPatcher(\n",
    "        patcher,\n",
    "        clinical_features,\n",
    "        sample_ids\n",
    "    )\n",
    "    \n",
    "    # test on jitter (a key PD biomarker)\n",
    "    if 'jitter' in clinical_features:\n",
    "        print(\"running stratified head patching for jitter...\")\n",
    "        \n",
    "        jitter_results = stratified_patcher.run_stratified_head_patching(\n",
    "            dataset,\n",
    "            feature_name='jitter',\n",
    "            target_heads=head_ranking.important_heads[:10],  # top 10 heads\n",
    "            n_pairs_per_stratum=15\n",
    "        )\n",
    "        \n",
    "        print(\"\\njitter-stratified patching results:\")\n",
    "        print(\"-\" * 50)\n",
    "        for stratum, data in jitter_results.items():\n",
    "            if stratum in ['low', 'medium', 'high']:\n",
    "                print(f\"\\n{stratum.upper()} jitter stratum:\")\n",
    "                for head, stats in data.get('head_effects', {}).items():\n",
    "                    print(f\"  {head}: recovery = {stats['mean_recovery']:.4f}\")\n",
    "        \n",
    "        # differential effects\n",
    "        print(\"\\ndifferential effects (high - low):\")\n",
    "        for head, diff in jitter_results.get('differential_effects', {}).items():\n",
    "            print(f\"  {head}: {diff:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d7710",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all results\n",
    "full_results = {\n",
    "    'config': CONFIG,\n",
    "    'layer_patching': patching_results['layer_patching'],\n",
    "    'head_patching': head_ranking.to_dict(),\n",
    "    'ablation_validation': ablation_results,\n",
    "    'important_layers': important_layers,\n",
    "    'important_heads': [{'layer': l, 'head': h} for l, h in head_ranking.important_heads]\n",
    "}\n",
    "\n",
    "if clinical_features is not None and 'jitter' in clinical_features:\n",
    "    full_results['clinical_stratified'] = {'jitter': jitter_results}\n",
    "\n",
    "# save to json\n",
    "results_path = output_path / 'patching_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(full_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACTIVATION PATCHING ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\ntotal minimal pairs tested: {len(pairs)}\")\n",
    "print(f\"\\nimportant layers (recovery > 0.1): {important_layers}\")\n",
    "print(f\"number of important attention heads: {len(head_ranking.important_heads)}\")\n",
    "\n",
    "print(f\"\\ntop 5 attention heads:\")\n",
    "for layer, head, score in head_ranking.head_rankings[:5]:\n",
    "    print(f\"  Layer {layer}, Head {head}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\npatching-ablation concordance: {ablation_results['concordance']['spearman_correlation']:.3f}\")\n",
    "print(f\"concordance interpretation: {ablation_results['concordance']['interpretation']}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
