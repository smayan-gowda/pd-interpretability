{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/pd-interpretability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -q transformers datasets librosa praat-parselmouth scipy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# project imports\n",
    "from src.interpretability.prediction_interface import (\n",
    "    InterpretablePredictionInterface,\n",
    "    InterpretablePrediction,\n",
    "    create_interpretable_interface\n",
    ")\n",
    "from src.features.clinical import ClinicalFeatureExtractor\n",
    "\n",
    "print(\"imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8660f1",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'project_path': '/content/drive/MyDrive/pd-interpretability',\n",
    "    'model_path': '/content/drive/MyDrive/pd-interpretability/results/checkpoints/best_model.pt',\n",
    "    'analysis_path': '/content/drive/MyDrive/pd-interpretability/results',\n",
    "    'data_path': '/content/drive/MyDrive/pd-interpretability/data',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"using device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf30ad",
   "metadata": {},
   "source": [
    "## 2. Load Model and Create Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b03109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wav2vec2 processor\n",
    "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base')\n",
    "\n",
    "# load fine-tuned model\n",
    "model_path = Path(CONFIG['model_path'])\n",
    "\n",
    "if model_path.exists():\n",
    "    model = torch.load(model_path, map_location=CONFIG['device'], weights_only=False)\n",
    "    print(f\"loaded fine-tuned model from {model_path}\")\n",
    "else:\n",
    "    # fallback to pretrained with random classifier\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "        'facebook/wav2vec2-base',\n",
    "        num_labels=2\n",
    "    )\n",
    "    print(\"using pretrained model (no fine-tuned checkpoint found)\")\n",
    "\n",
    "model = model.to(CONFIG['device'])\n",
    "model.eval()\n",
    "print(f\"model ready on {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac49d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clinical feature extractor\n",
    "clinical_extractor = ClinicalFeatureExtractor()\n",
    "print(\"clinical feature extractor ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load precomputed analysis results (if available)\n",
    "analysis_path = Path(CONFIG['analysis_path'])\n",
    "\n",
    "probing_results = None\n",
    "patching_results = None\n",
    "\n",
    "# try to load probing results\n",
    "probing_file = analysis_path / 'probing' / 'probing_results.json'\n",
    "if probing_file.exists():\n",
    "    with open(probing_file) as f:\n",
    "        probing_data = json.load(f)\n",
    "    # convert to expected format\n",
    "    probing_results = {\n",
    "        feat: {int(k): v.get('mean', v) if isinstance(v, dict) else v\n",
    "               for k, v in layers.items()}\n",
    "        for feat, layers in probing_data.items()\n",
    "        if isinstance(layers, dict)\n",
    "    }\n",
    "    print(f\"loaded probing results for {len(probing_results)} features\")\n",
    "\n",
    "# try to load patching results\n",
    "patching_file = analysis_path / 'patching' / 'head_importance.json'\n",
    "if patching_file.exists():\n",
    "    with open(patching_file) as f:\n",
    "        patching_data = json.load(f)\n",
    "    # convert to expected format (tuple keys)\n",
    "    patching_results = {\n",
    "        tuple(map(int, k.split(','))): v\n",
    "        for k, v in patching_data.items()\n",
    "    }\n",
    "    print(f\"loaded patching results for {len(patching_results)} heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the interpretable prediction interface\n",
    "interface = create_interpretable_interface(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    clinical_extractor=clinical_extractor,\n",
    "    probing_results=probing_results,\n",
    "    patching_results=patching_results,\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "print(\"\\n=== Interpretable Prediction Interface Created ===\")\n",
    "print(f\"Evidence layers: {interface._evidence_layers}\")\n",
    "print(f\"Key attention heads: {interface._key_heads[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6be523",
   "metadata": {},
   "source": [
    "## 3. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77603818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# load some test samples\n",
    "data_path = Path(CONFIG['data_path']) / 'raw' / 'italian_pvs'\n",
    "\n",
    "test_samples = []\n",
    "\n",
    "# load a few HC samples\n",
    "hc_dir = data_path / '22 elderly healthy control'\n",
    "if hc_dir.exists():\n",
    "    for subject_dir in list(hc_dir.iterdir())[:3]:\n",
    "        if subject_dir.is_dir():\n",
    "            audio_files = list(subject_dir.glob('*.txt'))\n",
    "            if audio_files:\n",
    "                # these are actually audio files with .txt extension\n",
    "                audio_path = audio_files[0]\n",
    "                try:\n",
    "                    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                    test_samples.append({\n",
    "                        'audio': audio,\n",
    "                        'sample_rate': sr,\n",
    "                        'label': 0,\n",
    "                        'subject_id': subject_dir.name\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# load a few PD samples\n",
    "pd_dir = data_path / '28 people with parkinson\\'s disease'\n",
    "if pd_dir.exists():\n",
    "    for subgroup in pd_dir.iterdir():\n",
    "        if subgroup.is_dir():\n",
    "            for subject_dir in list(subgroup.iterdir())[:1]:\n",
    "                if subject_dir.is_dir():\n",
    "                    audio_files = list(subject_dir.glob('*.*'))\n",
    "                    if audio_files:\n",
    "                        try:\n",
    "                            audio, sr = librosa.load(audio_files[0], sr=16000)\n",
    "                            test_samples.append({\n",
    "                                'audio': audio,\n",
    "                                'sample_rate': sr,\n",
    "                                'label': 1,\n",
    "                                'subject_id': subject_dir.name\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "print(f\"loaded {len(test_samples)} test samples\")\n",
    "\n",
    "# fallback to synthetic if no real data\n",
    "if len(test_samples) == 0:\n",
    "    print(\"using synthetic test samples\")\n",
    "    test_samples = [\n",
    "        {'audio': np.random.randn(48000).astype(np.float32), 'sample_rate': 16000, 'label': i % 2, 'subject_id': f'synth_{i}'}\n",
    "        for i in range(6)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e734bb2",
   "metadata": {},
   "source": [
    "## 4. Generate Interpretable Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions\n",
    "print(\"Generating interpretable predictions...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sample in test_samples:\n",
    "    # make prediction\n",
    "    prediction = interface.predict(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        include_clinical=True\n",
    "    )\n",
    "    \n",
    "    # display results\n",
    "    true_label = 'PD' if sample['label'] == 1 else 'HC'\n",
    "    pred_label = 'PD' if prediction.pd_probability >= 0.5 else 'HC'\n",
    "    correct = '✓' if (true_label == pred_label) else '✗'\n",
    "    \n",
    "    print(f\"\\nSubject: {sample['subject_id']}\")\n",
    "    print(f\"True label: {true_label}, Predicted: {pred_label} {correct}\")\n",
    "    print(f\"PD Probability: {prediction.pd_probability:.3f}\")\n",
    "    print(f\"Confidence: {prediction.confidence:.3f}\")\n",
    "    \n",
    "    print(\"\\nTop Feature Contributions:\")\n",
    "    for feat, score in prediction.get_top_features(3):\n",
    "        print(f\"  • {feat}: {score:+.3f}\")\n",
    "    \n",
    "    if prediction.clinical_features:\n",
    "        print(\"\\nKey Clinical Features:\")\n",
    "        for feat in ['jitter_local', 'shimmer_local', 'hnr_mean', 'f0_mean']:\n",
    "            if feat in prediction.clinical_features:\n",
    "                val = prediction.clinical_features[feat]\n",
    "                if not np.isnan(val):\n",
    "                    print(f\"  • {feat}: {val:.4f}\")\n",
    "    \n",
    "    print(f\"\\nEvidence Layers: {prediction.evidence_layers[:5]}\")\n",
    "    print(f\"Key Heads: {prediction.key_attention_heads[:3]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99a16c",
   "metadata": {},
   "source": [
    "## 5. Examine Full Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full JSON output for one sample\n",
    "if test_samples:\n",
    "    sample = test_samples[0]\n",
    "    prediction = interface.predict(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        include_clinical=True\n",
    "    )\n",
    "    \n",
    "    print(\"Full Prediction Output (JSON format):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(prediction.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84e327",
   "metadata": {},
   "source": [
    "## 6. Generate Natural Language Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate human-readable explanation\n",
    "if test_samples:\n",
    "    sample = test_samples[0]\n",
    "    \n",
    "    explanation = interface.explain_prediction(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        format='text'\n",
    "    )\n",
    "    \n",
    "    print(\"Natural Language Explanation:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown format explanation\n",
    "if test_samples:\n",
    "    explanation_md = interface.explain_prediction(\n",
    "        audio=test_samples[0]['audio'],\n",
    "        sample_rate=test_samples[0]['sample_rate'],\n",
    "        format='markdown'\n",
    "    )\n",
    "    \n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(explanation_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5040a4",
   "metadata": {},
   "source": [
    "## 7. Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2690028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch prediction\n",
    "audio_list = [s['audio'] for s in test_samples]\n",
    "\n",
    "predictions = interface.batch_predict(\n",
    "    audio_list=audio_list,\n",
    "    sample_rate=16000,\n",
    "    include_clinical=True,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(predictions)} predictions\")\n",
    "\n",
    "# summary statistics\n",
    "probs = [p.pd_probability for p in predictions]\n",
    "confs = [p.confidence for p in predictions]\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Mean PD probability: {np.mean(probs):.3f}\")\n",
    "print(f\"  Mean confidence: {np.mean(confs):.3f}\")\n",
    "print(f\"  Predicted as PD: {sum(1 for p in probs if p >= 0.5)}\")\n",
    "print(f\"  Predicted as HC: {sum(1 for p in probs if p < 0.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be04c6",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f29b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all predictions\n",
    "output_dir = Path(CONFIG['project_path']) / 'results' / 'phase5_synthesis'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save individual predictions\n",
    "for sample, prediction in zip(test_samples, predictions):\n",
    "    prediction.metadata['subject_id'] = sample['subject_id']\n",
    "    prediction.metadata['true_label'] = sample['label']\n",
    "    \n",
    "    interface.save_prediction(\n",
    "        prediction,\n",
    "        output_dir / f\"{sample['subject_id']}_prediction.json\"\n",
    "    )\n",
    "\n",
    "# save summary\n",
    "summary = {\n",
    "    'n_samples': len(predictions),\n",
    "    'mean_pd_probability': float(np.mean(probs)),\n",
    "    'mean_confidence': float(np.mean(confs)),\n",
    "    'n_predicted_pd': sum(1 for p in probs if p >= 0.5),\n",
    "    'n_predicted_hc': sum(1 for p in probs if p < 0.5)\n",
    "}\n",
    "\n",
    "with open(output_dir / 'prediction_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea92da",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **Interpretable Prediction Interface**, which:\n",
    "\n",
    "1. **Synthesizes** all mechanistic interpretability analyses into a single interface\n",
    "2. **Produces predictions** with probability, confidence, and explanations\n",
    "3. **Identifies** which clinical features (jitter, shimmer, HNR) drive predictions\n",
    "4. **Reveals** which transformer layers encode PD-relevant information\n",
    "5. **Highlights** key attention heads with causal importance\n",
    "\n",
    "### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"pd_probability\": 0.87,\n",
    "    \"feature_contributions\": {\n",
    "        \"jitter_elevated\": 0.34,\n",
    "        \"hnr_reduced\": 0.28,\n",
    "        \"f0_unstable\": 0.21\n",
    "    },\n",
    "    \"evidence_layers\": [3, 4, 7],\n",
    "    \"key_attention_heads\": [[3, 4], [4, 2], [7, 8]]\n",
    "}\n",
    "```\n",
    "\n",
    "This enables **transparent, explainable** PD detection from speech."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
