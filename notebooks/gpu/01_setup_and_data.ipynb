{"cells":[{"cell_type":"code","execution_count":2,"id":"c0b8a498","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0b8a498","executionInfo":{"status":"ok","timestamp":1767455979007,"user_tz":360,"elapsed":19876,"user":{"displayName":"Ishrith G","userId":"11841372263124350568"}},"outputId":"e68cd2ca-bcc2-4b7f-ba91-2a0035edb492"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"e75de55a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":9,"status":"error","timestamp":1767456038477,"user":{"displayName":"Ishrith G","userId":"11841372263124350568"},"user_tz":360},"id":"e75de55a","outputId":"30e1b4a6-19bb-47b9-cf97-823387223e7c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Volumes/usb drive/pd-interpretability'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2075519797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPROJECT_ROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Volumes/usb drive/pd-interpretability'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROJECT_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/usb drive/pd-interpretability'"]}],"source":["# set project path\n","import os\n","import sys\n","\n","PROJECT_ROOT = '/Volumes/usb drive/pd-interpretability'\n","os.chdir(PROJECT_ROOT)\n","sys.path.insert(0, PROJECT_ROOT)\n","\n","print(f'working directory: {os.getcwd()}')\n","print(f'project files: {os.listdir(\".\")}')"]},{"cell_type":"code","execution_count":null,"id":"5a7cfce7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10482,"status":"ok","timestamp":1767318012938,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"5a7cfce7","outputId":"3604d1dd-09de-4ec4-c1ca-272bb9478309"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: Cannot install -r requirements-colab.txt (line 1), -r requirements-colab.txt (line 12), -r requirements-colab.txt (line 2), -r requirements-colab.txt (line 7), numpy>=2.4.0 and scikit-learn==1.3.2 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# install requirements\n","!pip install -q -r requirements-colab.txt"]},{"cell_type":"code","execution_count":null,"id":"5aeebe76","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3584,"status":"ok","timestamp":1767318016526,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"5aeebe76","outputId":"0048fecb-d7fd-4a24-dffb-34e9a752dc7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["pytorch version: 2.9.0+cu126\n","cuda available: True\n","gpu device: Tesla T4\n","gpu memory: 15.83 GB\n"]}],"source":["# verify gpu availability\n","import torch\n","\n","print(f'pytorch version: {torch.__version__}')\n","print(f'cuda available: {torch.cuda.is_available()}')\n","\n","if torch.cuda.is_available():\n","    print(f'gpu device: {torch.cuda.get_device_name(0)}')\n","    print(f'gpu memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n","else:\n","    print('warning: no gpu detected. enable gpu runtime: Runtime -> Change runtime type -> GPU')"]},{"cell_type":"code","execution_count":null,"id":"42000066","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18889,"status":"ok","timestamp":1767318035416,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"42000066","outputId":"86bd7268-0eff-4c00-bfd5-b92e2a06c376"},"outputs":[{"name":"stdout","output_type":"stream","text":["all core packages imported successfully\n"]}],"source":["# verify imports\n","from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n","import torchaudio\n","import librosa\n","import parselmouth\n","\n","print('all core packages imported successfully')"]},{"cell_type":"code","execution_count":null,"id":"6508710a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2386,"status":"ok","timestamp":1767318037815,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"6508710a","outputId":"86877713-face-49f2-8297-57871943a277"},"outputs":[{"name":"stdout","output_type":"stream","text":["all project modules imported successfully\n"]}],"source":["# verify project module imports\n","from src.data.datasets import ItalianPVSDataset, MDVRKCLDataset, ArkansasDataset\n","from src.data.preprocessing import segment_audio, normalize_audio, AudioPreprocessor\n","from src.features.clinical import ClinicalFeatureExtractor\n","from src.models.classifier import Wav2Vec2PDClassifier, DataCollatorWithPadding\n","\n","print('all project modules imported successfully')"]},{"cell_type":"markdown","id":"9d6cb0dd","metadata":{"id":"9d6cb0dd"},"source":["## data verification"]},{"cell_type":"code","execution_count":null,"id":"d4ea7bc3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1767318037836,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"d4ea7bc3","outputId":"9abe88d1-681f-4391-f033-a27fd4a19007"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset availability:\n","  italian_pvs: available\n","  mdvr_kcl: available\n","  arkansas (figshare): available\n","  uci_oxford_parkinsons: available\n"]}],"source":["# check available datasets\n","from pathlib import Path\n","\n","data_root = Path(PROJECT_ROOT) / 'data' / 'raw'\n","\n","datasets_available = {\n","    'italian_pvs': (data_root / 'italian_pvs').exists(),\n","    'mdvr_kcl': (data_root / 'mdvr-kcl').exists(),\n","    'arkansas (figshare)': (data_root / 'arkansas (figshare)').exists(),\n","    'uci_oxford_parkinsons': (data_root / 'uci_oxford_parkinsons').exists()\n","}\n","\n","print('dataset availability:')\n","for name, available in datasets_available.items():\n","    status = 'available' if available else 'not found'\n","    print(f'  {name}: {status}')"]},{"cell_type":"code","execution_count":null,"id":"1525b888","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1767318038143,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"1525b888","outputId":"2cbc4376-8289-4d52-b332-722c77e66285"},"outputs":[{"name":"stdout","output_type":"stream","text":["italian pvs dataset loaded: 831 samples\n","class distribution: 394 hc, 437 pd\n"]}],"source":["# load italian pvs dataset for testing\n","try:\n","    italian_dataset = ItalianPVSDataset(\n","        root_dir=str(data_root / 'italian_pvs'),\n","        task=None,\n","        max_duration=10.0\n","    )\n","    print(f'italian pvs dataset loaded: {len(italian_dataset)} samples')\n","\n","    # get class distribution\n","    labels = [s['label'] for s in italian_dataset.samples]\n","    n_pd = sum(labels)\n","    n_hc = len(labels) - n_pd\n","    print(f'class distribution: {n_hc} hc, {n_pd} pd')\n","\n","except Exception as e:\n","    print(f'failed to load italian pvs: {e}')"]},{"cell_type":"code","execution_count":null,"id":"ab28e8b0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6416,"status":"ok","timestamp":1767318044562,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"ab28e8b0","outputId":"eaf41b20-da19-4564-dd75-35c8e233178a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0msample keys: dict_keys(['input_values', 'label', 'subject_id', 'task', 'path', 'diagnosis'])\n","input_values shape: torch.Size([160000])\n","label: 0\n","subject_id: HC_young_Alberto_R\n"]}],"source":["# test sample loading\n","import sys\n","\n","# install torchcodec\n","!pip install -q torchcodec\n","\n","# This code will only execute after the restart (if one was triggered manually or by previous cells)\n","sample = italian_dataset[0]\n","\n","print(f'sample keys: {sample.keys()}')\n","print(f'input_values shape: {sample[\"input_values\"].shape}')\n","print(f'label: {sample[\"label\"]}')\n","print(f'subject_id: {sample[\"subject_id\"]}')"]},{"cell_type":"code","execution_count":null,"id":"af207ea3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1767318044579,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"af207ea3","outputId":"be9580d3-bfd8-48bb-c4e5-705ee5475d76"},"outputs":[{"name":"stdout","output_type":"stream","text":["generating subject-wise splits...\n","train samples: 565 (total samples in this split)\n","validation samples: 65 (total samples in this split)\n","test samples: 201 (total samples in this split)\n","verifying for subject leakage between splits...\n","unique subjects in train split: 42\n","unique subjects in validation split: 6\n","unique subjects in test split: 13\n","no subject leakage detected - splits are valid and distinct.\n"]}],"source":["# test subject-wise split\n","print('generating subject-wise splits...')\n","train_subset, val_subset, test_subset = italian_dataset.get_subject_split(\n","    test_size=0.2,\n","    val_size=0.1,\n","    random_state=42\n",")\n","\n","print(f'train samples: {len(train_subset)} (total samples in this split)')\n","print(f'validation samples: {len(val_subset)} (total samples in this split)')\n","print(f'test samples: {len(test_subset)} (total samples in this split)')\n","\n","# verify no subject overlap\n","print('verifying for subject leakage between splits...')\n","# access subject_id directly from the dataset's metadata using the subset indices\n","train_subjects = set(train_subset.dataset.samples[i]['subject_id'] for i in train_subset.indices)\n","val_subjects = set(val_subset.dataset.samples[i]['subject_id'] for i in val_subset.indices)\n","test_subjects = set(test_subset.dataset.samples[i]['subject_id'] for i in test_subset.indices)\n","\n","print(f'unique subjects in train split: {len(train_subjects)}')\n","print(f'unique subjects in validation split: {len(val_subjects)}')\n","print(f'unique subjects in test split: {len(test_subjects)}')\n","\n","assert len(train_subjects & val_subjects) == 0, 'subject leakage detected: train and validation splits share subjects.'\n","assert len(train_subjects & test_subjects) == 0, 'subject leakage detected: train and test splits share subjects.'\n","assert len(val_subjects & test_subjects) == 0, 'subject leakage detected: validation and test splits share subjects.'\n","\n","print('no subject leakage detected - splits are valid and distinct.')"]},{"cell_type":"code","execution_count":null,"id":"08653b08","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2786,"status":"ok","timestamp":1767318048028,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"08653b08","outputId":"7cc12583-bb90-49df-af31-c8e40697ffc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["extracted clinical features:\n","  f0_mean: 132.5603\n","  f0_std: 85.6724\n","  f0_min: 69.4267\n","  f0_max: 597.5883\n","  f0_median: 111.0828\n","  f0_range: 528.1616\n","  voicing_fraction: 0.6061\n","  jitter_local: 0.0300\n","  jitter_rap: 0.0121\n","  jitter_ppq5: 0.0152\n","  jitter_ddp: 0.0363\n","  shimmer_local: 0.1281\n","  shimmer_apq3: 0.0673\n","  shimmer_apq5: 0.0760\n","  shimmer_apq11: 0.1145\n","  shimmer_dda: 0.2019\n","  hnr_mean: 10.0523\n","  hnr_std: 5.1828\n","  f1_mean: 716.9532\n","  f1_std: 438.6613\n","  f2_mean: 1810.4948\n","  f2_std: 575.4603\n","  f3_mean: 3044.5919\n","  f3_std: 444.7081\n","  f4_mean: 4102.5912\n","  f4_std: 444.9910\n","  total_duration: 38.2955\n","  voiced_duration: 23.2115\n","  unvoiced_duration: 15.0840\n"]}],"source":["# ensure parselmouth.undefined exists for clinicalfeatureextractor\n","import parselmouth\n","import numpy as np # added explicitly for clarity\n","\n","if not hasattr(parselmouth, 'UNDEFINED'):\n","    parselmouth.UNDEFINED = np.nan\n","\n","# test clinical feature extraction on sample\n","extractor = ClinicalFeatureExtractor()\n","\n","# extract from first sample\n","sample_path = italian_dataset.samples[0]['path']\n","features = extractor.extract(str(sample_path))\n","\n","print('extracted clinical features:')\n","for key, value in features.items():\n","    if value is not None:\n","        print(f'  {key}: {value:.4f}')"]},{"cell_type":"markdown","id":"8974a13e","metadata":{"id":"8974a13e"},"source":["## model verification"]},{"cell_type":"code","execution_count":null,"id":"ce09490b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2101,"status":"ok","timestamp":1767318050126,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"ce09490b","outputId":"03f0ec7d-91b6-40fc-8442-16600ef617fb"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model parameters:\n","  total: 94,569,090\n","  trainable: 90,368,642\n","  frozen: 4,200,448\n","  trainable %: 95.56%\n"]}],"source":["# test model loading\n","classifier = Wav2Vec2PDClassifier(\n","    model_name='facebook/wav2vec2-base-960h',\n","    num_labels=2,\n","    freeze_feature_extractor=True,\n","    device='cuda'\n",")\n","\n","params = classifier.count_parameters()\n","print('model parameters:')\n","print(f'  total: {params[\"total\"]:,}')\n","print(f'  trainable: {params[\"trainable\"]:,}')\n","print(f'  frozen: {params[\"frozen\"]:,}')\n","print(f'  trainable %: {params[\"trainable_percent\"]:.2f}%')"]},{"cell_type":"code","execution_count":null,"id":"bbc230cd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1353,"status":"ok","timestamp":1767318051480,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"bbc230cd","outputId":"751b1ab3-8b86-444a-d356-741d85be6ac2"},"outputs":[{"name":"stdout","output_type":"stream","text":["input shape: torch.Size([1, 160000])\n","output logits shape: torch.Size([1, 2])\n","output logits: tensor([[0.0011, 0.0350]], device='cuda:0')\n"]}],"source":["# test forward pass\n","sample_input = sample['input_values'].unsqueeze(0).to('cuda')\n","\n","with torch.no_grad():\n","    logits = classifier.forward(sample_input)\n","\n","print(f'input shape: {sample_input.shape}')\n","print(f'output logits shape: {logits.shape}')\n","print(f'output logits: {logits}')"]},{"cell_type":"code","execution_count":null,"id":"e53f2c21","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1767318051807,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"e53f2c21","outputId":"b81c7a3a-cdb3-4c1d-898f-6ab701d8ccc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["batch keys: KeysView({'input_values': tensor([[[-4.6985e-04, -4.6985e-04, -4.6985e-04,  ..., -3.2339e-01,\n","          -3.1667e-01, -8.1201e-02],\n","         [-4.6985e-04, -4.6985e-04,  2.2726e-03,  ..., -9.2194e-01,\n","          -8.1224e-01, -8.7806e-01],\n","         [-4.6985e-04, -4.6985e-04, -4.6985e-04,  ...,  1.5676e-01,\n","           2.3181e-01,  2.5325e-01],\n","         [-4.6985e-04, -4.6985e-04, -4.6985e-04,  ...,  2.7230e+00,\n","           1.8186e+00,  1.5370e+00]]]), 'attention_mask': tensor([[1, 1, 1, 1]], dtype=torch.int32), 'labels': tensor([0, 0, 0, 0])})\n","input_values shape: torch.Size([1, 4, 160000])\n","attention_mask shape: torch.Size([1, 4])\n","labels: tensor([0, 0, 0, 0])\n"]}],"source":["# test data collator\n","from torch.utils.data import Subset\n","\n","# initialize DataCollatorWithPadding with a specified max_length\n","# the max_length is derived from the dataset's max_duration (10.0s) and sampling rate (16000 hz)\n","collator = DataCollatorWithPadding(\n","    classifier.feature_extractor,\n","    max_length=160000 # 10 seconds * 16000 samples/second\n",")\n","\n","# create small batch\n","batch_samples = [italian_dataset[i] for i in range(4)]\n","batch = collator(batch_samples)\n","\n","print(f'batch keys: {batch.keys()}')\n","print(f'input_values shape: {batch[\"input_values\"].shape}')\n","print(f'attention_mask shape: {batch[\"attention_mask\"].shape}')\n","print(f'labels: {batch[\"labels\"]}')"]},{"cell_type":"markdown","id":"66998037","metadata":{"id":"66998037"},"source":["## environment saved\n","\n","environment is verified and ready for training.\n","proceed to notebook 02 for fine-tuning."]},{"cell_type":"code","execution_count":null,"id":"77d888c5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1767318051846,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"77d888c5","outputId":"35e25152-d183-44aa-8150-f46601b7eaf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["environment info saved to /content/drive/MyDrive/pd-interpretability/results/env_info.json\n"]}],"source":["# save environment info for reproducibility\n","import json\n","from datetime import datetime\n","\n","env_info = {\n","    'timestamp': datetime.now().isoformat(),\n","    'pytorch_version': torch.__version__,\n","    'cuda_available': torch.cuda.is_available(),\n","    'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    'datasets': {\n","        'italian_pvs': len(italian_dataset) if 'italian_dataset' in dir() else 0\n","    },\n","    'model_params': params\n","}\n","\n","env_path = Path(PROJECT_ROOT) / 'results' / 'env_info.json'\n","env_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","with open(env_path, 'w') as f:\n","    json.dump(env_info, f, indent=2)\n","\n","print(f'environment info saved to {env_path}')"]},{"cell_type":"code","execution_count":null,"id":"lqMFqoKdcCNP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21214,"status":"ok","timestamp":1767319453509,"user":{"displayName":"smayan","userId":"11108533569134271361"},"user_tz":360},"id":"lqMFqoKdcCNP","outputId":"58f6579b-2891-4544-e7d4-ccfae69e558b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Refresh index: 100% (69/69), done.\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   data/activations/activations\u001b[m\n","\t\u001b[31mmodified:   data/activations/activations.bak\u001b[m\n","\t\u001b[31mmodified:   notebooks/colab/01_setup_and_data.ipynb\u001b[m\n","\t\u001b[31mmodified:   requirements-colab.txt\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31m=4.41.0\u001b[m\n","\t\u001b[31mresults/env_info.json\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","[main 846a7cf] sync colab-tested notebook and requirements fixes\n"," 6 files changed, 21 insertions(+), 346 deletions(-)\n"," create mode 100644 =4.41.0\n"," rewrite notebooks/colab/01_setup_and_data.ipynb (100%)\n"," create mode 100644 results/env_info.json\n","Enumerating objects: 20, done.\n","Counting objects: 100% (20/20), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (10/10), done.\n","Writing objects: 100% (11/11), 6.68 KiB | 427.00 KiB/s, done.\n","Total 11 (delta 5), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n","To https://github.com/smayan-gowda/pd-interpretability.git\n","   3a77207..846a7cf  main -> main\n"]}],"source":["%cd /content/drive/MyDrive/pd-interpretability\n","\n","!git status\n","\n","!git config user.name \"smayan-gowda\"\n","!git config user.email \"smayan-gowda@users.noreply.github.com\"\n","\n","!git add -A\n","\n","!git commit -m \"sync colab-tested notebook and requirements fixes\"\n","\n","!git push origin main"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"venv (3.13.5)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"}},"nbformat":4,"nbformat_minor":5}