{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publication-quality LaTeX figure setup and helpers (same as cpu notebook)\n",
    "import matplotlib as mpl\n",
    "import shutil\n",
    "\n",
    "def setup_publication_figures():\n",
    "    tex_exe = shutil.which('pdflatex') or shutil.which('xelatex') or shutil.which('lualatex')\n",
    "    latex_available = bool(tex_exe)\n",
    "    if latex_available:\n",
    "        mpl.rcParams.update({\n",
    "            'text.usetex': True,\n",
    "            'font.family': 'serif',\n",
    "            'font.serif': ['Times'],\n",
    "            'axes.labelsize': 11,\n",
    "            'font.size': 11,\n",
    "            'axes.titlesize': 12,\n",
    "            'legend.fontsize': 10,\n",
    "            'xtick.labelsize': 10,\n",
    "            'ytick.labelsize': 10,\n",
    "            'figure.dpi': 300,\n",
    "        })\n",
    "        mpl.rcParams['text.latex.preamble'] = r'\\\\usepackage{amsmath}\\\\usepackage{siunitx}\\\\usepackage{bm}'\n",
    "        mpl.rcParams['pdf.fonttype'] = 42\n",
    "        mpl.rcParams['ps.fonttype'] = 42\n",
    "        print(f\"latex found: {tex_exe} -> enabled text.usetex\")\n",
    "    else:\n",
    "        mpl.rcParams.update({\n",
    "            'text.usetex': False,\n",
    "            'mathtext.fontset': 'cm',\n",
    "            'font.family': 'serif',\n",
    "            'axes.labelsize': 11,\n",
    "            'font.size': 11,\n",
    "            'axes.titlesize': 12,\n",
    "            'legend.fontsize': 10,\n",
    "            'xtick.labelsize': 10,\n",
    "            'ytick.labelsize': 10,\n",
    "            'figure.dpi': 300,\n",
    "        })\n",
    "        print(\"latex not found: falling back to matplotlib mathtext. Install a TeX distribution to enable full LaTeX rendering.\")\n",
    "    return latex_available\n",
    "\n",
    "\n",
    "def save_pub_fig(path_without_ext, fig=None, formats=('pdf','svg','png')):\n",
    "    import matplotlib.pyplot as _plt\n",
    "    from pathlib import Path as _Path\n",
    "    fig = fig if fig is not None else _plt.gcf()\n",
    "    base = _Path(path_without_ext)\n",
    "    saved = []\n",
    "    for fmt in formats:\n",
    "        p = base.with_suffix('.' + fmt)\n",
    "        fig.savefig(p, dpi=300, bbox_inches='tight', format=fmt)\n",
    "        saved.append(str(p.name))\n",
    "    return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/pd-interpretability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db82f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -q transformers datasets librosa scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa334f6",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport numpy as np\nimport json\nfrom pathlib import Path\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\n\n# suppress warnings for clean output\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# verify gpu\nprint(f\"gpu available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"gpu: {torch.cuda.get_device_name(0)}\")\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# setup publication-quality figures early\nprint(\"setting up publication-quality figures...\")\nlatex_enabled = setup_publication_figures()\nprint(f\"latex rendering: {'enabled' if latex_enabled else 'disabled (using mathtext fallback)'}\")"
  },
  {
   "cell_type": "markdown",
   "id": "d0408b82",
   "metadata": {},
   "source": [
    "## 1. Load Fine-tuned Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da029d3",
   "metadata": {},
   "outputs": [],
   "source": "# configuration\nproject_root = Path('/content/drive/MyDrive/pd-interpretability')\n\nCONFIG = {\n    'model_path': project_root / 'results' / 'checkpoints' / 'best_model',\n    'data_path': project_root / 'data',\n    'output_path': project_root / 'results' / 'patching',\n    'figures_path': project_root / 'results' / 'figures',\n    'n_pairs': 100,  # number of (HC, PD) pairs for patching\n    'batch_size': 8,\n    'random_seed': 42\n}\n\n# create output directories\nCONFIG['output_path'].mkdir(parents=True, exist_ok=True)\nCONFIG['figures_path'].mkdir(parents=True, exist_ok=True)\n\n# set random seeds\nnp.random.seed(CONFIG['random_seed'])\ntorch.manual_seed(CONFIG['random_seed'])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(CONFIG['random_seed'])\n\nprint(f\"configuration:\")\nprint(f\"  model: {CONFIG['model_path']}\")\nprint(f\"  data: {CONFIG['data_path']}\")\nprint(f\"  output: {CONFIG['output_path']}\")\nprint(f\"  figures: {CONFIG['figures_path']}\")\nprint(f\"  random seed: {CONFIG['random_seed']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324a21e",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import Wav2Vec2PDClassifier\nfrom src.data import ItalianPVSDataset\n\n# load fine-tuned model\nmodel_path = Path(CONFIG['model_path'])\n\nif model_path.exists():\n    classifier = Wav2Vec2PDClassifier.load(model_path)\n    print(f\"loaded model from {model_path}\")\nelse:\n    # load base model for testing\n    print(\"fine-tuned model not found, loading base model\")\n    classifier = Wav2Vec2PDClassifier(num_labels=2)\n\n# load dataset\ndataset = ItalianPVSDataset(\n    root_dir=Path(CONFIG['data_path']) / 'raw' / 'italian_pvs',\n    max_duration=10.0\n)\n\nprint(f\"dataset size: {len(dataset)} samples\")\nprint(f\"model layers: {len(classifier.model.wav2vec2.encoder.layers)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a5c141eb",
   "metadata": {},
   "source": [
    "## 2. Create Minimal Pairs for Patching\n",
    "\n",
    "Match HC samples with acoustically similar PD samples using MFCC distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c0c80",
   "metadata": {},
   "outputs": [],
   "source": "from src.interpretability import create_mfcc_matched_pairs, create_minimal_pairs\n\n# create mfcc-matched pairs\nprint(\"creating mfcc-matched minimal pairs...\")\npairs = create_mfcc_matched_pairs(\n    dataset,\n    n_pairs=CONFIG['n_pairs'],\n    same_task=True\n)\n\nif len(pairs) < CONFIG['n_pairs'] // 2:\n    print(\"falling back to random matching\")\n    pairs = create_minimal_pairs(dataset, n_pairs=CONFIG['n_pairs'])\n\nprint(f\"created {len(pairs)} minimal pairs\")\n\n# separate components\nclean_inputs = [p[0] for p in pairs]\ncorrupted_inputs = [p[1] for p in pairs]\nlabels = [p[2] for p in pairs]\n\n# show distance distribution if available\nif len(pairs[0]) > 3:\n    distances = [p[3] for p in pairs]\n    fig, ax = plt.subplots(figsize=(8, 4))\n    ax.hist(distances, bins=30, edgecolor='black', color='steelblue', alpha=0.7)\n    ax.set_xlabel('mfcc distance', fontsize=11)\n    ax.set_ylabel('count', fontsize=11)\n    ax.set_title('distribution of mfcc distances in minimal pairs', fontsize=12)\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    save_pub_fig(CONFIG['figures_path'] / 'fig_p3_01_mfcc_distances', fig=fig)\n    plt.show()\n    \n    print(f\"mfcc distance stats: mean={np.mean(distances):.3f}, std={np.std(distances):.3f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a51247b0",
   "metadata": {},
   "source": [
    "## 3. Layer-Level Patching\n",
    "\n",
    "For each layer (1-12):\n",
    "- Run model on HC sample, cache layer activations\n",
    "- Run model on matched PD sample with patched HC activations\n",
    "- Measure: Does prediction shift toward HC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9863a",
   "metadata": {},
   "outputs": [],
   "source": "from src.interpretability import ActivationPatcher\n\n# initialize patcher\nprint(\"initializing activation patcher...\")\npatcher = ActivationPatcher(classifier.model, device=device)\n\nprint(f\"  number of layers: {patcher.num_layers}\")\nprint(f\"  number of attention heads per layer: {patcher.num_heads}\")\nprint(f\"  hidden size: {patcher.hidden_size}\")\nprint(f\"  total attention heads: {patcher.num_layers * patcher.num_heads}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98110c7",
   "metadata": {},
   "outputs": [],
   "source": "# run layer-level patching with progress tracking\nprint(\"running layer-level activation patching...\")\nprint(f\"processing {len(clean_inputs)} minimal pairs across {patcher.num_layers} layers\")\nprint(\"(this may take several minutes)\\n\")\n\n# suppress warnings during patching\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    patching_results = patcher.run_batch_patching(\n        clean_inputs,\n        corrupted_inputs,\n        labels,\n        include_heads=False  # layer-level only first\n    )\n\nlayer_patching = patching_results['layer_patching']\n\n# display results\nprint(\"\\n\" + \"=\"*60)\nprint(\"layer-level patching results:\")\nprint(\"=\"*60)\nfor layer_idx in range(patcher.num_layers):\n    stats = layer_patching[layer_idx]\n    print(f\"layer {layer_idx:2d}: mean recovery = {stats['mean_recovery']:+.3f} ± {stats['std_recovery']:.3f}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386f6f7",
   "metadata": {},
   "outputs": [],
   "source": "# visualize layer-level patching results\nlayers = list(range(patcher.num_layers))\nmean_recoveries = [layer_patching[l]['mean_recovery'] for l in layers]\nstd_recoveries = [layer_patching[l]['std_recovery'] for l in layers]\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nbars = ax.bar(layers, mean_recoveries, yerr=std_recoveries, capsize=3,\n              color='steelblue', edgecolor='black', alpha=0.8)\n\n# highlight important layers (recovery > 0.1)\nfor i, (layer, recovery) in enumerate(zip(layers, mean_recoveries)):\n    if recovery > 0.1:\n        bars[i].set_color('darkred')\n\nax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\nax.axhline(y=0.1, color='red', linestyle='--', linewidth=1, alpha=0.7, label='importance threshold (0.1)')\n\nax.set_xlabel('layer', fontsize=12)\nax.set_ylabel('logit difference recovery', fontsize=12)\nax.set_title('layer-level activation patching results\\\\n(hc $\\\\\\\\rightarrow$ pd)', fontsize=14)\nax.set_xticks(layers)\nax.legend(fontsize=10)\nax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nsave_pub_fig(CONFIG['figures_path'] / 'fig_p3_02_layer_patching_results', fig=fig)\nplt.show()\n\n# identify important layers\nimportant_layers = [l for l, r in zip(layers, mean_recoveries) if r > 0.1]\nprint(f\"\\nimportant layers (recovery > 0.1): {important_layers}\")\nprint(f\"peak recovery: layer {np.argmax(mean_recoveries)} ({max(mean_recoveries):.3f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "fdad563b",
   "metadata": {},
   "source": [
    "## 4. Attention Head-Level Patching\n",
    "\n",
    "For layers identified as important, patch each attention head individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d04791",
   "metadata": {},
   "outputs": [],
   "source": "# run head-level patching on important layers\nprint(f\"running head-level patching on layers: {important_layers if important_layers else 'all'}\")\nprint(\"processing 50 pairs (subset for computational efficiency)\\n\")\n\nhead_results = []\n\n# add progress bar for head patching\nfor clean, corrupted, label in tqdm(\n    zip(clean_inputs[:50], corrupted_inputs[:50], labels[:50]),\n    total=50,\n    desc=\"head patching\",\n    ncols=100\n):\n    try:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            result = patcher.run_head_patching(\n                clean, corrupted, label,\n                target_layers=important_layers if important_layers else None\n            )\n            head_results.append(result)\n    except Exception as e:\n        print(f\"warning: head patching failed for one pair: {e}\")\n\nprint(f\"\\ncompleted {len(head_results)}/50 head patching experiments\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b764bc4",
   "metadata": {},
   "outputs": [],
   "source": "from src.interpretability import HeadImportanceRanking\n\n# create head importance ranking\nhead_ranking = HeadImportanceRanking.from_patching_results(\n    head_results,\n    top_k=20,\n    threshold=0.05\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"top 20 important attention heads:\")\nprint(\"=\"*60)\nfor i, (layer, head, score) in enumerate(head_ranking.head_rankings[:20]):\n    print(f\"{i+1:2d}. layer {layer:2d}, head {head:2d}: recovery = {score:+.4f}\")\nprint(\"=\"*60)\n\nprint(f\"\\nidentified {len(head_ranking.important_heads)} important heads (threshold: 0.05)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c91512",
   "metadata": {},
   "outputs": [],
   "source": "# visualize head importance as heatmap\nn_layers = patcher.num_layers\nn_heads = patcher.num_heads\n\nhead_matrix = np.zeros((n_layers, n_heads))\n\nfor (layer, head), score in head_ranking.head_scores.items():\n    head_matrix[layer, head] = score\n\nfig, ax = plt.subplots(figsize=(14, 8))\n\nim = ax.imshow(head_matrix, cmap='RdBu_r', aspect='auto', vmin=-0.2, vmax=0.2)\n\nax.set_xlabel('attention head', fontsize=12)\nax.set_ylabel('layer', fontsize=12)\nax.set_title('attention head patching results\\\\n(logit difference recovery)', fontsize=14)\n\nax.set_xticks(range(n_heads))\nax.set_yticks(range(n_layers))\n\ncbar = plt.colorbar(im, ax=ax)\ncbar.set_label('recovery score', fontsize=11)\n\n# mark important heads with black boxes\nfor layer, head in head_ranking.important_heads:\n    ax.add_patch(plt.Rectangle((head-0.5, layer-0.5), 1, 1, \n                               fill=False, edgecolor='black', linewidth=2))\n\nplt.tight_layout()\nsave_pub_fig(CONFIG['figures_path'] / 'fig_p3_03_head_patching_heatmap', fig=fig)\nplt.show()\n\nprint(f\"important heads marked with black boxes\")"
  },
  {
   "cell_type": "markdown",
   "id": "55513f2e",
   "metadata": {},
   "source": [
    "## 5. Mean Ablation Validation\n",
    "\n",
    "Complement patching with ablation: replace target component activations with dataset mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e9e47",
   "metadata": {},
   "outputs": [],
   "source": "# compute mean activations across dataset for ablation baseline\nprint(\"computing mean activations for ablation baseline...\")\nprint(\"(processing 200 samples - this may take a few minutes)\\n\")\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    mean_acts = patcher.compute_mean_activations(dataset, max_samples=200)\n\nprint(f\"computed mean activations for {len(mean_acts)} layers\")\nprint(f\"mean activation shape per layer: {list(mean_acts.values())[0].shape if mean_acts else 'N/A'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a465d",
   "metadata": {},
   "outputs": [],
   "source": "# run ablation validation to complement patching results\nprint(\"validating with mean ablation...\")\nprint(\"(processing 100 samples)\\n\")\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    ablation_results = patcher.validate_with_ablation(\n        dataset,\n        patching_results,\n        max_samples=100\n    )\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ablation effects per layer:\")\nprint(\"=\"*60)\nfor layer_idx, stats in ablation_results['ablation_effects'].items():\n    print(f\"layer {layer_idx:2d}: mean effect = {stats['mean_effect']:+.4f} ± {stats['std_effect']:.4f}\")\nprint(\"=\"*60)\n\nprint(\"\\nconcordance analysis (patching vs ablation):\")\nprint(f\"  spearman correlation: {ablation_results['concordance']['spearman_correlation']:.3f}\")\nprint(f\"  p-value: {ablation_results['concordance']['p_value']:.4f}\")\nprint(f\"  interpretation: {ablation_results['concordance']['interpretation']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538878a2",
   "metadata": {},
   "outputs": [],
   "source": "# visualize patching vs ablation concordance\npatching_scores = [layer_patching[l]['mean_recovery'] for l in range(n_layers)]\nablation_scores = [ablation_results['ablation_effects'].get(l, {}).get('mean_effect', 0) \n                   for l in range(n_layers)]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# comparison bar plot\nx = np.arange(n_layers)\nwidth = 0.35\n\nax1.bar(x - width/2, patching_scores, width, label='patching recovery', color='steelblue')\nax1.bar(x + width/2, ablation_scores, width, label='ablation effect', color='coral')\n\nax1.set_xlabel('layer', fontsize=11)\nax1.set_ylabel('effect size', fontsize=11)\nax1.set_title('patching vs. ablation effects', fontsize=12)\nax1.set_xticks(x)\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3, axis='y')\n\n# scatter plot for correlation\nax2.scatter(patching_scores, ablation_scores, s=100, c='darkgreen', alpha=0.7)\n\nfor i, (p, a) in enumerate(zip(patching_scores, ablation_scores)):\n    ax2.annotate(f'L{i}', (p, a), xytext=(5, 5), textcoords='offset points', fontsize=9)\n\n# add trend line\nz = np.polyfit(patching_scores, ablation_scores, 1)\np = np.poly1d(z)\nx_line = np.linspace(min(patching_scores), max(patching_scores), 100)\nax2.plot(x_line, p(x_line), 'r--', alpha=0.7, label='trend')\n\nax2.set_xlabel('patching recovery', fontsize=11)\nax2.set_ylabel('ablation effect', fontsize=11)\nax2.set_title(f'concordance (r = {ablation_results[\"concordance\"][\"spearman_correlation\"]:.3f})', fontsize=12)\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nsave_pub_fig(CONFIG['figures_path'] / 'fig_p3_04_patching_ablation_concordance', fig=fig)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "7edbf634",
   "metadata": {},
   "source": [
    "## 6. Clinical Feature Path Patching\n",
    "\n",
    "Test if heads with high clinical feature probing accuracy are the same heads that causally affect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b726",
   "metadata": {},
   "outputs": [],
   "source": "# load clinical features for stratified patching analysis\nclinical_path = Path(CONFIG['data_path']) / 'clinical_features' / 'italian_pvs_features.csv'\n\nif clinical_path.exists():\n    import pandas as pd\n    clinical_df = pd.read_csv(clinical_path)\n    \n    # extract feature columns\n    clinical_feature_cols = ['jitter_local', 'shimmer_local', 'hnr_mean', 'f0_std']\n    clinical_features = {\n        name: clinical_df[name].values for name in clinical_feature_cols if name in clinical_df.columns\n    }\n    sample_ids = clinical_df['subject_id'].values if 'subject_id' in clinical_df.columns else None\n    \n    print(f\"loaded clinical features: {list(clinical_features.keys())}\")\n    print(f\"total samples: {len(clinical_df)}\")\nelse:\n    print(\"clinical features not found at expected path\")\n    print(f\"expected: {clinical_path}\")\n    print(\"skipping stratified analysis\")\n    clinical_features = None\n    sample_ids = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9ab5c",
   "metadata": {},
   "outputs": [],
   "source": "if clinical_features is not None:\n    from src.interpretability import ClinicalStratifiedPatcher\n    \n    print(\"running clinical feature-stratified patching analysis...\")\n    print(\"(tests if heads encoding clinical features causally affect predictions)\\n\")\n    \n    stratified_patcher = ClinicalStratifiedPatcher(\n        patcher,\n        clinical_features,\n        sample_ids\n    )\n    \n    # test on jitter_local (a key PD biomarker)\n    if 'jitter_local' in clinical_features:\n        print(\"analyzing jitter_local stratification...\")\n        \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            jitter_results = stratified_patcher.run_stratified_head_patching(\n                dataset,\n                feature_name='jitter_local',\n                target_heads=head_ranking.important_heads[:10],  # top 10 heads\n                n_pairs_per_stratum=15\n            )\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"jitter-stratified patching results:\")\n        print(\"=\"*60)\n        for stratum, data in jitter_results.items():\n            if stratum in ['low', 'medium', 'high']:\n                print(f\"\\n{stratum.upper()} jitter stratum:\")\n                for head, stats in data.get('head_effects', {}).items():\n                    print(f\"  {head}: recovery = {stats['mean_recovery']:+.4f}\")\n        \n        # differential effects (high - low)\n        print(\"\\n\" + \"=\"*60)\n        print(\"differential effects (high jitter - low jitter):\")\n        print(\"=\"*60)\n        for head, diff in jitter_results.get('differential_effects', {}).items():\n            print(f\"  {head}: {diff:+.4f}\")\n        print(\"=\"*60)\nelse:\n    print(\"skipping stratified analysis (clinical features not loaded)\")"
  },
  {
   "cell_type": "markdown",
   "id": "652d7710",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7a3c1",
   "metadata": {},
   "outputs": [],
   "source": "# compile all results for saving\nfull_results = {\n    'config': CONFIG,\n    'layer_patching': patching_results['layer_patching'],\n    'head_patching': head_ranking.to_dict(),\n    'ablation_validation': ablation_results,\n    'important_layers': important_layers,\n    'important_heads': [{'layer': l, 'head': h} for l, h in head_ranking.important_heads]\n}\n\nif clinical_features is not None and 'jitter_local' in clinical_features:\n    full_results['clinical_stratified'] = {'jitter_local': jitter_results}\n\n# save to json\nresults_path = CONFIG['output_path'] / 'patching_results.json'\nwith open(results_path, 'w') as f:\n    json.dump(full_results, f, indent=2, default=str)\n\nprint(f\"results saved to {results_path}\")\n\n# also save a summary text file\nsummary_path = CONFIG['output_path'] / 'patching_summary.txt'\nwith open(summary_path, 'w') as f:\n    f.write(\"activation patching analysis summary\\n\")\n    f.write(\"=\"*60 + \"\\n\\n\")\n    f.write(f\"total minimal pairs tested: {len(pairs)}\\n\")\n    f.write(f\"important layers: {important_layers}\\n\")\n    f.write(f\"important attention heads: {len(head_ranking.important_heads)}\\n\")\n    f.write(f\"patching-ablation concordance: {ablation_results['concordance']['spearman_correlation']:.3f}\\n\")\n\nprint(f\"summary saved to {summary_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073aad",
   "metadata": {},
   "outputs": [],
   "source": "# final summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"activation patching analysis complete\")\nprint(\"=\" * 60)\nprint(f\"\\ntotal minimal pairs tested: {len(pairs)}\")\nprint(f\"\\nimportant layers (recovery > 0.1): {important_layers}\")\nprint(f\"number of important attention heads: {len(head_ranking.important_heads)}\")\n\nprint(f\"\\ntop 5 attention heads:\")\nfor layer, head, score in head_ranking.head_rankings[:5]:\n    print(f\"  layer {layer}, head {head}: {score:+.4f}\")\n\nprint(f\"\\npatching-ablation concordance: {ablation_results['concordance']['spearman_correlation']:.3f}\")\nprint(f\"concordance interpretation: {ablation_results['concordance']['interpretation']}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"all results saved to:\")\nprint(f\"  figures: {CONFIG['figures_path']}\")\nprint(f\"  data: {CONFIG['output_path']}\")\nprint(\"=\" * 60)"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}