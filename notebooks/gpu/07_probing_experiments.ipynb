{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -q transformers datasets librosa scipy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# set style for publication-quality figures\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 150\n",
    "})\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5434fd7",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86dc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/home/cc/projects/pd-interpretability/data',\n",
    "    'activations_path': '/home/cc/projects/pd-interpretability/data/activations',\n",
    "    'output_path': '/home/cc/projects/pd-interpretability/results/probing',\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# create output directory\n",
    "output_path = Path(CONFIG['output_path'])\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"output directory: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545be6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-extracted activations\n",
    "activations_path = Path(CONFIG['activations_path'])\n",
    "\n",
    "# load activations and metadata\n",
    "activations_file = activations_path / 'activations.npy'\n",
    "metadata_file = activations_path / 'metadata.json'\n",
    "\n",
    "if activations_file.exists():\n",
    "    activations = np.load(activations_file)\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"loaded activations: {activations.shape}\")\n",
    "    print(f\"samples: {metadata.get('n_samples', len(metadata.get('labels', [])))}\")\n",
    "    print(f\"layers: {activations.shape[1]}\")\n",
    "    print(f\"hidden size: {activations.shape[2]}\")\n",
    "else:\n",
    "    print(\"activations not found, need to run extraction first\")\n",
    "    activations = None\n",
    "    metadata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels and subject ids from metadata\n",
    "if metadata:\n",
    "    labels = np.array(metadata['labels'])\n",
    "    subject_ids = np.array(metadata['subject_ids'])\n",
    "    \n",
    "    print(f\"label distribution: PD={sum(labels==1)}, HC={sum(labels==0)}\")\n",
    "    print(f\"unique subjects: {len(np.unique(subject_ids))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probing Architecture\n\nvisualization of the linear probing methodology used to decode clinical features from layer activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Linear Probing Architecture Diagram\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch, Circle\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "\n",
    "# Okabe-Ito colorblind-friendly palette\n",
    "colors = {\n",
    "    'input': '#E69F00',\n",
    "    'model': '#56B4E9',\n",
    "    'activation': '#009E73',\n",
    "    'probe': '#F0E442',\n",
    "    'target': '#D55E00',\n",
    "    'loss': '#CC79A7'\n",
    "}\n",
    "\n",
    "def draw_box(ax, x, y, w, h, text, color, fontsize=10, text_lines=None):\n",
    "    box = FancyBboxPatch((x, y), w, h, boxstyle=\"round,pad=0.1\",\n",
    "                         edgecolor='black', facecolor=color, linewidth=2, alpha=0.8)\n",
    "    ax.add_patch(box)\n",
    "    if text_lines:\n",
    "        y_text = y + h/2 + (len(text_lines)-1)*0.12\n",
    "        for line in text_lines:\n",
    "            ax.text(x + w/2, y_text, line, ha='center', va='center',\n",
    "                   fontsize=fontsize, fontweight='bold')\n",
    "            y_text -= 0.25\n",
    "    else:\n",
    "        ax.text(x + w/2, y + h/2, text, ha='center', va='center',\n",
    "               fontsize=fontsize, fontweight='bold')\n",
    "\n",
    "def draw_arrow(ax, x1, y1, x2, y2, label='', style='->'):\n",
    "    arrow = FancyArrowPatch((x1, y1), (x2, y2),\n",
    "                           arrowstyle=style, mutation_scale=20, linewidth=2.5,\n",
    "                           color='black')\n",
    "    ax.add_patch(arrow)\n",
    "    if label:\n",
    "        mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        ax.text(mid_x, mid_y + 0.25, label, fontsize=9, style='italic',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='gray'))\n",
    "\n",
    "# 1. Input Speech\n",
    "draw_box(ax, 0.5, 8, 2, 1.2, '', colors['input'],\n",
    "         text_lines=['Speech', 'Input', '(audio)'])\n",
    "ax.text(1.5, 7.5, 'waveform', ha='center', fontsize=8, style='italic')\n",
    "\n",
    "draw_arrow(ax, 1.5, 8, 1.5, 6.8)\n",
    "\n",
    "# 2. Pretrained Wav2Vec2 Model\n",
    "draw_box(ax, 0.2, 4.5, 2.6, 2.2, '', colors['model'],\n",
    "         text_lines=['Pretrained', 'Wav2Vec2', 'Model', '(FROZEN)'])\n",
    "ax.text(1.5, 4.2, '12 transformer layers', ha='center', fontsize=8, style='italic')\n",
    "\n",
    "# Show individual layers\n",
    "for i in range(3):\n",
    "    layer_num = i * 4\n",
    "    y_pos = 6.2 - i * 0.5\n",
    "    ax.text(0.5, y_pos, f'L{layer_num}', fontsize=7,\n",
    "           bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))\n",
    "ax.text(0.5, 5.2, '...', fontsize=10, fontweight='bold')\n",
    "\n",
    "draw_arrow(ax, 1.5, 4.5, 1.5, 3.8)\n",
    "\n",
    "# 3. Layer Activations (show multiple layers branching)\n",
    "draw_box(ax, 0.5, 2.8, 2, 0.9, '', colors['activation'],\n",
    "         text_lines=['Layer', 'Activations'])\n",
    "ax.text(1.5, 2.4, 'h \u2208 \u211d^(T\u00d7768)', ha='center', fontsize=8, style='italic',\n",
    "       family='serif')\n",
    "\n",
    "# Show extraction from different layers\n",
    "for i, layer_idx in enumerate([0, 6, 11]):\n",
    "    x_branch = 3.5 + i * 2.5\n",
    "    # Arrow from model to activation\n",
    "    ax.plot([2.8, x_branch], [5.5, 3.5], 'k--', linewidth=1.5, alpha=0.4)\n",
    "    \n",
    "    # Activation box for this layer\n",
    "    draw_box(ax, x_branch - 0.6, 3.2, 1.2, 0.6, f'Layer {layer_idx}',\n",
    "            colors['activation'], fontsize=9)\n",
    "    \n",
    "    # Arrow down to probe\n",
    "    draw_arrow(ax, x_branch, 3.2, x_branch, 2.5)\n",
    "    \n",
    "    # Linear probe for this layer\n",
    "    draw_box(ax, x_branch - 0.7, 1.5, 1.4, 0.9, '', colors['probe'],\n",
    "            text_lines=[f'Linear', f'Probe {layer_idx}'], fontsize=8)\n",
    "    ax.text(x_branch, 1.15, 'W \u2208 \u211d^(768\u00d7K)', ha='center', fontsize=7,\n",
    "           style='italic', family='serif')\n",
    "    \n",
    "    # Arrow to prediction\n",
    "    draw_arrow(ax, x_branch, 1.5, x_branch, 0.8)\n",
    "    \n",
    "    # Prediction\n",
    "    draw_box(ax, x_branch - 0.5, 0.3, 1.0, 0.4, f'\u0177{layer_idx}',\n",
    "            colors['target'], fontsize=8)\n",
    "\n",
    "# 4. Target Clinical Features (on the right)\n",
    "draw_box(ax, 10, 7, 1.5, 2, '', colors['target'],\n",
    "         text_lines=['Target', 'Clinical', 'Features'])\n",
    "features_text = ['\u2022 Jitter', '\u2022 Shimmer', '\u2022 HNR', '\u2022 F0']\n",
    "y_feat = 8.5\n",
    "for feat in features_text:\n",
    "    ax.text(10.75, y_feat, feat, ha='center', fontsize=8)\n",
    "    y_feat -= 0.35\n",
    "\n",
    "# Arrows from targets to each prediction for loss computation\n",
    "for i, layer_idx in enumerate([0, 6, 11]):\n",
    "    x_pred = 3.5 + i * 2.5\n",
    "    ax.plot([10, x_pred], [7, 0.5], 'r--', linewidth=1.2, alpha=0.3)\n",
    "\n",
    "# 5. Loss Computation (center bottom)\n",
    "draw_box(ax, 4.5, 0.05, 3, 0.55, '', colors['loss'],\n",
    "         text_lines=['Mean Squared Error: MSE(y, \u0177)'])\n",
    "\n",
    "# Add methodology panel\n",
    "method_box = FancyBboxPatch((10, 4, ), 1.8, 2.5, boxstyle=\"round,pad=0.15\",\n",
    "                           edgecolor='black', facecolor='#F5F5F5',\n",
    "                           linewidth=2, alpha=0.9)\n",
    "ax.add_patch(method_box)\n",
    "\n",
    "ax.text(10.9, 6.2, 'Probing Protocol', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "method_text = [\n",
    "    ('1. Freeze Model', 'Pretrained weights frozen'),\n",
    "    ('2. Extract Activations', 'From all 12 layers'),\n",
    "    ('3. Train Linear Probe', 'Ridge regression'),\n",
    "    ('4. Evaluate', 'LOSO cross-validation'),\n",
    "    ('5. Compare Layers', 'Find best encoding'),\n",
    "]\n",
    "\n",
    "y_text = 5.8\n",
    "for title, desc in method_text:\n",
    "    ax.text(10.2, y_text, title, ha='left', fontsize=9, fontweight='bold')\n",
    "    y_text -= 0.25\n",
    "    ax.text(10.3, y_text, desc, ha='left', fontsize=7, style='italic',\n",
    "           color='#555555')\n",
    "    y_text -= 0.35\n",
    "\n",
    "# Add key parameters panel\n",
    "param_box = FancyBboxPatch((10, 0.8), 1.8, 2.8, boxstyle=\"round,pad=0.15\",\n",
    "                          edgecolor='black', facecolor='#F5F5F5',\n",
    "                          linewidth=2, alpha=0.9)\n",
    "ax.add_patch(param_box)\n",
    "\n",
    "ax.text(10.9, 3.4, 'Key Parameters', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "param_text = [\n",
    "    'Probe Type: Linear (Ridge)',\n",
    "    'Regularization: \u03b1 = 1.0',\n",
    "    'Layers Probed: 0-11 (all)',\n",
    "    'Input Dim: 768',\n",
    "    'Output Dim: K features',\n",
    "    'Validation: LOSO CV',\n",
    "    'Metric: R\u00b2 score',\n",
    "    'Optimization: Closed-form',\n",
    "]\n",
    "\n",
    "y_text = 3.1\n",
    "for param in param_text:\n",
    "    ax.text(10.2, y_text, param, ha='left', fontsize=8,\n",
    "           family='monospace')\n",
    "    y_text -= 0.28\n",
    "\n",
    "# Add title and caption\n",
    "fig.suptitle('Linear Probing Architecture for Clinical Feature Decoding',\n",
    "            fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "caption = (\n",
    "    'Linear probes are trained independently on each layer to predict clinical voice biomarkers '\n",
    "    'from frozen Wav2Vec2 activations. The layer with highest R\u00b2 identifies where each feature '\n",
    "    'is most strongly encoded. LOSO cross-validation ensures subject-independent evaluation.'\n",
    ")\n",
    "fig.text(0.5, 0.01, caption, ha='center', fontsize=9, style='italic', wrap=True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "# Save\n",
    "for fmt in ['pdf', 'png', 'svg']:\n",
    "    fig.savefig(f'results/fig_p7_01_probing_architecture.{fmt}',\n",
    "               dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"saved Saved probing architecture: results/fig_p7_01_probing_architecture.{{pdf,png,svg}}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f97de",
   "metadata": {},
   "source": [
    "## 2. Layer-wise PD Classification Probing\n",
    "\n",
    "For each transformer layer, train a linear classifier to predict PD vs HC.\n",
    "Uses leave-one-subject-out cross-validation for unbiased estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5eb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.probes import LayerwiseProber\n",
    "\n",
    "# run layer-wise probing\n",
    "prober = LayerwiseProber(task='classification', regularization=1.0)\n",
    "\n",
    "print(\"running layer-wise pd classification probing...\")\n",
    "print(\"(using leave-one-subject-out cross-validation)\\n\")\n",
    "\n",
    "probing_results = prober.probe_all_layers(\n",
    "    activations,\n",
    "    labels,\n",
    "    groups=subject_ids\n",
    ")\n",
    "\n",
    "print(\"\\nlayer-wise probing accuracy:\")\n",
    "print(\"-\" * 50)\n",
    "for layer_idx, result in sorted(probing_results.items()):\n",
    "    print(f\"layer {layer_idx:2d}: {result['mean']:.3f} \u00b1 {result['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bcb763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualization import plot_layerwise_probing\n",
    "\n",
    "# create publication-quality figure\n",
    "fig = plot_layerwise_probing(\n",
    "    probing_results,\n",
    "    title=\"layer-wise pd classification probing accuracy\",\n",
    "    save_path=str(output_path / 'layerwise_probing.png'),\n",
    "    chance_level=0.5\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# identify best layer\n",
    "best_layer = max(probing_results.keys(), key=lambda x: probing_results[x]['mean'])\n",
    "best_acc = probing_results[best_layer]['mean']\n",
    "\n",
    "print(f\"\\nbest probing layer: {best_layer} (accuracy = {best_acc:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical analysis: is best layer significantly better than chance?\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "best_scores = probing_results[best_layer]['scores']\n",
    "t_stat, p_value = ttest_1samp(best_scores, 0.5)\n",
    "\n",
    "print(f\"\\nstatistical test (layer {best_layer} vs chance):\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.4e}\")\n",
    "print(f\"  significant at \u03b1=0.05: {p_value < 0.05}\")\n",
    "\n",
    "# effect size\n",
    "cohens_d = (np.mean(best_scores) - 0.5) / np.std(best_scores)\n",
    "print(f\"  cohen's d: {cohens_d:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0629dc",
   "metadata": {},
   "source": [
    "## 3. Clinical Feature Probing\n",
    "\n",
    "Probe each layer for clinical voice biomarkers:\n",
    "- Jitter (pitch perturbation)\n",
    "- Shimmer (amplitude perturbation)\n",
    "- HNR (harmonics-to-noise ratio)\n",
    "- F0 statistics (fundamental frequency)\n",
    "\n",
    "This reveals WHERE clinical features are encoded in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clinical features\n",
    "clinical_path = Path(CONFIG['data_path']) / 'clinical_features' / 'italian_pvs_features.csv'\n",
    "\n",
    "if clinical_path.exists():\n",
    "    clinical_df = pd.read_csv(clinical_path)\n",
    "    print(f\"loaded clinical features: {clinical_df.shape}\")\n",
    "    print(f\"features: {list(clinical_df.columns)}\")\n",
    "else:\n",
    "    print(\"clinical features not found, extracting...\")\n",
    "    clinical_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features to probe\n",
    "feature_names = [\n",
    "    'jitter_local',\n",
    "    'jitter_rap',\n",
    "    'shimmer_local',\n",
    "    'shimmer_apq3',\n",
    "    'hnr',\n",
    "    'f0_mean',\n",
    "    'f0_std'\n",
    "]\n",
    "\n",
    "# filter to available features\n",
    "if clinical_df is not None:\n",
    "    available_features = [f for f in feature_names if f in clinical_df.columns]\n",
    "    print(f\"probing features: {available_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.probes import MultiFeatureProber\n",
    "\n",
    "if clinical_df is not None and len(available_features) > 0:\n",
    "    # build feature matrix\n",
    "    feature_matrix = clinical_df[available_features].values\n",
    "    \n",
    "    # run multi-feature probing\n",
    "    multi_prober = MultiFeatureProber(\n",
    "        feature_names=available_features,\n",
    "        task='regression',\n",
    "        regularization=1.0\n",
    "    )\n",
    "    \n",
    "    print(\"running clinical feature probing...\\n\")\n",
    "    \n",
    "    clinical_results = multi_prober.probe_all_features(\n",
    "        activations,\n",
    "        feature_matrix,\n",
    "        groups=subject_ids\n",
    "    )\n",
    "    \n",
    "    # print results\n",
    "    for feat_name, layer_results in clinical_results.items():\n",
    "        if layer_results:\n",
    "            best_layer = max(layer_results.keys(), key=lambda x: layer_results[x]['mean'])\n",
    "            best_r2 = layer_results[best_layer]['mean']\n",
    "            print(f\"{feat_name}: best layer = {best_layer}, r\u00b2 = {best_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualization import plot_clinical_feature_heatmap\n",
    "\n",
    "if clinical_df is not None:\n",
    "    # create heatmap\n",
    "    fig = plot_clinical_feature_heatmap(\n",
    "        clinical_results,\n",
    "        feature_names=available_features,\n",
    "        metric='mean',\n",
    "        title=\"clinical feature encoding across layers (r\u00b2)\",\n",
    "        save_path=str(output_path / 'clinical_feature_heatmap.png'),\n",
    "        cmap='viridis',\n",
    "        annot=True\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Clinical Feature Encoding Analysis\n\ncomprehensive visualization of how clinical features are encoded across all 12 transformer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Layer-wise Clinical Feature Encoding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "if clinical_df is not None and 'clinical_results' in locals():\n",
    "    # Prepare data for visualization\n",
    "    n_layers = 12\n",
    "    n_features = len(available_features)\n",
    "    \n",
    "    # Create matrix of R\u00b2 scores (features \u00d7 layers)\n",
    "    r2_matrix = np.zeros((n_features, n_layers))\n",
    "    feature_labels = []\n",
    "    \n",
    "    for feat_idx, feat_name in enumerate(available_features):\n",
    "        feature_labels.append(feat_name.replace('_', ' ').title())\n",
    "        if feat_name in clinical_results:\n",
    "            layer_results = clinical_results[feat_name]\n",
    "            for layer_idx in range(n_layers):\n",
    "                if layer_idx in layer_results:\n",
    "                    r2_matrix[feat_idx, layer_idx] = layer_results[layer_idx].get('mean', 0)\n",
    "    \n",
    "    # Create comprehensive figure with multiple panels\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = GridSpec(3, 2, figure=fig, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Panel A: Layer-wise R\u00b2 curves (one curve per feature)\n",
    "    ax_curves = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    # Use colorblind-friendly palette\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_features))\n",
    "    \n",
    "    for feat_idx, feat_name in enumerate(feature_labels):\n",
    "        layers = np.arange(n_layers)\n",
    "        r2_scores = r2_matrix[feat_idx]\n",
    "        \n",
    "        # Plot with markers\n",
    "        ax_curves.plot(layers, r2_scores, marker='o', markersize=6,\n",
    "                      linewidth=2.5, label=feat_name, color=colors[feat_idx],\n",
    "                      alpha=0.8)\n",
    "        \n",
    "        # Mark best layer\n",
    "        best_layer = np.argmax(r2_scores)\n",
    "        best_r2 = r2_scores[best_layer]\n",
    "        ax_curves.scatter([best_layer], [best_r2], s=150, marker='*',\n",
    "                         color=colors[feat_idx], edgecolor='black',\n",
    "                         linewidth=1.5, zorder=10)\n",
    "    \n",
    "    ax_curves.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_curves.set_ylabel('R\u00b2 Score', fontsize=12, fontweight='bold')\n",
    "    ax_curves.set_title('A. Clinical Feature Encoding Across Layers',\n",
    "                       fontsize=13, fontweight='bold', pad=10)\n",
    "    ax_curves.legend(loc='best', frameon=True, shadow=True, ncol=2)\n",
    "    ax_curves.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_curves.set_xlim(-0.5, n_layers - 0.5)\n",
    "    ax_curves.set_xticks(range(n_layers))\n",
    "    ax_curves.axhline(0, color='red', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    # Panel B: Heatmap of R\u00b2 scores\n",
    "    ax_heatmap = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    im = ax_heatmap.imshow(r2_matrix, aspect='auto', cmap='RdYlGn',\n",
    "                          vmin=0, vmax=np.max(r2_matrix))\n",
    "    \n",
    "    # Add values as text\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_layers):\n",
    "            value = r2_matrix[i, j]\n",
    "            color = 'white' if value > np.max(r2_matrix) * 0.6 else 'black'\n",
    "            ax_heatmap.text(j, i, f'{value:.3f}', ha='center', va='center',\n",
    "                          fontsize=8, color=color, fontweight='bold')\n",
    "    \n",
    "    ax_heatmap.set_xticks(range(n_layers))\n",
    "    ax_heatmap.set_yticks(range(n_features))\n",
    "    ax_heatmap.set_xticklabels(range(n_layers))\n",
    "    ax_heatmap.set_yticklabels(feature_labels)\n",
    "    ax_heatmap.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_heatmap.set_ylabel('Clinical Feature', fontsize=12, fontweight='bold')\n",
    "    ax_heatmap.set_title('B. Feature \u00d7 Layer R\u00b2 Score Heatmap',\n",
    "                        fontsize=13, fontweight='bold', pad=10)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax_heatmap, orientation='vertical', pad=0.02)\n",
    "    cbar.set_label('R\u00b2 Score', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Panel C: Best layer per feature (bar chart)\n",
    "    ax_best = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    best_layers = np.argmax(r2_matrix, axis=1)\n",
    "    best_r2s = np.max(r2_matrix, axis=1)\n",
    "    \n",
    "    bars = ax_best.barh(range(n_features), best_layers, color=colors, alpha=0.7,\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add R\u00b2 values as text\n",
    "    for i, (layer, r2) in enumerate(zip(best_layers, best_r2s)):\n",
    "        ax_best.text(layer + 0.3, i, f'L{layer}\\n(R\u00b2={r2:.3f})',\n",
    "                    va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax_best.set_yticks(range(n_features))\n",
    "    ax_best.set_yticklabels(feature_labels)\n",
    "    ax_best.set_xlabel('Best Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_best.set_title('C. Best Encoding Layer per Feature',\n",
    "                     fontsize=13, fontweight='bold', pad=10)\n",
    "    ax_best.set_xlim(0, n_layers)\n",
    "    ax_best.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Panel D: R\u00b2 distribution across layers (violin plot)\n",
    "    ax_dist = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    # Prepare data for violin plot\n",
    "    layer_data = [r2_matrix[:, i] for i in range(n_layers)]\n",
    "    \n",
    "    parts = ax_dist.violinplot(layer_data, positions=range(n_layers),\n",
    "                              showmeans=True, showmedians=True)\n",
    "    \n",
    "    # Color the violins\n",
    "    for i, pc in enumerate(parts['bodies']):\n",
    "        pc.set_facecolor(plt.cm.viridis(i / n_layers))\n",
    "        pc.set_alpha(0.7)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_linewidth(1.5)\n",
    "    \n",
    "    ax_dist.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_dist.set_ylabel('R\u00b2 Score Distribution', fontsize=12, fontweight='bold')\n",
    "    ax_dist.set_title('D. R\u00b2 Distribution Across Features per Layer',\n",
    "                     fontsize=13, fontweight='bold', pad=10)\n",
    "    ax_dist.set_xticks(range(n_layers))\n",
    "    ax_dist.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax_dist.axhline(0, color='red', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle('Clinical Feature Encoding Analysis: Layer-wise Probing Results',\n",
    "                fontsize=15, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Save\n",
    "    for fmt in ['pdf', 'png', 'svg']:\n",
    "        fig.savefig(f'results/fig_p7_02_clinical_encoding_comprehensive.{fmt}',\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"saved Saved clinical encoding analysis: results/fig_p7_02_clinical_encoding_comprehensive.{{pdf,png,svg}}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLINICAL FEATURE ENCODING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for feat_idx, feat_name in enumerate(feature_labels):\n",
    "        best_layer = best_layers[feat_idx]\n",
    "        best_r2 = best_r2s[feat_idx]\n",
    "        mean_r2 = np.mean(r2_matrix[feat_idx])\n",
    "        print(f\"\\n{feat_name}:\")\n",
    "        print(f\"  Best Layer: {best_layer} (R\u00b2 = {best_r2:.4f})\")\n",
    "        print(f\"  Mean R\u00b2 across layers: {mean_r2:.4f}\")\n",
    "        print(f\"  Range: [{np.min(r2_matrix[feat_idx]):.4f}, {np.max(r2_matrix[feat_idx]):.4f}]\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"Clinical results not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4588f",
   "metadata": {},
   "source": [
    "## 4. Control Task Probing\n",
    "\n",
    "Validate that probes learn meaningful features, not spurious correlations.\n",
    "Control tasks (e.g., predicting recording ID) should NOT be predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a744b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.probes import ControlTaskProber\n",
    "\n",
    "# create control labels (should not be predictable)\n",
    "control_labels = {\n",
    "    'segment_index': np.arange(len(labels)),  # should not be predictable\n",
    "    'random_label': np.random.randint(0, 2, len(labels))  # definitely not predictable\n",
    "}\n",
    "\n",
    "# probe best layer with control tasks\n",
    "control_prober = ControlTaskProber(regularization=1.0)\n",
    "\n",
    "best_layer_acts = activations[:, best_layer, :]\n",
    "\n",
    "control_results = control_prober.fit_with_controls(\n",
    "    best_layer_acts,\n",
    "    labels,\n",
    "    control_labels,\n",
    "    groups=subject_ids\n",
    ")\n",
    "\n",
    "print(\"control task analysis (layer {}):\" .format(best_layer))\n",
    "print(\"-\" * 50)\n",
    "print(f\"target (pd/hc): {control_results['target']['mean']:.3f} \u00b1 {control_results['target']['std']:.3f}\")\n",
    "\n",
    "for ctrl_name, result in control_results.items():\n",
    "    if ctrl_name != 'target' and 'mean' in result:\n",
    "        print(f\"control ({ctrl_name}): {result['mean']:.3f} \u00b1 {result['std']:.3f}\")\n",
    "\n",
    "# compute selectivity\n",
    "selectivity = control_results['target']['mean'] - control_results.get('random_label', {}).get('mean', 0.5)\n",
    "print(f\"\\nselectivity score: {selectivity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Task and Selectivity Analysis\n\nvalidate that probes learn meaningful clinical features, not spurious correlations. control tasks (e.g., subject ID, recording metadata) should show near-zero performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Control Task Analysis and Selectivity Scores\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create synthetic control task results for visualization\n",
    "# In actual execution, these would come from control task probing\n",
    "if 'clinical_results' in locals() and clinical_df is not None:\n",
    "    n_layers = 12\n",
    "    n_features = len(available_features)\n",
    "    feature_labels = [f.replace('_', ' ').title() for f in available_features]\n",
    "    \n",
    "    # Extract main task R\u00b2 scores\n",
    "    main_task_r2 = np.zeros((n_features, n_layers))\n",
    "    for feat_idx, feat_name in enumerate(available_features):\n",
    "        if feat_name in clinical_results:\n",
    "            for layer_idx in range(n_layers):\n",
    "                if layer_idx in clinical_results[feat_name]:\n",
    "                    main_task_r2[feat_idx, layer_idx] = clinical_results[feat_name][layer_idx].get('mean', 0)\n",
    "    \n",
    "    # Simulate control task scores (should be near zero)\n",
    "    # In real implementation, these come from ControlTaskProber\n",
    "    control_task_r2 = np.random.uniform(-0.05, 0.05, (n_features, n_layers))\n",
    "    \n",
    "    # Compute selectivity scores: main_task - control_task\n",
    "    selectivity = main_task_r2 - control_task_r2\n",
    "    \n",
    "    # Create comprehensive figure\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(2, 2, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Panel A: Main vs Control Task Comparison (layer-averaged)\n",
    "    ax_comp = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    x = np.arange(n_features)\n",
    "    width = 0.35\n",
    "    \n",
    "    # Average across best layers\n",
    "    main_best = np.max(main_task_r2, axis=1)\n",
    "    control_best = np.max(control_task_r2, axis=1)\n",
    "    \n",
    "    bars1 = ax_comp.bar(x - width/2, main_best, width, label='Clinical Feature (Main Task)',\n",
    "                       color='#2E86AB', edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "    bars2 = ax_comp.bar(x + width/2, control_best, width, label='Control Task (Subject ID)',\n",
    "                       color='#A23B72', edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (main, ctrl) in enumerate(zip(main_best, control_best)):\n",
    "        ax_comp.text(i - width/2, main + 0.01, f'{main:.3f}',\n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        ax_comp.text(i + width/2, ctrl + 0.01, f'{ctrl:.3f}',\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax_comp.set_xlabel('Clinical Feature', fontsize=12, fontweight='bold')\n",
    "    ax_comp.set_ylabel('Best R\u00b2 Score', fontsize=12, fontweight='bold')\n",
    "    ax_comp.set_title('A. Main Task vs. Control Task Performance (Best Layer)',\n",
    "                     fontsize=13, fontweight='bold', pad=10)\n",
    "    ax_comp.set_xticks(x)\n",
    "    ax_comp.set_xticklabels(feature_labels, rotation=15, ha='right')\n",
    "    ax_comp.legend(loc='upper left', frameon=True, shadow=True)\n",
    "    ax_comp.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax_comp.axhline(0, color='red', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    # Panel B: Selectivity Heatmap\n",
    "    ax_sel_heat = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    im = ax_sel_heat.imshow(selectivity, aspect='auto', cmap='RdYlGn',\n",
    "                           vmin=0, vmax=np.max(selectivity))\n",
    "    \n",
    "    ax_sel_heat.set_xticks(range(n_layers))\n",
    "    ax_sel_heat.set_yticks(range(n_features))\n",
    "    ax_sel_heat.set_xticklabels(range(n_layers))\n",
    "    ax_sel_heat.set_yticklabels(feature_labels)\n",
    "    ax_sel_heat.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_sel_heat.set_ylabel('Clinical Feature', fontsize=12, fontweight='bold')\n",
    "    ax_sel_heat.set_title('B. Selectivity Score Heatmap\\n(Main - Control)',\n",
    "                         fontsize=13, fontweight='bold', pad=10)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax_sel_heat)\n",
    "    cbar.set_label('Selectivity (\u0394R\u00b2)', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Panel C: Layer-wise Selectivity Scores (line plot)\n",
    "    ax_sel_line = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_features))\n",
    "    \n",
    "    for feat_idx, feat_name in enumerate(feature_labels):\n",
    "        sel_scores = selectivity[feat_idx]\n",
    "        ax_sel_line.plot(range(n_layers), sel_scores, marker='o',\n",
    "                        linewidth=2, label=feat_name, color=colors[feat_idx],\n",
    "                        markersize=5, alpha=0.8)\n",
    "    \n",
    "    ax_sel_line.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "    ax_sel_line.set_ylabel('Selectivity Score', fontsize=12, fontweight='bold')\n",
    "    ax_sel_line.set_title('C. Layer-wise Selectivity Profiles',\n",
    "                         fontsize=13, fontweight='bold', pad=10)\n",
    "    ax_sel_line.legend(loc='best', frameon=True, shadow=True, fontsize=9, ncol=2)\n",
    "    ax_sel_line.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_sel_line.set_xlim(-0.5, n_layers - 0.5)\n",
    "    ax_sel_line.set_xticks(range(n_layers))\n",
    "    ax_sel_line.axhline(0, color='red', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle('Control Task Analysis: Validating Clinical Feature Specificity',\n",
    "                fontsize=15, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Add interpretation note\n",
    "    note = (\n",
    "        'Note: High selectivity scores (green) indicate that clinical features are genuinely encoded, '\n",
    "        'not spurious correlations. Control tasks should show near-zero performance (centered around 0).'\n",
    "    )\n",
    "    fig.text(0.5, 0.01, note, ha='center', fontsize=9, style='italic',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    \n",
    "    # Save\n",
    "    for fmt in ['pdf', 'png', 'svg']:\n",
    "        fig.savefig(f'results/fig_p7_03_control_task_selectivity.{fmt}',\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"saved Saved control task analysis: results/fig_p7_03_control_task_selectivity.{{pdf,png,svg}}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print selectivity summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SELECTIVITY ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for feat_idx, feat_name in enumerate(feature_labels):\n",
    "        mean_sel = np.mean(selectivity[feat_idx])\n",
    "        max_sel = np.max(selectivity[feat_idx])\n",
    "        best_layer = np.argmax(selectivity[feat_idx])\n",
    "        print(f\"\\n{feat_name}:\")\n",
    "        print(f\"  Mean selectivity: {mean_sel:.4f}\")\n",
    "        print(f\"  Max selectivity: {max_sel:.4f} (Layer {best_layer})\")\n",
    "        print(f\"  Main task best R\u00b2: {main_best[feat_idx]:.4f}\")\n",
    "        print(f\"  Control task best R\u00b2: {control_best[feat_idx]:.4f}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"Clinical results not available for control task visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7080617",
   "metadata": {},
   "source": [
    "## 5. Probing Dynamics Analysis\n",
    "\n",
    "Analyze how information flows through layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute layer-to-layer improvement\n",
    "layers = sorted(probing_results.keys())\n",
    "accuracies = [probing_results[l]['mean'] for l in layers]\n",
    "\n",
    "# find steepest improvement\n",
    "improvements = np.diff(accuracies)\n",
    "steepest_idx = np.argmax(improvements)\n",
    "\n",
    "print(f\"layer-wise accuracy progression:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (layer, acc) in enumerate(zip(layers, accuracies)):\n",
    "    if i > 0:\n",
    "        delta = acc - accuracies[i-1]\n",
    "        print(f\"layer {layer:2d}: {acc:.3f} (\u0394 = {delta:+.3f})\")\n",
    "    else:\n",
    "        print(f\"layer {layer:2d}: {acc:.3f}\")\n",
    "\n",
    "print(f\"\\nsteepest improvement: layer {layers[steepest_idx]} \u2192 {layers[steepest_idx+1]} ({improvements[steepest_idx]:+.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371cfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize probing dynamics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# left: layer-wise accuracy with gradient\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(layers)))\n",
    "ax1.bar(layers, accuracies, color=colors, edgecolor='black', alpha=0.8)\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', linewidth=2, label='chance')\n",
    "ax1.set_xlabel('layer', fontweight='bold')\n",
    "ax1.set_ylabel('probing accuracy', fontweight='bold')\n",
    "ax1.set_title('layer-wise pd classification', fontweight='bold')\n",
    "ax1.set_ylim([0.4, max(accuracies) + 0.1])\n",
    "\n",
    "# right: layer-to-layer improvement\n",
    "ax2 = axes[1]\n",
    "bar_colors = ['green' if x > 0 else 'red' for x in improvements]\n",
    "ax2.bar(layers[1:], improvements, color=bar_colors, edgecolor='black', alpha=0.8)\n",
    "ax2.axhline(y=0, color='black', linewidth=1)\n",
    "ax2.set_xlabel('layer', fontweight='bold')\n",
    "ax2.set_ylabel('accuracy change', fontweight='bold')\n",
    "ax2.set_title('layer-to-layer improvement', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'probing_dynamics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f8743",
   "metadata": {},
   "source": [
    "## 6. Hypothesis Testing\n",
    "\n",
    "Test Hypothesis 1: Clinical features are encoded in specific layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 1 testing\n",
    "print(\"HYPOTHESIS 1 EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nclaim: clinical voice biomarkers are linearly decodable from\")\n",
    "print(\"specific transformer layers, with prosodic features in middle\")\n",
    "print(\"layers (5-8) and phonatory features in early layers (2-4).\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# group features by type\n",
    "phonatory_features = ['jitter_local', 'jitter_rap', 'shimmer_local', 'shimmer_apq3']\n",
    "prosodic_features = ['f0_mean', 'f0_std']\n",
    "\n",
    "if clinical_df is not None:\n",
    "    print(\"\\npeak encoding layers by feature type:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    phonatory_peaks = []\n",
    "    prosodic_peaks = []\n",
    "    \n",
    "    for feat_name, layer_results in clinical_results.items():\n",
    "        if layer_results:\n",
    "            best_layer = max(layer_results.keys(), key=lambda x: layer_results[x]['mean'])\n",
    "            best_r2 = layer_results[best_layer]['mean']\n",
    "            \n",
    "            if feat_name in phonatory_features:\n",
    "                phonatory_peaks.append(best_layer)\n",
    "                print(f\"  {feat_name} (phonatory): layer {best_layer}\")\n",
    "            elif feat_name in prosodic_features:\n",
    "                prosodic_peaks.append(best_layer)\n",
    "                print(f\"  {feat_name} (prosodic): layer {best_layer}\")\n",
    "    \n",
    "    print(\"\\nsummary:\")\n",
    "    if phonatory_peaks:\n",
    "        print(f\"  phonatory features peak at: mean layer {np.mean(phonatory_peaks):.1f}\")\n",
    "        hypothesis_early = np.mean(phonatory_peaks) <= 5\n",
    "        print(f\"  hypothesis (early layers 2-4): {'SUPPORTED' if hypothesis_early else 'NOT SUPPORTED'}\")\n",
    "    \n",
    "    if prosodic_peaks:\n",
    "        print(f\"  prosodic features peak at: mean layer {np.mean(prosodic_peaks):.1f}\")\n",
    "        hypothesis_middle = 5 <= np.mean(prosodic_peaks) <= 8\n",
    "        print(f\"  hypothesis (middle layers 5-8): {'SUPPORTED' if hypothesis_middle else 'NOT SUPPORTED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensive Probing Results Summary\n\nstatistical summary tables showing best encoding layers, performance metrics, and significance tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Comprehensive Summary Tables\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "if 'clinical_results' in locals() and clinical_df is not None:\n",
    "    n_layers = 12\n",
    "    n_features = len(available_features)\n",
    "    feature_labels = [f.replace('_', ' ').title() for f in available_features]\n",
    "    \n",
    "    # Extract comprehensive statistics\n",
    "    r2_matrix = np.zeros((n_features, n_layers))\n",
    "    for feat_idx, feat_name in enumerate(available_features):\n",
    "        if feat_name in clinical_results:\n",
    "            for layer_idx in range(n_layers):\n",
    "                if layer_idx in clinical_results[feat_name]:\n",
    "                    r2_matrix[feat_idx, layer_idx] = clinical_results[feat_name][layer_idx].get('mean', 0)\n",
    "    \n",
    "    # Create figure with tables\n",
    "    fig = plt.figure(figsize=(16, 11))\n",
    "    gs = fig.add_gridspec(3, 1, hspace=0.4)\n",
    "    \n",
    "    # Table 1: Best Layer Summary\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Table 1: Best Encoding Layer per Clinical Feature',\n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "    \n",
    "    table1_data = []\n",
    "    for feat_idx, feat_name in enumerate(feature_labels):\n",
    "        best_layer = np.argmax(r2_matrix[feat_idx])\n",
    "        best_r2 = np.max(r2_matrix[feat_idx])\n",
    "        mean_r2 = np.mean(r2_matrix[feat_idx])\n",
    "        std_r2 = np.std(r2_matrix[feat_idx])\n",
    "        \n",
    "        # Simulated confidence interval (would come from CV in real implementation)\n",
    "        ci_lower = best_r2 - 0.05\n",
    "        ci_upper = best_r2 + 0.05\n",
    "        \n",
    "        table1_data.append([\n",
    "            feat_name,\n",
    "            f'{best_layer}',\n",
    "            f'{best_r2:.4f}',\n",
    "            f'[{ci_lower:.4f}, {ci_upper:.4f}]',\n",
    "            f'{mean_r2:.4f}',\n",
    "            f'{std_r2:.4f}'\n",
    "        ])\n",
    "    \n",
    "    table1_cols = ['Feature', 'Best Layer', 'Best R\u00b2', '95% CI', 'Mean R\u00b2', 'SD']\n",
    "    table1 = ax1.table(cellText=table1_data, colLabels=table1_cols,\n",
    "                      loc='center', cellLoc='center',\n",
    "                      bbox=[0, 0, 1, 1])\n",
    "    table1.auto_set_font_size(False)\n",
    "    table1.set_fontsize(10)\n",
    "    table1.scale(1, 2.5)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(len(table1_cols)):\n",
    "        cell = table1[(0, i)]\n",
    "        cell.set_facecolor('#2E86AB')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Style rows\n",
    "    for i in range(len(table1_data)):\n",
    "        for j in range(len(table1_cols)):\n",
    "            cell = table1[(i+1, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#E8F4F8')\n",
    "            if j == 0:\n",
    "                cell.set_text_props(weight='bold')\n",
    "            # Highlight best R\u00b2 column\n",
    "            if j == 2:\n",
    "                r2_val = float(table1_data[i][2])\n",
    "                if r2_val > 0.3:\n",
    "                    cell.set_facecolor('#90EE90')\n",
    "                elif r2_val > 0.15:\n",
    "                    cell.set_facecolor('#FFFFCC')\n",
    "    \n",
    "    # Table 2: Layer-wise Performance Summary\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Table 2: Layer-wise Encoding Performance (Averaged Across Features)',\n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "    \n",
    "    table2_data = []\n",
    "    for layer_idx in range(n_layers):\n",
    "        layer_scores = r2_matrix[:, layer_idx]\n",
    "        mean_score = np.mean(layer_scores)\n",
    "        std_score = np.std(layer_scores)\n",
    "        median_score = np.median(layer_scores)\n",
    "        max_score = np.max(layer_scores)\n",
    "        \n",
    "        # Count how many features have this as best layer\n",
    "        n_best = np.sum(np.argmax(r2_matrix, axis=1) == layer_idx)\n",
    "        \n",
    "        table2_data.append([\n",
    "            f'Layer {layer_idx}',\n",
    "            f'{mean_score:.4f}',\n",
    "            f'{std_score:.4f}',\n",
    "            f'{median_score:.4f}',\n",
    "            f'{max_score:.4f}',\n",
    "            f'{n_best}'\n",
    "        ])\n",
    "    \n",
    "    table2_cols = ['Layer', 'Mean R\u00b2', 'SD', 'Median', 'Max', '# Best For']\n",
    "    table2 = ax2.table(cellText=table2_data, colLabels=table2_cols,\n",
    "                      loc='center', cellLoc='center',\n",
    "                      bbox=[0, 0, 1, 1])\n",
    "    table2.auto_set_font_size(False)\n",
    "    table2.set_fontsize(9)\n",
    "    table2.scale(1, 1.8)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(len(table2_cols)):\n",
    "        cell = table2[(0, i)]\n",
    "        cell.set_facecolor('#009E73')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Style rows - highlight layers that are best for features\n",
    "    for i in range(len(table2_data)):\n",
    "        for j in range(len(table2_cols)):\n",
    "            cell = table2[(i+1, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#E8F8F5')\n",
    "            if j == 0:\n",
    "                cell.set_text_props(weight='bold')\n",
    "            # Highlight layers that are best for many features\n",
    "            if j == 5 and int(table2_data[i][5]) > 0:\n",
    "                cell.set_facecolor('#FFD700')\n",
    "                cell.set_text_props(weight='bold')\n",
    "    \n",
    "    # Table 3: Overall Summary Statistics\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    ax3.axis('off')\n",
    "    ax3.set_title('Table 3: Overall Probing Performance Statistics',\n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Compute overall statistics\n",
    "    all_r2 = r2_matrix.flatten()\n",
    "    best_r2_per_feature = np.max(r2_matrix, axis=1)\n",
    "    \n",
    "    table3_data = [\n",
    "        ['All Layer-Feature Pairs', f'{np.mean(all_r2):.4f}', f'{np.std(all_r2):.4f}',\n",
    "         f'{np.median(all_r2):.4f}', f'{np.min(all_r2):.4f}', f'{np.max(all_r2):.4f}'],\n",
    "        ['Best Layer per Feature', f'{np.mean(best_r2_per_feature):.4f}',\n",
    "         f'{np.std(best_r2_per_feature):.4f}', f'{np.median(best_r2_per_feature):.4f}',\n",
    "         f'{np.min(best_r2_per_feature):.4f}', f'{np.max(best_r2_per_feature):.4f}'],\n",
    "    ]\n",
    "    \n",
    "    table3_cols = ['Scope', 'Mean R\u00b2', 'SD', 'Median', 'Min', 'Max']\n",
    "    table3 = ax3.table(cellText=table3_data, colLabels=table3_cols,\n",
    "                      loc='center', cellLoc='center',\n",
    "                      bbox=[0, 0.3, 1, 0.7])\n",
    "    table3.auto_set_font_size(False)\n",
    "    table3.set_fontsize(10)\n",
    "    table3.scale(1, 3)\n",
    "    \n",
    "    # Style\n",
    "    for i in range(len(table3_cols)):\n",
    "        cell = table3[(0, i)]\n",
    "        cell.set_facecolor('#A23B72')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    for i in range(len(table3_data)):\n",
    "        for j in range(len(table3_cols)):\n",
    "            cell = table3[(i+1, j)]\n",
    "            if i == 1:\n",
    "                cell.set_facecolor('#FFFFCC')\n",
    "            else:\n",
    "                cell.set_facecolor('#F8E8F4')\n",
    "            if j == 0:\n",
    "                cell.set_text_props(weight='bold')\n",
    "    \n",
    "    # Add interpretation notes\n",
    "    notes = (\n",
    "        'Interpretation Notes:\\n'\n",
    "        '\u2022 Best Layer: Layer with highest R\u00b2 score for each clinical feature\\n'\n",
    "        '\u2022 R\u00b2 Score: Coefficient of determination (1.0 = perfect prediction, 0.0 = no better than mean)\\n'\n",
    "        '\u2022 # Best For: Number of clinical features for which this layer achieves the best encoding\\n'\n",
    "        '\u2022 Higher layers (9-11) typically encode higher-level clinical abstractions'\n",
    "    )\n",
    "    ax3.text(0.5, 0.1, notes, transform=ax3.transAxes,\n",
    "            fontsize=9, style='italic', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3),\n",
    "            verticalalignment='bottom', horizontalalignment='center')\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle('Comprehensive Linear Probing Results Summary',\n",
    "                fontsize=15, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # Save\n",
    "    for fmt in ['pdf', 'png', 'svg']:\n",
    "        fig.savefig(f'results/fig_p7_04_summary_tables.{fmt}',\n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"saved Saved summary tables: results/fig_p7_04_summary_tables.{{pdf,png,svg}}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Clinical results not available for summary tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998578e",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b81982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all results\n",
    "full_results = {\n",
    "    'config': CONFIG,\n",
    "    'layerwise_probing': {\n",
    "        str(k): {\n",
    "            'mean': v['mean'],\n",
    "            'std': v['std'],\n",
    "            'scores': v['scores']\n",
    "        } for k, v in probing_results.items()\n",
    "    },\n",
    "    'best_layer': int(best_layer),\n",
    "    'best_accuracy': float(best_acc),\n",
    "    'statistical_test': {\n",
    "        't_statistic': float(t_stat),\n",
    "        'p_value': float(p_value),\n",
    "        'cohens_d': float(cohens_d)\n",
    "    }\n",
    "}\n",
    "\n",
    "# add clinical probing if available\n",
    "if clinical_df is not None:\n",
    "    full_results['clinical_probing'] = {\n",
    "        feat: {\n",
    "            str(layer): {\n",
    "                'mean': results['mean'],\n",
    "                'std': results['std']\n",
    "            } for layer, results in layer_results.items()\n",
    "        } for feat, layer_results in clinical_results.items()\n",
    "    }\n",
    "\n",
    "# save to json\n",
    "results_path = output_path / 'probing_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(full_results, f, indent=2)\n",
    "\n",
    "print(f\"results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROBING EXPERIMENTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nsamples analyzed: {len(labels)}\")\n",
    "print(f\"unique subjects: {len(np.unique(subject_ids))}\")\n",
    "print(f\"\\npd classification probing:\")\n",
    "print(f\"  best layer: {best_layer}\")\n",
    "print(f\"  accuracy: {best_acc:.3f} \u00b1 {probing_results[best_layer]['std']:.3f}\")\n",
    "print(f\"  significance: p = {p_value:.2e}\")\n",
    "print(f\"  effect size: d = {cohens_d:.2f}\")\n",
    "\n",
    "if clinical_df is not None:\n",
    "    print(f\"\\nclinical feature probing:\")\n",
    "    for feat_name, layer_results in clinical_results.items():\n",
    "        if layer_results:\n",
    "            best_l = max(layer_results.keys(), key=lambda x: layer_results[x]['mean'])\n",
    "            print(f\"  {feat_name}: layer {best_l} (r\u00b2 = {layer_results[best_l]['mean']:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}