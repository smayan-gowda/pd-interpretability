{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/pd-interpretability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -q transformers datasets librosa praat-parselmouth scipy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# project imports\n",
    "from src.interpretability.prediction_interface import (\n",
    "    InterpretablePredictionInterface,\n",
    "    InterpretablePrediction,\n",
    "    create_interpretable_interface\n",
    ")\n",
    "from src.features.clinical import ClinicalFeatureExtractor\n",
    "\n",
    "print(\"imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8660f1",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142be76",
   "metadata": {},
   "outputs": [],
   "source": "CONFIG = {\n    'project_path': '/content/drive/MyDrive/pd-interpretability',\n    'model_path': '/content/drive/MyDrive/pd-interpretability/results/checkpoints/wav2vec2_loso_20260106_014308/final_model',\n    'probing_results_path': '/content/drive/MyDrive/pd-interpretability/results/probing/probing_results.json',\n    'patching_results_path': '/content/drive/MyDrive/pd-interpretability/results/patching/patching_results.json',\n    'data_path': '/content/drive/MyDrive/pd-interpretability/data',\n    'output_path': '/content/drive/MyDrive/pd-interpretability/results/phase5_synthesis',\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n}\n\nprint(f\"using device: {CONFIG['device']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "1bbf30ad",
   "metadata": {},
   "source": [
    "## 2. Load Model and Create Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b03109",
   "metadata": {},
   "outputs": [],
   "source": "# load wav2vec2 processor\nprocessor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')\n\n# load fine-tuned model\nfrom src.models import Wav2Vec2PDClassifier\n\nmodel_path = Path(CONFIG['model_path'])\n\ntry:\n    if model_path.exists():\n        print(f\"loading fine-tuned model from {model_path}...\")\n        classifier = Wav2Vec2PDClassifier.load(model_path)\n        model = classifier.model\n        print(f\"✓ successfully loaded fine-tuned model\")\n    else:\n        raise FileNotFoundError(f\"model not found at {model_path}\")\nexcept Exception as e:\n    print(f\"⚠️ could not load fine-tuned model: {e}\")\n    print(\"falling back to base model (untrained) for demonstration\")\n    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n        'facebook/wav2vec2-base-960h',\n        num_labels=2\n    )\n\nmodel = model.to(CONFIG['device'])\nmodel.eval()\nprint(f\"model ready on {CONFIG['device']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac49d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clinical feature extractor\n",
    "clinical_extractor = ClinicalFeatureExtractor()\n",
    "print(\"clinical feature extractor ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699c361",
   "metadata": {},
   "outputs": [],
   "source": "# load precomputed analysis results\nprint(\"loading probing and patching results...\\n\")\n\nprobing_results = None\npatching_results = None\n\n# load probing results\nprobing_file = Path(CONFIG['probing_results_path'])\nif probing_file.exists():\n    with open(probing_file) as f:\n        probing_data = json.load(f)\n    \n    # extract clinical feature probing results\n    # format: {feature_name: {layer_idx: {'r2_mean': value}}}\n    if 'clinical_feature_probing' in probing_data:\n        probing_results = probing_data['clinical_feature_probing']\n        print(f\"✓ loaded probing results for {len(probing_results)} clinical features\")\n        print(f\"  features: {list(probing_results.keys())}\")\n    else:\n        print(\"⚠️ no clinical_feature_probing found in results\")\nelse:\n    print(f\"⚠️ probing results not found at {probing_file}\")\n\n# load patching results  \npatching_file = Path(CONFIG['patching_results_path'])\nif patching_file.exists():\n    with open(patching_file) as f:\n        patching_data = json.load(f)\n    \n    # extract head importance from head_patching\n    # format: {layer: head: recovery_score}\n    if 'head_patching' in patching_data and 'head_scores' in patching_data['head_patching']:\n        head_scores = patching_data['head_patching']['head_scores']\n        # convert string keys like \"0,1\" to tuples (0, 1)\n        patching_results = {}\n        for key, score in head_scores.items():\n            if ',' in str(key):\n                layer, head = map(int, str(key).split(','))\n                patching_results[(layer, head)] = score\n            elif isinstance(key, list) and len(key) == 2:\n                patching_results[tuple(key)] = score\n        print(f\"✓ loaded patching results for {len(patching_results)} attention heads\")\n        print(f\"  top head: {max(patching_results.items(), key=lambda x: x[1])}\")\n    else:\n        print(\"⚠️ no head_patching.head_scores found in results\")\nelse:\n    print(f\"⚠️ patching results not found at {patching_file}\")\n\n# identify evidence layers and key heads from results\nevidence_layers = []\nkey_heads = []\n\nif probing_results:\n    # find layers with strong clinical feature encoding (r2 > 0.5)\n    for feature, layers in probing_results.items():\n        for layer_str, metrics in layers.items():\n            layer_idx = int(layer_str)\n            r2 = metrics.get('r2_mean', 0)\n            if r2 > 0.5 and layer_idx not in evidence_layers:\n                evidence_layers.append(layer_idx)\n    evidence_layers.sort()\n    print(f\"\\nevidence layers (r² > 0.5): {evidence_layers}\")\n\nif patching_results:\n    # find heads with high recovery scores (> 0.03)\n    key_heads = [(layer, head) for (layer, head), score in patching_results.items() if score > 0.03]\n    key_heads.sort(key=lambda x: patching_results[x], reverse=True)\n    print(f\"key attention heads (recovery > 0.03): {len(key_heads)} heads\")\n    print(f\"  top 5: {key_heads[:5]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the interpretable prediction interface\n",
    "interface = create_interpretable_interface(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    clinical_extractor=clinical_extractor,\n",
    "    probing_results=probing_results,\n",
    "    patching_results=patching_results,\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "print(\"\\n=== Interpretable Prediction Interface Created ===\")\n",
    "print(f\"Evidence layers: {interface._evidence_layers}\")\n",
    "print(f\"Key attention heads: {interface._key_heads[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6be523",
   "metadata": {},
   "source": [
    "## 3. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77603818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# load some test samples\n",
    "data_path = Path(CONFIG['data_path']) / 'raw' / 'italian_pvs'\n",
    "\n",
    "test_samples = []\n",
    "\n",
    "# load a few HC samples\n",
    "hc_dir = data_path / '22 elderly healthy control'\n",
    "if hc_dir.exists():\n",
    "    for subject_dir in list(hc_dir.iterdir())[:3]:\n",
    "        if subject_dir.is_dir():\n",
    "            audio_files = list(subject_dir.glob('*.txt'))\n",
    "            if audio_files:\n",
    "                # these are actually audio files with .txt extension\n",
    "                audio_path = audio_files[0]\n",
    "                try:\n",
    "                    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                    test_samples.append({\n",
    "                        'audio': audio,\n",
    "                        'sample_rate': sr,\n",
    "                        'label': 0,\n",
    "                        'subject_id': subject_dir.name\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# load a few PD samples\n",
    "pd_dir = data_path / '28 people with parkinson\\'s disease'\n",
    "if pd_dir.exists():\n",
    "    for subgroup in pd_dir.iterdir():\n",
    "        if subgroup.is_dir():\n",
    "            for subject_dir in list(subgroup.iterdir())[:1]:\n",
    "                if subject_dir.is_dir():\n",
    "                    audio_files = list(subject_dir.glob('*.*'))\n",
    "                    if audio_files:\n",
    "                        try:\n",
    "                            audio, sr = librosa.load(audio_files[0], sr=16000)\n",
    "                            test_samples.append({\n",
    "                                'audio': audio,\n",
    "                                'sample_rate': sr,\n",
    "                                'label': 1,\n",
    "                                'subject_id': subject_dir.name\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "print(f\"loaded {len(test_samples)} test samples\")\n",
    "\n",
    "# fallback to synthetic if no real data\n",
    "if len(test_samples) == 0:\n",
    "    print(\"using synthetic test samples\")\n",
    "    test_samples = [\n",
    "        {'audio': np.random.randn(48000).astype(np.float32), 'sample_rate': 16000, 'label': i % 2, 'subject_id': f'synth_{i}'}\n",
    "        for i in range(6)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e734bb2",
   "metadata": {},
   "source": [
    "## 4. Generate Interpretable Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions\n",
    "print(\"Generating interpretable predictions...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sample in test_samples:\n",
    "    # make prediction\n",
    "    prediction = interface.predict(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        include_clinical=True\n",
    "    )\n",
    "    \n",
    "    # display results\n",
    "    true_label = 'PD' if sample['label'] == 1 else 'HC'\n",
    "    pred_label = 'PD' if prediction.pd_probability >= 0.5 else 'HC'\n",
    "    correct = '✓' if (true_label == pred_label) else '✗'\n",
    "    \n",
    "    print(f\"\\nSubject: {sample['subject_id']}\")\n",
    "    print(f\"True label: {true_label}, Predicted: {pred_label} {correct}\")\n",
    "    print(f\"PD Probability: {prediction.pd_probability:.3f}\")\n",
    "    print(f\"Confidence: {prediction.confidence:.3f}\")\n",
    "    \n",
    "    print(\"\\nTop Feature Contributions:\")\n",
    "    for feat, score in prediction.get_top_features(3):\n",
    "        print(f\"  • {feat}: {score:+.3f}\")\n",
    "    \n",
    "    if prediction.clinical_features:\n",
    "        print(\"\\nKey Clinical Features:\")\n",
    "        for feat in ['jitter_local', 'shimmer_local', 'hnr_mean', 'f0_mean']:\n",
    "            if feat in prediction.clinical_features:\n",
    "                val = prediction.clinical_features[feat]\n",
    "                if not np.isnan(val):\n",
    "                    print(f\"  • {feat}: {val:.4f}\")\n",
    "    \n",
    "    print(f\"\\nEvidence Layers: {prediction.evidence_layers[:5]}\")\n",
    "    print(f\"Key Heads: {prediction.key_attention_heads[:3]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99a16c",
   "metadata": {},
   "source": [
    "## 5. Examine Full Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full JSON output for one sample\n",
    "if test_samples:\n",
    "    sample = test_samples[0]\n",
    "    prediction = interface.predict(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        include_clinical=True\n",
    "    )\n",
    "    \n",
    "    print(\"Full Prediction Output (JSON format):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(prediction.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84e327",
   "metadata": {},
   "source": [
    "## 6. Generate Natural Language Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate human-readable explanation\n",
    "if test_samples:\n",
    "    sample = test_samples[0]\n",
    "    \n",
    "    explanation = interface.explain_prediction(\n",
    "        audio=sample['audio'],\n",
    "        sample_rate=sample['sample_rate'],\n",
    "        format='text'\n",
    "    )\n",
    "    \n",
    "    print(\"Natural Language Explanation:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown format explanation\n",
    "if test_samples:\n",
    "    explanation_md = interface.explain_prediction(\n",
    "        audio=test_samples[0]['audio'],\n",
    "        sample_rate=test_samples[0]['sample_rate'],\n",
    "        format='markdown'\n",
    "    )\n",
    "    \n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(explanation_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5040a4",
   "metadata": {},
   "source": [
    "## 7. Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2690028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch prediction\n",
    "audio_list = [s['audio'] for s in test_samples]\n",
    "\n",
    "predictions = interface.batch_predict(\n",
    "    audio_list=audio_list,\n",
    "    sample_rate=16000,\n",
    "    include_clinical=True,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(predictions)} predictions\")\n",
    "\n",
    "# summary statistics\n",
    "probs = [p.pd_probability for p in predictions]\n",
    "confs = [p.confidence for p in predictions]\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Mean PD probability: {np.mean(probs):.3f}\")\n",
    "print(f\"  Mean confidence: {np.mean(confs):.3f}\")\n",
    "print(f\"  Predicted as PD: {sum(1 for p in probs if p >= 0.5)}\")\n",
    "print(f\"  Predicted as HC: {sum(1 for p in probs if p < 0.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be04c6",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f29b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all predictions\n",
    "output_dir = Path(CONFIG['project_path']) / 'results' / 'phase5_synthesis'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save individual predictions\n",
    "for sample, prediction in zip(test_samples, predictions):\n",
    "    prediction.metadata['subject_id'] = sample['subject_id']\n",
    "    prediction.metadata['true_label'] = sample['label']\n",
    "    \n",
    "    interface.save_prediction(\n",
    "        prediction,\n",
    "        output_dir / f\"{sample['subject_id']}_prediction.json\"\n",
    "    )\n",
    "\n",
    "# save summary\n",
    "summary = {\n",
    "    'n_samples': len(predictions),\n",
    "    'mean_pd_probability': float(np.mean(probs)),\n",
    "    'mean_confidence': float(np.mean(confs)),\n",
    "    'n_predicted_pd': sum(1 for p in probs if p >= 0.5),\n",
    "    'n_predicted_hc': sum(1 for p in probs if p < 0.5)\n",
    "}\n",
    "\n",
    "with open(output_dir / 'prediction_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea92da",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **Interpretable Prediction Interface**, which:\n",
    "\n",
    "1. **Synthesizes** all mechanistic interpretability analyses into a single interface\n",
    "2. **Produces predictions** with probability, confidence, and explanations\n",
    "3. **Identifies** which clinical features (jitter, shimmer, HNR) drive predictions\n",
    "4. **Reveals** which transformer layers encode PD-relevant information\n",
    "5. **Highlights** key attention heads with causal importance\n",
    "\n",
    "### Output Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"pd_probability\": 0.87,\n",
    "    \"feature_contributions\": {\n",
    "        \"jitter_elevated\": 0.34,\n",
    "        \"hnr_reduced\": 0.28,\n",
    "        \"f0_unstable\": 0.21\n",
    "    },\n",
    "    \"evidence_layers\": [3, 4, 7],\n",
    "    \"key_attention_heads\": [[3, 4], [4, 2], [7, 8]]\n",
    "}\n",
    "```\n",
    "\n",
    "This enables **transparent, explainable** PD detection from speech."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}