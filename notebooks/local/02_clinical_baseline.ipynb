{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff19821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Volumes/usb drive/pd-interpretability\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneGroupOut, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from src.data.datasets import ItalianPVSDataset\n",
    "from src.features.clinical import ClinicalFeatureExtractor, get_clinical_feature_names\n",
    "\n",
    "print(f\"project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2083dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module reloaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Force reload of clinical features module to pick up the fix\n",
    "import importlib\n",
    "import src.features.clinical\n",
    "importlib.reload(src.features.clinical)\n",
    "from src.features.clinical import ClinicalFeatureExtractor\n",
    "print(\"Module reloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523d4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "DATA_ROOT = project_root / 'data'\n",
    "RAW_DATA = DATA_ROOT / 'raw'\n",
    "CLINICAL_FEATURES_DIR = DATA_ROOT / 'clinical_features'\n",
    "RESULTS_DIR = project_root / 'results'\n",
    "\n",
    "CLINICAL_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb20ca",
   "metadata": {},
   "source": [
    "## 1. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b10596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded: 831 samples\n",
      "subjects: 61\n",
      "class distribution: 394 hc, 437 pd\n"
     ]
    }
   ],
   "source": [
    "italian_pvs_path = RAW_DATA / 'italian_pvs'\n",
    "\n",
    "dataset = ItalianPVSDataset(\n",
    "    root_dir=str(italian_pvs_path),\n",
    "    task=None,\n",
    "    max_duration=10.0\n",
    ")\n",
    "\n",
    "print(f\"dataset loaded: {len(dataset)} samples\")\n",
    "\n",
    "# get sample info\n",
    "n_subjects = len(set(s['subject_id'] for s in dataset.samples))\n",
    "labels = [s['label'] for s in dataset.samples]\n",
    "n_pd = sum(labels)\n",
    "n_hc = len(labels) - n_pd\n",
    "\n",
    "print(f\"subjects: {n_subjects}\")\n",
    "print(f\"class distribution: {n_hc} hc, {n_pd} pd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74447002",
   "metadata": {},
   "source": [
    "## 2. extract clinical features for all samples\n",
    "\n",
    "extracting jitter, shimmer, hnr, and f0 statistics using parselmouth (praat interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad74f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting clinical features for all samples...\n",
      "this may take several minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting features: 100%|██████████| 831/831 [05:20<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracted features for 831 samples\n",
      "failed: 0 samples\n",
      "saved to /Volumes/usb drive/pd-interpretability/data/clinical_features/italian_pvs_features.csv\n"
     ]
    }
   ],
   "source": [
    "# check if features already extracted\n",
    "features_csv_path = CLINICAL_FEATURES_DIR / 'italian_pvs_features.csv'\n",
    "\n",
    "if features_csv_path.exists():\n",
    "    print(f\"loading existing features from {features_csv_path}\")\n",
    "    features_df = pd.read_csv(features_csv_path)\n",
    "    print(f\"loaded {len(features_df)} samples\")\n",
    "else:\n",
    "    print(\"extracting clinical features for all samples...\")\n",
    "    print(\"this may take several minutes.\")\n",
    "    \n",
    "    extractor = ClinicalFeatureExtractor(\n",
    "        f0_min=75.0,\n",
    "        f0_max=600.0\n",
    "    )\n",
    "    \n",
    "    features_list = []\n",
    "    failed_samples = []\n",
    "    \n",
    "    for i in tqdm(range(len(dataset)), desc=\"extracting features\"):\n",
    "        sample = dataset.samples[i]\n",
    "        \n",
    "        try:\n",
    "            features = extractor.extract(str(sample['path']))\n",
    "            \n",
    "            features['sample_idx'] = i\n",
    "            features['path'] = str(sample['path'])\n",
    "            features['subject_id'] = sample['subject_id']\n",
    "            features['label'] = sample['label']\n",
    "            features['diagnosis'] = 'pd' if sample['label'] == 1 else 'hc'\n",
    "            \n",
    "            features_list.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_samples.append((i, str(e)))\n",
    "    \n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    \n",
    "    print(f\"\\nextracted features for {len(features_df)} samples\")\n",
    "    print(f\"failed: {len(failed_samples)} samples\")\n",
    "    \n",
    "    if failed_samples:\n",
    "        print(f\"first 5 failures: {failed_samples[:5]}\")\n",
    "    \n",
    "    # save to csv\n",
    "    features_df.to_csv(features_csv_path, index=False)\n",
    "    print(f\"saved to {features_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de53c6f",
   "metadata": {},
   "outputs": [],
   "source": "# feature summary\nclinical_feature_cols = [\n    'f0_mean', 'f0_std', 'f0_min', 'f0_max', 'f0_range',\n    'jitter_local', 'jitter_rap', 'jitter_ppq5', 'jitter_ddp',\n    'shimmer_local', 'shimmer_apq3', 'shimmer_apq5', 'shimmer_apq11', 'shimmer_dda',\n    'hnr_mean', 'hnr_std'\n]\n\navailable_features = [f for f in clinical_feature_cols if f in features_df.columns]\n\nprint(f\"available clinical features: {len(available_features)}\")\nprint(features_df[available_features].describe().T)"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8541ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values per feature:\n",
      "shimmer_apq11    2\n",
      "dtype: int64\n",
      "\n",
      "samples after removing missing: 829 / 831\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(\"missing values per feature:\")\n",
    "missing = features_df[available_features].isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# drop rows with any missing clinical features\n",
    "features_clean = features_df.dropna(subset=available_features)\n",
    "print(f\"\\nsamples after removing missing: {len(features_clean)} / {len(features_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0e01a",
   "metadata": {},
   "source": [
    "## 3. prepare data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d396f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix shape: (829, 14)\n",
      "labels shape: (829,)\n",
      "unique subjects: 61\n",
      "class distribution: [394 435]\n"
     ]
    }
   ],
   "source": [
    "# prepare feature matrix and labels\n",
    "X = features_clean[available_features].values\n",
    "y = features_clean['label'].values\n",
    "groups = features_clean['subject_id'].values\n",
    "\n",
    "print(f\"feature matrix shape: {X.shape}\")\n",
    "print(f\"labels shape: {y.shape}\")\n",
    "print(f\"unique subjects: {len(np.unique(groups))}\")\n",
    "print(f\"class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08003b74",
   "metadata": {},
   "source": [
    "## 4. leave-one-subject-out cross-validation\n",
    "\n",
    "loso cv is the gold standard for medical ml with limited subjects.\n",
    "it ensures the model is evaluated on completely unseen subjects,\n",
    "preventing any data leakage between train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6d41fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of folds (subjects): 61\n"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print(f\"number of folds (subjects): {logo.get_n_splits(X, y, groups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de75cdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running svm with loso cv...\n",
      "\n",
      "svm accuracy: 0.824 +/- 0.209\n",
      "min: 0.000, max: 1.000\n"
     ]
    }
   ],
   "source": [
    "# svm baseline with rbf kernel\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "print(\"running svm with loso cv...\")\n",
    "svm_scores = cross_val_score(svm_pipeline, X, y, cv=logo, groups=groups, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nsvm accuracy: {svm_scores.mean():.3f} +/- {svm_scores.std():.3f}\")\n",
    "print(f\"min: {svm_scores.min():.3f}, max: {svm_scores.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77a2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running random forest with loso cv...\n",
      "\n",
      "random forest accuracy: 0.850 +/- 0.191\n",
      "min: 0.000, max: 1.000\n"
     ]
    }
   ],
   "source": [
    "# random forest baseline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"running random forest with loso cv...\")\n",
    "rf_scores = cross_val_score(rf_pipeline, X, y, cv=logo, groups=groups, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nrandom forest accuracy: {rf_scores.mean():.3f} +/- {rf_scores.std():.3f}\")\n",
    "print(f\"min: {rf_scores.min():.3f}, max: {rf_scores.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e72645a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating detailed metrics using best model...\n",
      "\n",
      "random forest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.84      0.83      0.84       394\n",
      "   parkinson       0.85      0.86      0.85       435\n",
      "\n",
      "    accuracy                           0.85       829\n",
      "   macro avg       0.85      0.85      0.85       829\n",
      "weighted avg       0.85      0.85      0.85       829\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "           predicted\n",
      "            hc    pd\n",
      "actual hc   328    66\n",
      "       pd    61   374\n"
     ]
    }
   ],
   "source": [
    "# detailed classification report using cross_val_predict\n",
    "print(\"generating detailed metrics using best model...\")\n",
    "\n",
    "best_model = svm_pipeline if svm_scores.mean() > rf_scores.mean() else rf_pipeline\n",
    "best_name = 'svm' if svm_scores.mean() > rf_scores.mean() else 'random forest'\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X, y, cv=logo, groups=groups)\n",
    "\n",
    "print(f\"\\n{best_name} classification report:\")\n",
    "print(classification_report(y, y_pred, target_names=['healthy', 'parkinson']))\n",
    "\n",
    "print(\"\\nconfusion matrix:\")\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(f\"           predicted\")\n",
    "print(f\"            hc    pd\")\n",
    "print(f\"actual hc  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "print(f\"       pd  {cm[1,0]:4d}  {cm[1,1]:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c8674",
   "metadata": {},
   "source": [
    "## 5. per-subject analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cb474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-subject accuracy distribution:\n",
      "  mean: 0.850\n",
      "  median: 0.875\n",
      "  subjects with 100% accuracy: 21\n",
      "  subjects with 0% accuracy: 1\n",
      "\n",
      "accuracy by diagnosis:\n",
      "               mean       std       min  max\n",
      "diagnosis                                   \n",
      "hc         0.844205  0.212955  0.000000  1.0\n",
      "pd         0.858271  0.161247  0.285714  1.0\n"
     ]
    }
   ],
   "source": [
    "# analyze per-subject accuracy\n",
    "unique_subjects = np.unique(groups)\n",
    "subject_results = []\n",
    "\n",
    "for subject in unique_subjects:\n",
    "    mask = groups == subject\n",
    "    subject_true = y[mask]\n",
    "    subject_pred = y_pred[mask]\n",
    "    \n",
    "    subject_acc = accuracy_score(subject_true, subject_pred)\n",
    "    subject_label = 'pd' if subject_true[0] == 1 else 'hc'\n",
    "    n_samples = mask.sum()\n",
    "    \n",
    "    subject_results.append({\n",
    "        'subject_id': subject,\n",
    "        'diagnosis': subject_label,\n",
    "        'n_samples': n_samples,\n",
    "        'accuracy': subject_acc,\n",
    "        'correct': int(subject_acc * n_samples),\n",
    "        'total': n_samples\n",
    "    })\n",
    "\n",
    "subject_df = pd.DataFrame(subject_results)\n",
    "\n",
    "print(\"per-subject accuracy distribution:\")\n",
    "print(f\"  mean: {subject_df['accuracy'].mean():.3f}\")\n",
    "print(f\"  median: {subject_df['accuracy'].median():.3f}\")\n",
    "print(f\"  subjects with 100% accuracy: {(subject_df['accuracy'] == 1.0).sum()}\")\n",
    "print(f\"  subjects with 0% accuracy: {(subject_df['accuracy'] == 0.0).sum()}\")\n",
    "\n",
    "print(\"\\naccuracy by diagnosis:\")\n",
    "print(subject_df.groupby('diagnosis')['accuracy'].agg(['mean', 'std', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9aae8e",
   "metadata": {},
   "source": [
    "## 6. feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1714d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importance ranking:\n",
      "      feature  importance\n",
      " shimmer_apq5    0.132821\n",
      "  shimmer_dda    0.121524\n",
      "shimmer_apq11    0.115200\n",
      " shimmer_apq3    0.102394\n",
      "shimmer_local    0.088838\n",
      "  jitter_ppq5    0.076277\n",
      " jitter_local    0.063677\n",
      "   jitter_ddp    0.057934\n",
      "   jitter_rap    0.054022\n",
      "       f0_max    0.052473\n",
      "      f0_mean    0.041560\n",
      "     f0_range    0.034807\n",
      "       f0_std    0.029296\n",
      "       f0_min    0.029178\n"
     ]
    }
   ],
   "source": [
    "# train rf on full data to get feature importance\n",
    "rf_full = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "rf_full.fit(X_scaled, y)\n",
    "\n",
    "importances = rf_full.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"feature importance ranking:\")\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbb707",
   "metadata": {},
   "source": [
    "## 7. statistical comparison: pd vs hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfac880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical comparison (pd vs hc):\n",
      "      feature    hc_mean    pd_mean      p_value  cohens_d  significant\n",
      "      f0_mean 160.742396 157.214900 1.552615e-01 -0.099071        False\n",
      "       f0_std  28.358798  16.314699 9.934741e-12 -0.474039         True\n",
      "       f0_min 104.664480 112.084145 6.084628e-03  0.191354         True\n",
      "       f0_max 327.872990 265.079022 2.020530e-07 -0.364051         True\n",
      "     f0_range 223.208510 152.994877 1.612838e-07 -0.367048         True\n",
      " jitter_local   0.013715   0.010967 1.844817e-04 -0.260806         True\n",
      "   jitter_rap   0.006565   0.004915 5.828475e-06 -0.317014         True\n",
      "  jitter_ppq5   0.007286   0.004994 2.053376e-10 -0.444103         True\n",
      "   jitter_ddp   0.019694   0.014746 5.828475e-06 -0.317014         True\n",
      "shimmer_local   0.086921   0.050745 1.929831e-28 -0.792726         True\n",
      " shimmer_apq3   0.039901   0.018900 6.362333e-41 -0.969389         True\n",
      " shimmer_apq5   0.053709   0.025031 7.443816e-41 -0.968453         True\n",
      "shimmer_apq11   0.083906   0.045621 1.327847e-31 -0.841674         True\n",
      "  shimmer_dda   0.119702   0.056699 6.362333e-41 -0.969389         True\n",
      "\n",
      "significant features (p < 0.05): 13 / 14\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stat_results = []\n",
    "\n",
    "for feature in available_features:\n",
    "    hc_values = features_clean[features_clean['label'] == 0][feature]\n",
    "    pd_values = features_clean[features_clean['label'] == 1][feature]\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(hc_values, pd_values)\n",
    "    \n",
    "    # cohen's d effect size\n",
    "    pooled_std = np.sqrt((hc_values.std()**2 + pd_values.std()**2) / 2)\n",
    "    cohens_d = (pd_values.mean() - hc_values.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    stat_results.append({\n",
    "        'feature': feature,\n",
    "        'hc_mean': hc_values.mean(),\n",
    "        'hc_std': hc_values.std(),\n",
    "        'pd_mean': pd_values.mean(),\n",
    "        'pd_std': pd_values.std(),\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_val,\n",
    "        'cohens_d': cohens_d,\n",
    "        'significant': p_val < 0.05\n",
    "    })\n",
    "\n",
    "stat_df = pd.DataFrame(stat_results)\n",
    "\n",
    "print(\"statistical comparison (pd vs hc):\")\n",
    "print(stat_df[['feature', 'hc_mean', 'pd_mean', 'p_value', 'cohens_d', 'significant']].to_string(index=False))\n",
    "\n",
    "n_sig = stat_df['significant'].sum()\n",
    "print(f\"\\nsignificant features (p < 0.05): {n_sig} / {len(stat_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8fb28",
   "metadata": {},
   "source": [
    "## 8. save baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b623d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline results saved to /Volumes/usb drive/pd-interpretability/results/clinical_baseline_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "baseline_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'dataset': 'italian_pvs',\n",
    "    'n_samples': len(features_clean),\n",
    "    'n_subjects': len(np.unique(groups)),\n",
    "    'n_features': len(available_features),\n",
    "    'features_used': available_features,\n",
    "    'cv_method': 'leave_one_subject_out',\n",
    "    'n_folds': logo.get_n_splits(X, y, groups),\n",
    "    'svm': {\n",
    "        'accuracy_mean': float(svm_scores.mean()),\n",
    "        'accuracy_std': float(svm_scores.std()),\n",
    "        'accuracy_min': float(svm_scores.min()),\n",
    "        'accuracy_max': float(svm_scores.max()),\n",
    "        'per_fold_scores': svm_scores.tolist()\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'accuracy_mean': float(rf_scores.mean()),\n",
    "        'accuracy_std': float(rf_scores.std()),\n",
    "        'accuracy_min': float(rf_scores.min()),\n",
    "        'accuracy_max': float(rf_scores.max()),\n",
    "        'per_fold_scores': rf_scores.tolist()\n",
    "    },\n",
    "    'best_model': best_name,\n",
    "    'feature_importance': importance_df.to_dict('records'),\n",
    "    'statistical_comparison': stat_df.to_dict('records')\n",
    "}\n",
    "\n",
    "# save results\n",
    "baseline_path = RESULTS_DIR / 'clinical_baseline_results.json'\n",
    "with open(baseline_path, 'w') as f:\n",
    "    json.dump(baseline_results, f, indent=2)\n",
    "\n",
    "print(f\"baseline results saved to {baseline_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f83f6bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject results saved to /Volumes/usb drive/pd-interpretability/results/clinical_baseline_subjects.csv\n"
     ]
    }
   ],
   "source": [
    "# save subject-level results\n",
    "subject_results_path = RESULTS_DIR / 'clinical_baseline_subjects.csv'\n",
    "subject_df.to_csv(subject_results_path, index=False)\n",
    "print(f\"subject results saved to {subject_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8245c7",
   "metadata": {},
   "source": [
    "## 9. summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b8b8f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 2: CLINICAL BASELINE - SUMMARY\n",
      "============================================================\n",
      "\n",
      "dataset: italian pvs\n",
      "samples: 829\n",
      "subjects: 61\n",
      "features: 14 clinical biomarkers\n",
      "\n",
      "cross-validation: leave-one-subject-out (61 folds)\n",
      "\n",
      "BASELINE RESULTS:\n",
      "  svm (rbf):       82.4% +/- 20.9%\n",
      "  random forest:   85.0% +/- 19.1%\n",
      "\n",
      "target range: 70-85%\n",
      "status: WITHIN TARGET RANGE\n",
      "\n",
      "top 5 most important features:\n",
      "  shimmer_apq5: 0.1328\n",
      "  shimmer_dda: 0.1215\n",
      "  shimmer_apq11: 0.1152\n",
      "  shimmer_apq3: 0.1024\n",
      "  shimmer_local: 0.0888\n",
      "\n",
      "significant features (p < 0.05): 13 / 14\n",
      "\n",
      "phase 2 complete. ready to proceed to phase 3 (wav2vec2 fine-tuning).\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: CLINICAL BASELINE - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\ndataset: italian pvs\")\n",
    "print(f\"samples: {len(features_clean)}\")\n",
    "print(f\"subjects: {len(np.unique(groups))}\")\n",
    "print(f\"features: {len(available_features)} clinical biomarkers\")\n",
    "print(f\"\\ncross-validation: leave-one-subject-out ({logo.get_n_splits(X, y, groups)} folds)\")\n",
    "print(f\"\\nBASELINE RESULTS:\")\n",
    "print(f\"  svm (rbf):       {svm_scores.mean()*100:.1f}% +/- {svm_scores.std()*100:.1f}%\")\n",
    "print(f\"  random forest:   {rf_scores.mean()*100:.1f}% +/- {rf_scores.std()*100:.1f}%\")\n",
    "print(f\"\\ntarget range: 70-85%\")\n",
    "\n",
    "best_acc = max(svm_scores.mean(), rf_scores.mean()) * 100\n",
    "if 70 <= best_acc <= 85:\n",
    "    print(f\"status: WITHIN TARGET RANGE\")\n",
    "elif best_acc > 85:\n",
    "    print(f\"status: ABOVE TARGET (excellent clinical features)\")\n",
    "else:\n",
    "    print(f\"status: BELOW TARGET (may need feature engineering)\")\n",
    "\n",
    "print(f\"\\ntop 5 most important features:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\nsignificant features (p < 0.05): {n_sig} / {len(stat_df)}\")\n",
    "print(\"\\nphase 2 complete. ready to proceed to phase 3 (wav2vec2 fine-tuning).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}