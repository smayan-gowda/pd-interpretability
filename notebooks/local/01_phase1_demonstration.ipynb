{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phase 1 demonstration: data infrastructure\n",
    "\n",
    "comprehensive demonstration of phase 1 implementation including:\n",
    "- dataset loading and preprocessing\n",
    "- clinical feature extraction\n",
    "- subject-wise data splitting\n",
    "- data quality validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data import (\n",
    "    ItalianPVSDataset,\n",
    "    MDVRKCLDataset,\n",
    "    ArkansasDataset,\n",
    "    AudioPreprocessor,\n",
    "    load_audio\n",
    ")\n",
    "\n",
    "from src.features import (\n",
    "    ClinicalFeatureExtractor,\n",
    "    extract_clinical_features,\n",
    "    get_clinical_feature_names,\n",
    "    get_pd_discriminative_features\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. dataset loading\n",
    "\n",
    "demonstration of loading pd voice datasets with proper configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = project_root / 'data' / 'raw'\n",
    "\n",
    "italian_pvs_path = data_root / 'italian_pvs'\n",
    "mdvr_kcl_path = data_root / 'mdvr_kcl'\n",
    "arkansas_path = data_root / 'arkansas'\n",
    "\n",
    "if italian_pvs_path.exists():\n",
    "    dataset = ItalianPVSDataset(\n",
    "        root_dir=italian_pvs_path,\n",
    "        task='vowel_a',\n",
    "        target_sr=16000,\n",
    "        max_duration=10.0,\n",
    "        normalize_audio=True\n",
    "    )\n",
    "    \n",
    "    print(f\"dataset loaded: {len(dataset)} samples\")\n",
    "    print(f\"subjects: {dataset.get_subject_count()}\")\n",
    "    print(f\"label distribution: {dataset.get_label_distribution()}\")\n",
    "    print(f\"task distribution: {dataset.get_task_distribution()}\")\n",
    "else:\n",
    "    print(f\"italian pvs dataset not found at {italian_pvs_path}\")\n",
    "    print(\"download from: ieee dataport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. sample inspection\n",
    "\n",
    "examine individual samples to verify correct loading and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists():\n",
    "    sample = dataset[0]\n",
    "    \n",
    "    print(\"sample structure:\")\n",
    "    for key, value in sample.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"  {key}: tensor shape {value.shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    waveform = sample['input_values']\n",
    "    \n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(waveform.numpy()[:5000])\n",
    "    plt.title(f\"audio waveform - {sample['diagnosis']} subject\")\n",
    "    plt.xlabel('sample')\n",
    "    plt.ylabel('amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. subject-wise splitting\n",
    "\n",
    "demonstrate proper subject-wise train/val/test splitting to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists():\n",
    "    train_ds, val_ds, test_ds = dataset.get_subject_split(\n",
    "        test_size=0.2,\n",
    "        val_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=True\n",
    "    )\n",
    "    \n",
    "    print(f\"split sizes:\")\n",
    "    print(f\"  train: {len(train_ds)} samples\")\n",
    "    print(f\"  val: {len(val_ds)} samples\")\n",
    "    print(f\"  test: {len(test_ds)} samples\")\n",
    "    \n",
    "    train_subjects = set(dataset[i]['subject_id'] for i in train_ds.indices)\n",
    "    val_subjects = set(dataset[i]['subject_id'] for i in val_ds.indices)\n",
    "    test_subjects = set(dataset[i]['subject_id'] for i in test_ds.indices)\n",
    "    \n",
    "    print(f\"\\nsubject counts:\")\n",
    "    print(f\"  train: {len(train_subjects)} subjects\")\n",
    "    print(f\"  val: {len(val_subjects)} subjects\")\n",
    "    print(f\"  test: {len(test_subjects)} subjects\")\n",
    "    \n",
    "    overlap = (train_subjects & val_subjects) | (train_subjects & test_subjects) | (val_subjects & test_subjects)\n",
    "    print(f\"\\nsubject overlap: {len(overlap)} (should be 0)\")\n",
    "    \n",
    "    train_labels = [dataset[i]['label'] for i in train_ds.indices]\n",
    "    val_labels = [dataset[i]['label'] for i in val_ds.indices]\n",
    "    test_labels = [dataset[i]['label'] for i in test_ds.indices]\n",
    "    \n",
    "    print(f\"\\nlabel distribution:\")\n",
    "    print(f\"  train: {sum(train_labels)}/{len(train_labels)} pd ({sum(train_labels)/len(train_labels)*100:.1f}%)\")\n",
    "    print(f\"  val: {sum(val_labels)}/{len(val_labels)} pd ({sum(val_labels)/len(val_labels)*100:.1f}%)\")\n",
    "    print(f\"  test: {sum(test_labels)}/{len(test_labels)} pd ({sum(test_labels)/len(test_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. clinical feature extraction\n",
    "\n",
    "extract clinical voice biomarkers using parselmouth/praat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists():\n",
    "    extractor = ClinicalFeatureExtractor(\n",
    "        f0_min=75.0,\n",
    "        f0_max=600.0\n",
    "    )\n",
    "    \n",
    "    sample_path = dataset.samples[0]['path']\n",
    "    \n",
    "    features = extractor.extract(sample_path)\n",
    "    \n",
    "    print(\"extracted clinical features:\")\n",
    "    for name, value in features.items():\n",
    "        if not np.isnan(value):\n",
    "            print(f\"  {name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {name}: nan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. batch clinical feature extraction\n",
    "\n",
    "extract features from all samples and analyze distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists():\n",
    "    audio_paths = [s['path'] for s in dataset.samples[:50]]\n",
    "    labels = [s['label'] for s in dataset.samples[:50]]\n",
    "    \n",
    "    from src.features import batch_extract_features\n",
    "    \n",
    "    features_list = batch_extract_features(\n",
    "        audio_paths,\n",
    "        f0_min=75.0,\n",
    "        f0_max=600.0,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    features_df = pd.DataFrame([f for f in features_list if f is not None])\n",
    "    features_df['label'] = labels[:len(features_df)]\n",
    "    \n",
    "    print(f\"\\nfeature matrix shape: {features_df.shape}\")\n",
    "    print(f\"\\nfeature summary:\")\n",
    "    print(features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. clinical feature visualization\n",
    "\n",
    "visualize distribution of clinical features for pd vs healthy controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists() and len(features_df) > 0:\n",
    "    discriminative_features = get_pd_discriminative_features()\n",
    "    \n",
    "    available_features = [f for f in discriminative_features if f in features_df.columns]\n",
    "    \n",
    "    if len(available_features) > 0:\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(available_features[:8]):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            hc_vals = features_df[features_df['label'] == 0][feature].dropna()\n",
    "            pd_vals = features_df[features_df['label'] == 1][feature].dropna()\n",
    "            \n",
    "            ax.hist(hc_vals, alpha=0.5, label='healthy', bins=15)\n",
    "            ax.hist(pd_vals, alpha=0.5, label='parkinson', bins=15)\n",
    "            ax.set_xlabel(feature)\n",
    "            ax.set_ylabel('count')\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{feature} distribution\")\n",
    "        \n",
    "        for j in range(len(available_features), 8):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"no discriminative features available in extracted features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. statistical comparison\n",
    "\n",
    "compare clinical features between pd and hc groups using t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists() and len(features_df) > 0:\n",
    "    from scipy import stats\n",
    "    \n",
    "    available_features = [f for f in get_pd_discriminative_features() if f in features_df.columns]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for feature in available_features:\n",
    "        hc_vals = features_df[features_df['label'] == 0][feature].dropna()\n",
    "        pd_vals = features_df[features_df['label'] == 1][feature].dropna()\n",
    "        \n",
    "        if len(hc_vals) > 2 and len(pd_vals) > 2:\n",
    "            t_stat, p_val = stats.ttest_ind(hc_vals, pd_vals)\n",
    "            \n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hc_mean': hc_vals.mean(),\n",
    "                'hc_std': hc_vals.std(),\n",
    "                'pd_mean': pd_vals.mean(),\n",
    "                'pd_std': pd_vals.std(),\n",
    "                't_statistic': t_stat,\n",
    "                'p_value': p_val,\n",
    "                'significant': p_val < 0.05\n",
    "            })\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(\"\\nclinical feature comparison (hc vs pd):\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        sig_count = sum(results_df['significant'])\n",
    "        print(f\"\\nsignificant features (p < 0.05): {sig_count}/{len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. audio preprocessing pipeline\n",
    "\n",
    "demonstrate audio preprocessing with vad and filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if italian_pvs_path.exists():\n",
    "    preprocessor = AudioPreprocessor(\n",
    "        target_sr=16000,\n",
    "        remove_silence=True,\n",
    "        apply_filters=True,\n",
    "        normalize=True,\n",
    "        check_quality=True\n",
    "    )\n",
    "    \n",
    "    sample_path = dataset.samples[0]['path']\n",
    "    waveform, sr = load_audio(sample_path, target_sr=16000, normalize=False)\n",
    "    \n",
    "    processed, metrics = preprocessor(waveform, sr)\n",
    "    \n",
    "    print(\"preprocessing metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    ax1.plot(waveform.squeeze().numpy()[:10000])\n",
    "    ax1.set_title('original waveform')\n",
    "    ax1.set_xlabel('sample')\n",
    "    ax1.set_ylabel('amplitude')\n",
    "    \n",
    "    ax2.plot(processed.squeeze().numpy()[:10000])\n",
    "    ax2.set_title('preprocessed waveform (filtered + normalized)')\n",
    "    ax2.set_xlabel('sample')\n",
    "    ax2.set_ylabel('amplitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. phase 1 summary\n",
    "\n",
    "phase 1 deliverables:\n",
    "- comprehensive dataset loading infrastructure for 6 pd voice corpora\n",
    "- robust audio preprocessing with vad, filtering, and normalization\n",
    "- clinical feature extraction using parselmouth (jitter, shimmer, hnr, formants)\n",
    "- proper subject-wise data splitting to prevent leakage\n",
    "- comprehensive unit tests for all components\n",
    "\n",
    "ready to proceed to phase 2: wav2vec2 fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"phase 1 implementation complete\")\n",
    "print(\"\\nnext steps:\")\n",
    "print(\"  - phase 2: fine-tune wav2vec2 on pd classification\")\n",
    "print(\"  - phase 3: extract activations from all transformer layers\")\n",
    "print(\"  - phase 4: probing experiments to identify clinical feature encoding\")\n",
    "print(\"  - phase 5: activation patching to establish causal circuits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
