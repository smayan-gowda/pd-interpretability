{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phase 3: wav2vec2 fine-tuning for pd classification\n",
    "\n",
    "fine-tune wav2vec2-base-960h on parkinson's disease voice detection using\n",
    "leave-one-subject-out (loso) cross-validation for rigorous evaluation.\n",
    "\n",
    "**methodology:**\n",
    "- loso cv: same protocol as clinical baseline (88.3% accuracy) for fair comparison\n",
    "- freeze cnn feature extractor + first 4 transformer layers (small dataset)\n",
    "- gradient checkpointing for memory efficiency\n",
    "- early stopping to prevent overfitting\n",
    "\n",
    "**expected results:**\n",
    "- target accuracy: 80-90% (competitive with clinical baseline)\n",
    "- comparison with 17-feature clinical model establishes deep learning value\n",
    "\n",
    "**hardware support:**\n",
    "- nvidia gpu (cuda) - recommended\n",
    "- apple silicon (mps) - supported but slower\n",
    "- cpu - not recommended (10-20+ hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# set project root\n",
    "project_root = Path('/Volumes/usb drive/pd-interpretability')\n",
    "assert project_root.exists(), f\"project root not found: {project_root}\"\n",
    "\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"project root: {project_root}\")\n",
    "print(f\"working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def detect_device():\n",
    "    \"\"\"detect best available compute device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"detected: nvidia gpu ({device_name})\")\n",
    "        print(f\"vram: {memory_gb:.1f} gb\")\n",
    "        return device, True\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"detected: apple silicon (mps)\")\n",
    "        return device, True\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"warning: no gpu detected, using cpu (very slow)\")\n",
    "        return device, False\n",
    "\n",
    "device, has_accelerator = detect_device()\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from src.data.datasets import ItalianPVSDataset\n",
    "from src.models.classifier import DataCollatorWithPadding\n",
    "\n",
    "print(\"imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment configuration\n",
    "config = {\n",
    "    # model\n",
    "    'model_name': 'facebook/wav2vec2-base-960h',\n",
    "    'num_labels': 2,\n",
    "    'freeze_feature_extractor': True,\n",
    "    'freeze_encoder_layers': 4,  # freeze first 4 transformer layers\n",
    "    'dropout': 0.15,\n",
    "    'gradient_checkpointing': True,\n",
    "    \n",
    "    # audio\n",
    "    'max_duration': 10.0,\n",
    "    'target_sr': 16000,\n",
    "    \n",
    "    # training\n",
    "    'num_epochs': 15,\n",
    "    'learning_rate': 5e-5,  # lower for small dataset stability\n",
    "    'warmup_ratio': 0.1,\n",
    "    'weight_decay': 0.01,\n",
    "    'early_stopping_patience': 3,\n",
    "    \n",
    "    # loso cv\n",
    "    'max_folds': None,  # none = all subjects, set to 5-10 for testing\n",
    "    \n",
    "    # random seed\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# device-specific settings\n",
    "if device == 'cuda':\n",
    "    config['batch_size'] = 8\n",
    "    config['gradient_accumulation_steps'] = 4\n",
    "    config['fp16'] = True\n",
    "elif device == 'mps':\n",
    "    config['batch_size'] = 4\n",
    "    config['gradient_accumulation_steps'] = 8\n",
    "    config['fp16'] = False  # mps fp16 unstable\n",
    "else:\n",
    "    config['batch_size'] = 2\n",
    "    config['gradient_accumulation_steps'] = 16\n",
    "    config['fp16'] = False\n",
    "\n",
    "effective_batch = config['batch_size'] * config['gradient_accumulation_steps']\n",
    "print(f\"batch size: {config['batch_size']} (effective: {effective_batch})\")\n",
    "print(f\"learning rate: {config['learning_rate']}\")\n",
    "print(f\"epochs: {config['num_epochs']}\")\n",
    "print(f\"frozen layers: cnn + first {config['freeze_encoder_layers']} transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_root = project_root / 'data' / 'raw'\n",
    "\n",
    "dataset = ItalianPVSDataset(\n",
    "    root_dir=str(data_root / 'italian_pvs'),\n",
    "    task=None,  # all tasks\n",
    "    target_sr=config['target_sr'],\n",
    "    max_duration=config['max_duration']\n",
    ")\n",
    "\n",
    "print(f\"samples: {len(dataset)}\")\n",
    "\n",
    "# extract labels and subject ids for loso cv\n",
    "labels = np.array([s['label'] for s in dataset.samples])\n",
    "subject_ids = np.array([s['subject_id'] for s in dataset.samples])\n",
    "\n",
    "# unique subjects\n",
    "unique_subjects = np.unique(subject_ids)\n",
    "n_subjects = len(unique_subjects)\n",
    "\n",
    "# class distribution\n",
    "n_pd = np.sum(labels)\n",
    "n_hc = len(labels) - n_pd\n",
    "print(f\"class distribution: {n_hc} hc, {n_pd} pd\")\n",
    "print(f\"subjects: {n_subjects}\")\n",
    "print(f\"loso cv folds: {n_subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "experiment_name = f\"wav2vec2_loso_{timestamp}\"\n",
    "output_dir = project_root / 'results' / 'checkpoints' / experiment_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save config\n",
    "config_path = output_dir / 'config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"experiment: {experiment_name}\")\n",
    "print(f\"output: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config: dict, device: str):\n",
    "    \"\"\"create fresh wav2vec2 model with specified freezing strategy.\"\"\"\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels'],\n",
    "        classifier_proj_size=256,\n",
    "        hidden_dropout=config['dropout'],\n",
    "        attention_dropout=config['dropout'],\n",
    "        final_dropout=config['dropout']\n",
    "    )\n",
    "    \n",
    "    # enable gradient checkpointing\n",
    "    if config['gradient_checkpointing']:\n",
    "        model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # freeze cnn feature extractor\n",
    "    if config['freeze_feature_extractor']:\n",
    "        model.freeze_feature_encoder()\n",
    "    \n",
    "    # freeze first n transformer layers\n",
    "    if config['freeze_encoder_layers'] > 0:\n",
    "        for i, layer in enumerate(model.wav2vec2.encoder.layers):\n",
    "            if i < config['freeze_encoder_layers']:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"count trainable and frozen parameters.\"\"\"\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable, total - trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, scaler, device, accumulation_steps):\n",
    "    \"\"\"train for one epoch with gradient accumulation.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss / accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "            loss.backward()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        n_batches += 1\n",
    "        \n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            if scaler is not None:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    return total_loss / n_batches if n_batches > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"evaluate model on dataset.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "        total_loss += outputs.loss.item()\n",
    "        \n",
    "        probs = torch.softmax(outputs.logits, dim=-1)\n",
    "        preds = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    n_batches = len(loader)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / n_batches if n_batches > 0 else 0,\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'predictions': np.array(all_preds),\n",
    "        'labels': np.array(all_labels),\n",
    "        'probabilities': np.array(all_probs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. loso cross-validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(\n",
    "    dataset,\n",
    "    train_indices: np.ndarray,\n",
    "    test_indices: np.ndarray,\n",
    "    config: dict,\n",
    "    device: str,\n",
    "    fold_idx: int,\n",
    "    output_dir: Path\n",
    ") -> Dict:\n",
    "    \"\"\"train model on single loso fold.\"\"\"\n",
    "    \n",
    "    # create data subsets\n",
    "    train_subset = Subset(dataset, train_indices.tolist())\n",
    "    test_subset = Subset(dataset, test_indices.tolist())\n",
    "    \n",
    "    # feature extractor and collator\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config['model_name'])\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        feature_extractor=feature_extractor,\n",
    "        max_length=int(config['max_duration'] * config['target_sr'])\n",
    "    )\n",
    "    \n",
    "    # dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "        num_workers=0,\n",
    "        pin_memory=(device == 'cuda')\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_subset,\n",
    "        batch_size=config['batch_size'] * 2,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "        num_workers=0,\n",
    "        pin_memory=(device == 'cuda')\n",
    "    )\n",
    "    \n",
    "    # create fresh model\n",
    "    model = create_model(config, device)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # scheduler\n",
    "    steps_per_epoch = max(1, len(train_loader) // config['gradient_accumulation_steps'])\n",
    "    total_steps = steps_per_epoch * config['num_epochs']\n",
    "    warmup_steps = int(total_steps * config['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # gradient scaler for fp16\n",
    "    scaler = torch.cuda.amp.GradScaler() if config['fp16'] and device == 'cuda' else None\n",
    "    \n",
    "    # training loop with early stopping\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, optimizer, scheduler, scaler,\n",
    "            device, config['gradient_accumulation_steps']\n",
    "        )\n",
    "        \n",
    "        test_metrics = evaluate(model, test_loader, device)\n",
    "        \n",
    "        # early stopping check\n",
    "        if test_metrics['loss'] < best_loss:\n",
    "            best_loss = test_metrics['loss']\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['early_stopping_patience']:\n",
    "                break\n",
    "    \n",
    "    # final evaluation\n",
    "    final_metrics = evaluate(model, test_loader, device)\n",
    "    \n",
    "    # cleanup\n",
    "    del model, optimizer, scheduler\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_idx,\n",
    "        'train_samples': len(train_indices),\n",
    "        'test_samples': len(test_indices),\n",
    "        'accuracy': final_metrics['accuracy'],\n",
    "        'predictions': final_metrics['predictions'],\n",
    "        'labels': final_metrics['labels'],\n",
    "        'probabilities': final_metrics['probabilities']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run loso cross-validation\n",
    "logo = LeaveOneGroupOut()\n",
    "n_folds = logo.get_n_splits(groups=subject_ids)\n",
    "\n",
    "if config['max_folds']:\n",
    "    n_folds = min(n_folds, config['max_folds'])\n",
    "\n",
    "print(f\"running loso cv: {n_folds} folds\")\n",
    "print(f\"device: {device}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fold_results = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "all_subject_ids = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(\n",
    "    logo.split(np.arange(len(dataset)), labels, subject_ids)\n",
    "):\n",
    "    if config['max_folds'] and fold_idx >= config['max_folds']:\n",
    "        break\n",
    "    \n",
    "    test_subject = subject_ids[test_idx[0]]\n",
    "    test_label = labels[test_idx[0]]\n",
    "    label_str = \"pd\" if test_label == 1 else \"hc\"\n",
    "    \n",
    "    print(f\"\\nfold {fold_idx + 1}/{n_folds}: {test_subject} ({label_str})\")\n",
    "    print(f\"  train: {len(train_idx)}, test: {len(test_idx)}\")\n",
    "    \n",
    "    result = train_fold(\n",
    "        dataset=dataset,\n",
    "        train_indices=train_idx,\n",
    "        test_indices=test_idx,\n",
    "        config=config,\n",
    "        device=device,\n",
    "        fold_idx=fold_idx,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    fold_results.append(result)\n",
    "    all_predictions.extend(result['predictions'])\n",
    "    all_labels.extend(result['labels'])\n",
    "    all_probabilities.extend(result['probabilities'])\n",
    "    all_subject_ids.extend([test_subject] * len(result['predictions']))\n",
    "    \n",
    "    print(f\"  accuracy: {result['accuracy']:.1%}\")\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"loso cv complete in {elapsed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "# overall metrics\n",
    "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "overall_precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "overall_recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "overall_f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "\n",
    "try:\n",
    "    overall_auc = roc_auc_score(all_labels, all_probabilities)\n",
    "except:\n",
    "    overall_auc = 0.5\n",
    "\n",
    "# per-fold accuracy\n",
    "fold_accuracies = [r['accuracy'] for r in fold_results]\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOSO CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\noverall metrics (aggregated across all folds):\")\n",
    "print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "print(f\"  precision: {overall_precision:.3f}\")\n",
    "print(f\"  recall: {overall_recall:.3f}\")\n",
    "print(f\"  f1 score: {overall_f1:.3f}\")\n",
    "print(f\"  auc-roc: {overall_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nper-fold statistics:\")\n",
    "print(f\"  mean accuracy: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "print(f\"  min: {min(fold_accuracies):.1%}, max: {max(fold_accuracies):.1%}\")\n",
    "\n",
    "print(f\"\\nconfusion matrix:\")\n",
    "print(f\"           predicted\")\n",
    "print(f\"            hc    pd\")\n",
    "print(f\"actual hc  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "print(f\"       pd  {cm[1,0]:4d}  {cm[1,1]:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per-subject accuracy\n",
    "subject_results = {}\n",
    "for subj, pred, label in zip(all_subject_ids, all_predictions, all_labels):\n",
    "    if subj not in subject_results:\n",
    "        subject_results[subj] = {'correct': 0, 'total': 0, 'label': label}\n",
    "    subject_results[subj]['total'] += 1\n",
    "    if pred == label:\n",
    "        subject_results[subj]['correct'] += 1\n",
    "\n",
    "subject_accuracies = []\n",
    "subject_data = []\n",
    "\n",
    "for subj, data in subject_results.items():\n",
    "    acc = data['correct'] / data['total']\n",
    "    subject_accuracies.append(acc)\n",
    "    diagnosis = 'pd' if data['label'] == 1 else 'hc'\n",
    "    subject_data.append({\n",
    "        'subject_id': subj,\n",
    "        'diagnosis': diagnosis,\n",
    "        'accuracy': acc,\n",
    "        'correct': data['correct'],\n",
    "        'total': data['total']\n",
    "    })\n",
    "\n",
    "subject_df = pd.DataFrame(subject_data)\n",
    "subject_df = subject_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "print(f\"\\nper-subject accuracy:\")\n",
    "print(f\"  mean: {np.mean(subject_accuracies):.1%}\")\n",
    "print(f\"  median: {np.median(subject_accuracies):.1%}\")\n",
    "print(f\"  subjects with 100% accuracy: {sum(1 for a in subject_accuracies if a == 1.0)}/{len(subject_accuracies)}\")\n",
    "print(f\"  subjects with <50% accuracy: {sum(1 for a in subject_accuracies if a < 0.5)}/{len(subject_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. comparison with clinical baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clinical baseline results for comparison\n",
    "baseline_path = project_root / 'results' / 'clinical_baseline_results.json'\n",
    "\n",
    "if baseline_path.exists():\n",
    "    with open(baseline_path) as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    clinical_acc = baseline_results['svm_results']['mean_accuracy']\n",
    "    clinical_std = baseline_results['svm_results']['std_accuracy']\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMPARISON WITH CLINICAL BASELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nclinical baseline (svm, 17 features):\")\n",
    "    print(f\"  accuracy: {clinical_acc:.1%} ± {clinical_std:.1%}\")\n",
    "    \n",
    "    print(f\"\\nwav2vec2 (loso cv):\")\n",
    "    print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "    print(f\"  per-fold mean: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "    \n",
    "    diff = overall_accuracy - clinical_acc\n",
    "    print(f\"\\ndifference: {diff:+.1%}\")\n",
    "    \n",
    "    if diff > 0:\n",
    "        print(\"  wav2vec2 outperforms clinical baseline\")\n",
    "    elif diff < -0.05:\n",
    "        print(\"  clinical baseline outperforms wav2vec2\")\n",
    "    else:\n",
    "        print(\"  comparable performance\")\n",
    "else:\n",
    "    print(\"clinical baseline results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save comprehensive results\n",
    "results = {\n",
    "    'experiment': experiment_name,\n",
    "    'config': config,\n",
    "    'device': device,\n",
    "    'n_folds': len(fold_results),\n",
    "    'n_subjects': n_subjects,\n",
    "    'n_samples': len(dataset),\n",
    "    \n",
    "    'overall_metrics': {\n",
    "        'accuracy': float(overall_accuracy),\n",
    "        'precision': float(overall_precision),\n",
    "        'recall': float(overall_recall),\n",
    "        'f1': float(overall_f1),\n",
    "        'auc': float(overall_auc)\n",
    "    },\n",
    "    \n",
    "    'per_fold_stats': {\n",
    "        'mean_accuracy': float(mean_accuracy),\n",
    "        'std_accuracy': float(std_accuracy),\n",
    "        'min_accuracy': float(min(fold_accuracies)),\n",
    "        'max_accuracy': float(max(fold_accuracies))\n",
    "    },\n",
    "    \n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    \n",
    "    'fold_results': [\n",
    "        {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in r.items()}\n",
    "        for r in fold_results\n",
    "    ],\n",
    "    \n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'elapsed_time': str(elapsed)\n",
    "}\n",
    "\n",
    "# save to json\n",
    "results_path = output_dir / 'wav2vec2_loso_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# save subject-level results\n",
    "subject_path = output_dir / 'wav2vec2_subject_accuracy.csv'\n",
    "subject_df.to_csv(subject_path, index=False)\n",
    "\n",
    "# also save to main results folder for easy access\n",
    "main_results_path = project_root / 'results' / 'wav2vec2_loso_results.json'\n",
    "with open(main_results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"results saved to:\")\n",
    "print(f\"  {results_path}\")\n",
    "print(f\"  {subject_path}\")\n",
    "print(f\"  {main_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# publication style\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 11,\n",
    "    'axes.labelsize': 10,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# fold accuracy distribution\n",
    "ax1 = axes[0]\n",
    "ax1.bar(range(len(fold_accuracies)), fold_accuracies, color='steelblue', alpha=0.7)\n",
    "ax1.axhline(y=mean_accuracy, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'mean: {mean_accuracy:.1%}')\n",
    "ax1.set_xlabel('fold')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('per-fold accuracy')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# confusion matrix\n",
    "ax2 = axes[1]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['hc', 'pd'], yticklabels=['hc', 'pd'])\n",
    "ax2.set_xlabel('predicted')\n",
    "ax2.set_ylabel('actual')\n",
    "ax2.set_title(f'confusion matrix (acc: {overall_accuracy:.1%})')\n",
    "\n",
    "# subject accuracy histogram\n",
    "ax3 = axes[2]\n",
    "ax3.hist(subject_accuracies, bins=10, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "ax3.axvline(x=np.mean(subject_accuracies), color='red', linestyle='--', \n",
    "            label=f'mean: {np.mean(subject_accuracies):.1%}')\n",
    "ax3.set_xlabel('accuracy')\n",
    "ax3.set_ylabel('count')\n",
    "ax3.set_title('per-subject accuracy distribution')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'wav2vec2_results_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"figure saved to {output_dir / 'wav2vec2_results_summary.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison bar chart\n",
    "if baseline_path.exists():\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    models = ['clinical baseline\\n(svm, 17 features)', 'wav2vec2\\n(fine-tuned)']\n",
    "    accuracies = [clinical_acc, overall_accuracy]\n",
    "    stds = [clinical_std, std_accuracy]\n",
    "    colors = ['#2ecc71', '#3498db']\n",
    "    \n",
    "    bars = ax.bar(models, accuracies, yerr=stds, capsize=8, color=colors, alpha=0.8)\n",
    "    \n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{acc:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_title('model comparison: loso cross-validation')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5, label='chance')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"comparison figure saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. summary and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 3 COMPLETE: WAV2VEC2 FINE-TUNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nmodel: {config['model_name']}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"loso cv folds: {len(fold_results)}\")\n",
    "print(f\"training time: {elapsed}\")\n",
    "\n",
    "print(f\"\\nresults:\")\n",
    "print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "print(f\"  precision: {overall_precision:.3f}\")\n",
    "print(f\"  recall: {overall_recall:.3f}\")\n",
    "print(f\"  f1 score: {overall_f1:.3f}\")\n",
    "print(f\"  auc-roc: {overall_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nper-fold accuracy: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\nnext steps:\")\n",
    "print(f\"  1. phase 4: activation extraction (notebook 04)\")\n",
    "print(f\"  2. phase 5: probing experiments (notebook 05)\")\n",
    "print(f\"  3. phase 6: activation patching (notebook 06)\")\n",
    "\n",
    "print(f\"\\noutputs saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. train final model for activation extraction\n",
    "\n",
    "train a single model on all data for use in probing and patching experiments.\n",
    "this model will be used to extract activations in phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on 80% of data (hold out 20% for testing)\n",
    "train_subset, _, test_subset = dataset.get_subject_split(\n",
    "    test_size=0.2,\n",
    "    val_size=0.0,\n",
    "    random_state=config['random_seed']\n",
    ")\n",
    "\n",
    "print(f\"training final model...\")\n",
    "print(f\"  train samples: {len(train_subset)}\")\n",
    "print(f\"  test samples: {len(test_subset)}\")\n",
    "\n",
    "# create model\n",
    "final_model = create_model(config, device)\n",
    "\n",
    "# feature extractor and data collator\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config['model_name'])\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    feature_extractor=feature_extractor,\n",
    "    max_length=int(config['max_duration'] * config['target_sr'])\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device == 'cuda')\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=config['batch_size'] * 2,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device == 'cuda')\n",
    ")\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = AdamW(\n",
    "    [p for p in final_model.parameters() if p.requires_grad],\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "steps_per_epoch = max(1, len(train_loader) // config['gradient_accumulation_steps'])\n",
    "total_steps = steps_per_epoch * config['num_epochs']\n",
    "warmup_steps = int(total_steps * config['warmup_ratio'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() if config['fp16'] and device == 'cuda' else None\n",
    "\n",
    "# training loop\n",
    "best_acc = 0\n",
    "for epoch in range(config['num_epochs']):\n",
    "    train_loss = train_epoch(\n",
    "        final_model, train_loader, optimizer, scheduler, scaler,\n",
    "        device, config['gradient_accumulation_steps']\n",
    "    )\n",
    "    \n",
    "    test_metrics = evaluate(final_model, test_loader, device)\n",
    "    \n",
    "    if test_metrics['accuracy'] > best_acc:\n",
    "        best_acc = test_metrics['accuracy']\n",
    "        # save checkpoint\n",
    "        checkpoint_path = output_dir / 'final_model'\n",
    "        final_model.save_pretrained(checkpoint_path)\n",
    "        feature_extractor.save_pretrained(checkpoint_path)\n",
    "    \n",
    "    print(f\"epoch {epoch+1}/{config['num_epochs']}: loss={train_loss:.4f}, acc={test_metrics['accuracy']:.1%}\")\n",
    "\n",
    "print(f\"\\nfinal model saved to: {checkpoint_path}\")\n",
    "print(f\"test accuracy: {best_acc:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
