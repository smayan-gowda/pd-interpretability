{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phase 3: wav2vec2 fine-tuning for pd classification\n",
    "\n",
    "fine-tune wav2vec2-base-960h on parkinson's disease voice detection using\n",
    "leave-one-subject-out (loso) cross-validation for rigorous evaluation.\n",
    "\n",
    "**methodology:**\n",
    "- loso cv: same protocol as clinical baseline (88.3% accuracy) for fair comparison\n",
    "- freeze cnn feature extractor + first 4 transformer layers (small dataset)\n",
    "- gradient checkpointing for memory efficiency\n",
    "- early stopping to prevent overfitting\n",
    "\n",
    "**expected results:**\n",
    "- target accuracy: 80-90% (competitive with clinical baseline)\n",
    "- comparison with 17-feature clinical model establishes deep learning value\n",
    "\n",
    "**hardware support:**\n",
    "- nvidia gpu (cuda) - recommended\n",
    "- apple silicon (mps) - supported but slower\n",
    "- cpu - not recommended (10-20+ hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Volumes/usb drive/pd-interpretability\n",
      "working directory: /Volumes/usb drive/pd-interpretability\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# set project root\n",
    "project_root = Path('/Volumes/usb drive/pd-interpretability')\n",
    "assert project_root.exists(), f\"project root not found: {project_root}\"\n",
    "\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"project root: {project_root}\")\n",
    "print(f\"working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected: apple silicon (mps)\n",
      "pytorch version: 2.2.0\n",
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def detect_device():\n",
    "    \"\"\"detect best available compute device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"detected: nvidia gpu ({device_name})\")\n",
    "        print(f\"vram: {memory_gb:.1f} gb\")\n",
    "        return device, True\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"detected: apple silicon (mps)\")\n",
    "        return device, True\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"warning: no gpu detected, using cpu (very slow)\")\n",
    "        return device, False\n",
    "\n",
    "device, has_accelerator = detect_device()\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from src.data.datasets import ItalianPVSDataset\n",
    "from src.models.classifier import DataCollatorWithPadding\n",
    "\n",
    "print(\"imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 4 (effective: 32)\n",
      "learning rate: 5e-05\n",
      "epochs: 15\n",
      "frozen layers: cnn + first 4 transformer\n",
      "max folds: 3 (set to None for full LOSO CV)\n"
     ]
    }
   ],
   "source": [
    "# experiment configuration\n",
    "config = {\n",
    "    # model\n",
    "    'model_name': 'facebook/wav2vec2-base-960h',\n",
    "    'num_labels': 2,\n",
    "    'freeze_feature_extractor': True,\n",
    "    'freeze_encoder_layers': 4,  # freeze first 4 transformer layers\n",
    "    'dropout': 0.15,\n",
    "    'gradient_checkpointing': True,\n",
    "    \n",
    "    # audio\n",
    "    'max_duration': 10.0,\n",
    "    'target_sr': 16000,\n",
    "    \n",
    "    # training\n",
    "    'num_epochs': 15,\n",
    "    'learning_rate': 5e-5,  # lower for small dataset stability\n",
    "    'warmup_ratio': 0.1,\n",
    "    'weight_decay': 0.01,\n",
    "    'early_stopping_patience': 3,\n",
    "    \n",
    "    # loso cv\n",
    "    'max_folds': 3,  # set to 3 for quick test, None for full CV\n",
    "    \n",
    "    # random seed\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# device-specific settings\n",
    "if device == 'cuda':\n",
    "    config['batch_size'] = 8\n",
    "    config['gradient_accumulation_steps'] = 4\n",
    "    config['fp16'] = True\n",
    "elif device == 'mps':\n",
    "    config['batch_size'] = 4\n",
    "    config['gradient_accumulation_steps'] = 8\n",
    "    config['fp16'] = False  # mps fp16 unstable\n",
    "else:\n",
    "    config['batch_size'] = 2\n",
    "    config['gradient_accumulation_steps'] = 16\n",
    "    config['fp16'] = False\n",
    "\n",
    "effective_batch = config['batch_size'] * config['gradient_accumulation_steps']\n",
    "print(f\"batch size: {config['batch_size']} (effective: {effective_batch})\")\n",
    "print(f\"learning rate: {config['learning_rate']}\")\n",
    "print(f\"epochs: {config['num_epochs']}\")\n",
    "print(f\"frozen layers: cnn + first {config['freeze_encoder_layers']} transformer\")\n",
    "print(f\"max folds: {config['max_folds']} (set to None for full LOSO CV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 831\n",
      "class distribution: 394 hc, 437 pd\n",
      "subjects: 61\n",
      "loso cv folds: 61\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_root = project_root / 'data' / 'raw'\n",
    "\n",
    "dataset = ItalianPVSDataset(\n",
    "    root_dir=str(data_root / 'italian_pvs'),\n",
    "    task=None,  # all tasks\n",
    "    target_sr=config['target_sr'],\n",
    "    max_duration=config['max_duration']\n",
    ")\n",
    "\n",
    "print(f\"samples: {len(dataset)}\")\n",
    "\n",
    "# extract labels and subject ids for loso cv\n",
    "labels = np.array([s['label'] for s in dataset.samples])\n",
    "subject_ids = np.array([s['subject_id'] for s in dataset.samples])\n",
    "\n",
    "# unique subjects\n",
    "unique_subjects = np.unique(subject_ids)\n",
    "n_subjects = len(unique_subjects)\n",
    "\n",
    "# class distribution\n",
    "n_pd = np.sum(labels)\n",
    "n_hc = len(labels) - n_pd\n",
    "print(f\"class distribution: {n_hc} hc, {n_pd} pd\")\n",
    "print(f\"subjects: {n_subjects}\")\n",
    "print(f\"loso cv folds: {n_subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment: wav2vec2_loso_20260102_125342\n",
      "output: /Volumes/usb drive/pd-interpretability/results/checkpoints/wav2vec2_loso_20260102_125342\n"
     ]
    }
   ],
   "source": [
    "# create output directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "experiment_name = f\"wav2vec2_loso_{timestamp}\"\n",
    "output_dir = project_root / 'results' / 'checkpoints' / experiment_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save config\n",
    "config_path = output_dir / 'config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"experiment: {experiment_name}\")\n",
    "print(f\"output: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config: dict, device: str):\n",
    "    \"\"\"create fresh wav2vec2 model with specified freezing strategy.\"\"\"\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=config['num_labels'],\n",
    "        classifier_proj_size=256,\n",
    "        hidden_dropout=config['dropout'],\n",
    "        attention_dropout=config['dropout'],\n",
    "        final_dropout=config['dropout']\n",
    "    )\n",
    "    \n",
    "    # enable gradient checkpointing\n",
    "    if config['gradient_checkpointing']:\n",
    "        model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # freeze cnn feature extractor\n",
    "    if config['freeze_feature_extractor']:\n",
    "        model.freeze_feature_encoder()\n",
    "    \n",
    "    # freeze first n transformer layers\n",
    "    if config['freeze_encoder_layers'] > 0:\n",
    "        for i, layer in enumerate(model.wav2vec2.encoder.layers):\n",
    "            if i < config['freeze_encoder_layers']:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"count trainable and frozen parameters.\"\"\"\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable, total - trainable\n",
    "\n",
    "\n",
    "def create_collate_fn(feature_extractor, max_length: int):\n",
    "    \"\"\"create collate function for wav2vec2 training.\"\"\"\n",
    "    def collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        # extract raw audio waveforms - dataset returns 1d tensors\n",
    "        input_values = [item['input_values'] for item in batch]\n",
    "        labels = torch.tensor([item['label'] for item in batch], dtype=torch.long)\n",
    "        \n",
    "        # pad sequences to max length in batch\n",
    "        max_len = min(max(len(x) for x in input_values), max_length)\n",
    "        \n",
    "        padded_input = torch.zeros(len(input_values), max_len)\n",
    "        attention_mask = torch.zeros(len(input_values), max_len)\n",
    "        \n",
    "        for i, wav in enumerate(input_values):\n",
    "            length = min(len(wav), max_len)\n",
    "            padded_input[i, :length] = wav[:length]\n",
    "            attention_mask[i, :length] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'input_values': padded_input,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scheduler, scaler, device, accumulation_steps):\n",
    "    \"\"\"train for one epoch with gradient accumulation and mps memory management.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss / accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "            loss.backward()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        n_batches += 1\n",
    "        \n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            if scaler is not None:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # mps memory management - synchronize periodically to prevent fragmentation\n",
    "        if device == 'mps' and (step + 1) % 50 == 0:\n",
    "            torch.mps.synchronize()\n",
    "        \n",
    "        # cleanup batch tensors\n",
    "        del input_values, attention_mask, labels, outputs, loss\n",
    "    \n",
    "    # end of epoch cleanup for mps\n",
    "    if device == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "        torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    return total_loss / n_batches if n_batches > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"evaluate model on dataset with memory management.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "        total_loss += outputs.loss.item()\n",
    "        \n",
    "        probs = torch.softmax(outputs.logits, dim=-1)\n",
    "        preds = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "        \n",
    "        # cleanup batch tensors\n",
    "        del input_values, attention_mask, labels, outputs, probs, preds\n",
    "    \n",
    "    # mps memory cleanup\n",
    "    if device == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "        torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    n_batches = len(loader)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / n_batches if n_batches > 0 else 0,\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'predictions': np.array(all_preds),\n",
    "        'labels': np.array(all_labels),\n",
    "        'probabilities': np.array(all_probs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. loso cross-validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(\n",
    "    dataset,\n",
    "    train_indices: np.ndarray,\n",
    "    test_indices: np.ndarray,\n",
    "    config: dict,\n",
    "    device: str,\n",
    "    fold_idx: int,\n",
    "    output_dir: Path\n",
    ") -> Dict:\n",
    "    \"\"\"train model on single loso fold with robust memory management.\"\"\"\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] creating data subsets...\")\n",
    "    # create data subsets\n",
    "    train_subset = Subset(dataset, train_indices.tolist())\n",
    "    test_subset = Subset(dataset, test_indices.tolist())\n",
    "    \n",
    "    # feature extractor and custom collate function\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config['model_name'])\n",
    "    max_length = int(config['max_duration'] * config['target_sr'])\n",
    "    collate_fn = create_collate_fn(feature_extractor, max_length)\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] creating dataloaders (batch_size={config['batch_size']})...\")\n",
    "    # dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0,\n",
    "        pin_memory=(device == 'cuda')\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_subset,\n",
    "        batch_size=config['batch_size'] * 2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0,\n",
    "        pin_memory=(device == 'cuda')\n",
    "    )\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] initializing model ({config['model_name']})...\")\n",
    "    # create fresh model\n",
    "    model = create_model(config, device)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # scheduler\n",
    "    steps_per_epoch = max(1, len(train_loader) // config['gradient_accumulation_steps'])\n",
    "    total_steps = steps_per_epoch * config['num_epochs']\n",
    "    warmup_steps = int(total_steps * config['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # gradient scaler for fp16\n",
    "    scaler = torch.cuda.amp.GradScaler() if config['fp16'] and device == 'cuda' else None\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] starting training ({config['num_epochs']} epochs, {len(train_loader)} batches/epoch)...\")\n",
    "    # training loop with early stopping\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_metrics = None\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        epoch_start = datetime.now()\n",
    "        \n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, optimizer, scheduler, scaler,\n",
    "            device, config['gradient_accumulation_steps']\n",
    "        )\n",
    "        \n",
    "        test_metrics = evaluate(model, test_loader, device)\n",
    "        \n",
    "        epoch_time = (datetime.now() - epoch_start).total_seconds()\n",
    "        \n",
    "        print(f\"      epoch {epoch + 1}/{config['num_epochs']}: \"\n",
    "              f\"train_loss={train_loss:.4f}, test_loss={test_metrics['loss']:.4f}, \"\n",
    "              f\"test_acc={test_metrics['accuracy']:.1%}, time={epoch_time:.1f}s\")\n",
    "        \n",
    "        # save best metrics\n",
    "        if test_metrics['loss'] < best_loss:\n",
    "            best_loss = test_metrics['loss']\n",
    "            patience_counter = 0\n",
    "            best_metrics = test_metrics.copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['early_stopping_patience']:\n",
    "                print(f\"      early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "        \n",
    "        # mps: aggressive cleanup after each epoch to prevent memory fragmentation\n",
    "        if device == 'mps':\n",
    "            torch.mps.synchronize()\n",
    "            torch.mps.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] final evaluation...\")\n",
    "    # final evaluation\n",
    "    final_metrics = evaluate(model, test_loader, device) if best_metrics is None else best_metrics\n",
    "    \n",
    "    print(f\"    [fold {fold_idx + 1}] cleaning up...\")\n",
    "    # aggressive cleanup\n",
    "    del model, optimizer, scheduler, train_loader, test_loader\n",
    "    del train_subset, test_subset, feature_extractor, collate_fn\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    elif device == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_idx,\n",
    "        'train_samples': len(train_indices),\n",
    "        'test_samples': len(test_indices),\n",
    "        'accuracy': final_metrics['accuracy'],\n",
    "        'predictions': final_metrics['predictions'],\n",
    "        'labels': final_metrics['labels'],\n",
    "        'probabilities': final_metrics['probabilities']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING LOSO CROSS-VALIDATION\n",
      "================================================================================\n",
      "total folds to run: 3\n",
      "device: mps\n",
      "model: facebook/wav2vec2-base-960h\n",
      "batch size: 4\n",
      "learning rate: 5e-05\n",
      "max epochs per fold: 15\n",
      "early stopping patience: 3\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FOLD 1/3\n",
      "================================================================================\n",
      "  test subject: HC_elderly_AGNESE_P (hc)\n",
      "  train samples: 815, test samples: 16\n",
      "  starting training...\n",
      "    [fold 1] creating data subsets...\n",
      "    [fold 1] creating dataloaders (batch_size=4)...\n",
      "    [fold 1] initializing model (facebook/wav2vec2-base-960h)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['projector.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.bias', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [fold 1] starting training (15 epochs, 204 batches/epoch)...\n",
      "      epoch 1/15: train_loss=0.6868, test_loss=0.7901, test_acc=0.0%, time=518.2s\n",
      "      epoch 2/15: train_loss=0.5461, test_loss=0.4938, test_acc=81.2%, time=613.3s\n",
      "      epoch 3/15: train_loss=0.3458, test_loss=0.7751, test_acc=68.8%, time=570.6s\n",
      "      epoch 4/15: train_loss=0.2105, test_loss=1.4799, test_acc=62.5%, time=546.6s\n",
      "      epoch 5/15: train_loss=0.2099, test_loss=0.0795, test_acc=93.8%, time=505.2s\n",
      "      epoch 6/15: train_loss=0.1794, test_loss=0.0501, test_acc=100.0%, time=585.6s\n",
      "      epoch 7/15: train_loss=0.1374, test_loss=0.1589, test_acc=93.8%, time=526.1s\n",
      "      epoch 8/15: train_loss=0.0930, test_loss=0.1946, test_acc=93.8%, time=483.0s\n",
      "      epoch 9/15: train_loss=0.0757, test_loss=0.0134, test_acc=100.0%, time=496.0s\n",
      "      epoch 10/15: train_loss=0.0550, test_loss=0.3135, test_acc=87.5%, time=492.6s\n",
      "      epoch 11/15: train_loss=0.0628, test_loss=0.0714, test_acc=93.8%, time=480.2s\n",
      "      epoch 12/15: train_loss=0.0610, test_loss=0.0085, test_acc=100.0%, time=483.8s\n",
      "      epoch 13/15: train_loss=0.0341, test_loss=0.0085, test_acc=100.0%, time=534.6s\n",
      "      epoch 14/15: train_loss=0.0537, test_loss=0.0095, test_acc=100.0%, time=476.2s\n",
      "      epoch 15/15: train_loss=0.0301, test_loss=0.0093, test_acc=100.0%, time=481.9s\n",
      "    [fold 1] final evaluation...\n",
      "    [fold 1] cleaning up...\n",
      "\n",
      "  FOLD 1 COMPLETE:\n",
      "    fold accuracy: 100.0%\n",
      "    fold time: 7800.0s (130.0m)\n",
      "    running overall accuracy: 100.0%\n",
      "    time elapsed: 2:10:00.003502\n",
      "    estimated time remaining: 260.0m (4.3h)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FOLD 2/3\n",
      "================================================================================\n",
      "  test subject: HC_elderly_ANGELA_C (hc)\n",
      "  train samples: 815, test samples: 16\n",
      "  starting training...\n",
      "    [fold 2] creating data subsets...\n",
      "    [fold 2] creating dataloaders (batch_size=4)...\n",
      "    [fold 2] initializing model (facebook/wav2vec2-base-960h)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['projector.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.bias', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [fold 2] starting training (15 epochs, 204 batches/epoch)...\n",
      "      epoch 1/15: train_loss=0.6891, test_loss=0.7750, test_acc=0.0%, time=460.8s\n",
      "      epoch 2/15: train_loss=0.6318, test_loss=0.6903, test_acc=87.5%, time=489.1s\n",
      "      epoch 3/15: train_loss=0.4510, test_loss=0.8636, test_acc=68.8%, time=471.2s\n",
      "      epoch 4/15: train_loss=0.3735, test_loss=0.3949, test_acc=87.5%, time=477.8s\n",
      "      epoch 5/15: train_loss=0.2417, test_loss=0.4809, test_acc=87.5%, time=474.5s\n",
      "      epoch 6/15: train_loss=0.1805, test_loss=0.4367, test_acc=87.5%, time=482.2s\n",
      "      epoch 7/15: train_loss=0.1502, test_loss=0.4388, test_acc=87.5%, time=632.2s\n",
      "      early stopping triggered at epoch 7\n",
      "    [fold 2] final evaluation...\n",
      "    [fold 2] cleaning up...\n",
      "\n",
      "  FOLD 2 COMPLETE:\n",
      "    fold accuracy: 87.5%\n",
      "    fold time: 3495.4s (58.3m)\n",
      "    running overall accuracy: 93.8%\n",
      "    time elapsed: 3:08:15.408072\n",
      "    estimated time remaining: 94.1m (1.6h)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FOLD 3/3\n",
      "================================================================================\n",
      "  test subject: HC_elderly_ANGELA_G (hc)\n",
      "  train samples: 815, test samples: 16\n",
      "  starting training...\n",
      "    [fold 3] creating data subsets...\n",
      "    [fold 3] creating dataloaders (batch_size=4)...\n",
      "    [fold 3] initializing model (facebook/wav2vec2-base-960h)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['projector.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.bias', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [fold 3] starting training (15 epochs, 204 batches/epoch)...\n",
      "      epoch 1/15: train_loss=0.6902, test_loss=0.7941, test_acc=0.0%, time=580.4s\n",
      "      epoch 2/15: train_loss=0.6244, test_loss=0.3095, test_acc=100.0%, time=595.0s\n",
      "      epoch 3/15: train_loss=0.4144, test_loss=0.1840, test_acc=93.8%, time=664.6s\n",
      "      epoch 4/15: train_loss=0.3523, test_loss=0.0727, test_acc=100.0%, time=577.2s\n",
      "      epoch 5/15: train_loss=0.2704, test_loss=0.0541, test_acc=100.0%, time=644.4s\n",
      "      epoch 6/15: train_loss=0.1939, test_loss=0.0914, test_acc=93.8%, time=14641.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  train samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  starting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m result = \u001b[43mtrain_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m fold_time = (datetime.now() - fold_start).total_seconds()\n\u001b[32m     58\u001b[39m elapsed_total = datetime.now() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mtrain_fold\u001b[39m\u001b[34m(dataset, train_indices, test_indices, config, device, fold_idx, output_dir)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m     73\u001b[39m     epoch_start = datetime.now()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgradient_accumulation_steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     test_metrics = evaluate(model, test_loader, device)\n\u001b[32m     82\u001b[39m     epoch_time = (datetime.now() - epoch_start).total_seconds()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, scheduler, scaler, device, accumulation_steps)\u001b[39m\n\u001b[32m     19\u001b[39m     outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n\u001b[32m     20\u001b[39m     loss = outputs.loss / accumulation_steps\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m total_loss += loss.item() * accumulation_steps\n\u001b[32m     24\u001b[39m n_batches += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/usb drive/pd-interpretability/venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/usb drive/pd-interpretability/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# run loso cross-validation\n",
    "logo = LeaveOneGroupOut()\n",
    "n_folds = logo.get_n_splits(groups=subject_ids)\n",
    "\n",
    "if config['max_folds']:\n",
    "    n_folds = min(n_folds, config['max_folds'])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"STARTING LOSO CROSS-VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"total folds to run: {n_folds}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"model: {config['model_name']}\")\n",
    "print(f\"batch size: {config['batch_size']}\")\n",
    "print(f\"learning rate: {config['learning_rate']}\")\n",
    "print(f\"max epochs per fold: {config['num_epochs']}\")\n",
    "print(f\"early stopping patience: {config['early_stopping_patience']}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fold_results = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "all_subject_ids = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(\n",
    "    logo.split(np.arange(len(dataset)), labels, subject_ids)\n",
    "):\n",
    "    if config['max_folds'] and fold_idx >= config['max_folds']:\n",
    "        break\n",
    "    \n",
    "    fold_start = datetime.now()\n",
    "    \n",
    "    test_subject = subject_ids[test_idx[0]]\n",
    "    test_label = labels[test_idx[0]]\n",
    "    label_str = \"pd\" if test_label == 1 else \"hc\"\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{n_folds}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"  test subject: {test_subject} ({label_str})\")\n",
    "    print(f\"  train samples: {len(train_idx)}, test samples: {len(test_idx)}\")\n",
    "    print(f\"  starting training...\")\n",
    "    \n",
    "    result = train_fold(\n",
    "        dataset=dataset,\n",
    "        train_indices=train_idx,\n",
    "        test_indices=test_idx,\n",
    "        config=config,\n",
    "        device=device,\n",
    "        fold_idx=fold_idx,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    fold_time = (datetime.now() - fold_start).total_seconds()\n",
    "    elapsed_total = datetime.now() - start_time\n",
    "    avg_time_per_fold = elapsed_total.total_seconds() / (fold_idx + 1)\n",
    "    remaining_folds = n_folds - (fold_idx + 1)\n",
    "    eta = remaining_folds * avg_time_per_fold\n",
    "    \n",
    "    fold_results.append(result)\n",
    "    all_predictions.extend(result['predictions'])\n",
    "    all_labels.extend(result['labels'])\n",
    "    all_probabilities.extend(result['probabilities'])\n",
    "    all_subject_ids.extend([test_subject] * len(result['predictions']))\n",
    "    \n",
    "    # calculate running accuracy\n",
    "    running_acc = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"\\n  FOLD {fold_idx + 1} COMPLETE:\")\n",
    "    print(f\"    fold accuracy: {result['accuracy']:.1%}\")\n",
    "    print(f\"    fold time: {fold_time:.1f}s ({fold_time/60:.1f}m)\")\n",
    "    print(f\"    running overall accuracy: {running_acc:.1%}\")\n",
    "    print(f\"    time elapsed: {elapsed_total}\")\n",
    "    print(f\"    estimated time remaining: {eta/60:.1f}m ({eta/3600:.1f}h)\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    # mps: add brief sleep between folds to allow system memory stabilization\n",
    "    if device == 'mps' and remaining_folds > 0:\n",
    "        print(f\"  [mps] stabilizing memory before next fold...\")\n",
    "        torch.mps.synchronize()\n",
    "        torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "        time.sleep(2)\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"LOSO CV COMPLETE\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"total time: {elapsed} ({elapsed.total_seconds()/60:.1f}m)\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "# overall metrics\n",
    "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "overall_precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "overall_recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "overall_f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "\n",
    "try:\n",
    "    overall_auc = roc_auc_score(all_labels, all_probabilities)\n",
    "except:\n",
    "    overall_auc = 0.5\n",
    "\n",
    "# per-fold accuracy\n",
    "fold_accuracies = [r['accuracy'] for r in fold_results]\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOSO CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\noverall metrics (aggregated across all folds):\")\n",
    "print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "print(f\"  precision: {overall_precision:.3f}\")\n",
    "print(f\"  recall: {overall_recall:.3f}\")\n",
    "print(f\"  f1 score: {overall_f1:.3f}\")\n",
    "print(f\"  auc-roc: {overall_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nper-fold statistics:\")\n",
    "print(f\"  mean accuracy: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "print(f\"  min: {min(fold_accuracies):.1%}, max: {max(fold_accuracies):.1%}\")\n",
    "\n",
    "print(f\"\\nconfusion matrix:\")\n",
    "print(f\"           predicted\")\n",
    "print(f\"            hc    pd\")\n",
    "print(f\"actual hc  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "print(f\"       pd  {cm[1,0]:4d}  {cm[1,1]:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per-subject accuracy analysis\n",
    "subject_results = {}\n",
    "for subj, pred, label in zip(all_subject_ids, all_predictions, all_labels):\n",
    "    if subj not in subject_results:\n",
    "        subject_results[subj] = {'correct': 0, 'total': 0, 'label': label}\n",
    "    subject_results[subj]['total'] += 1\n",
    "    if pred == label:\n",
    "        subject_results[subj]['correct'] += 1\n",
    "\n",
    "subject_accuracies = []\n",
    "subject_data = []\n",
    "\n",
    "for subj, data in subject_results.items():\n",
    "    acc = data['correct'] / data['total']\n",
    "    subject_accuracies.append(acc)\n",
    "    diagnosis = 'pd' if data['label'] == 1 else 'hc'\n",
    "    subject_data.append({\n",
    "        'subject_id': subj,\n",
    "        'diagnosis': diagnosis,\n",
    "        'accuracy': acc,\n",
    "        'correct': data['correct'],\n",
    "        'total': data['total']\n",
    "    })\n",
    "\n",
    "subject_df = pd.DataFrame(subject_data)\n",
    "subject_df = subject_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "print(f\"\\nper-subject accuracy:\")\n",
    "print(f\"  mean: {np.mean(subject_accuracies):.1%}\")\n",
    "print(f\"  median: {np.median(subject_accuracies):.1%}\")\n",
    "print(f\"  subjects with 100% accuracy: {sum(1 for a in subject_accuracies if a == 1.0)}/{len(subject_accuracies)}\")\n",
    "print(f\"  subjects with <50% accuracy: {sum(1 for a in subject_accuracies if a < 0.5)}/{len(subject_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. comparison with clinical baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clinical baseline results for comparison\n",
    "baseline_path = project_root / 'results' / 'clinical_baseline_results.json'\n",
    "\n",
    "if baseline_path.exists():\n",
    "    with open(baseline_path) as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    clinical_acc = baseline_results['svm_results']['mean_accuracy']\n",
    "    clinical_std = baseline_results['svm_results']['std_accuracy']\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMPARISON WITH CLINICAL BASELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nclinical baseline (svm, 17 features):\")\n",
    "    print(f\"  accuracy: {clinical_acc:.1%} ± {clinical_std:.1%}\")\n",
    "    \n",
    "    print(f\"\\nwav2vec2 (loso cv):\")\n",
    "    print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "    print(f\"  per-fold mean: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "    \n",
    "    diff = overall_accuracy - clinical_acc\n",
    "    print(f\"\\ndifference: {diff:+.1%}\")\n",
    "    \n",
    "    if diff > 0:\n",
    "        print(\"  wav2vec2 outperforms clinical baseline\")\n",
    "    elif diff < -0.05:\n",
    "        print(\"  clinical baseline outperforms wav2vec2\")\n",
    "    else:\n",
    "        print(\"  comparable performance\")\n",
    "else:\n",
    "    print(\"clinical baseline results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save comprehensive results\n",
    "results = {\n",
    "    'experiment': experiment_name,\n",
    "    'config': config,\n",
    "    'device': device,\n",
    "    'n_folds': len(fold_results),\n",
    "    'n_subjects': n_subjects,\n",
    "    'n_samples': len(dataset),\n",
    "    \n",
    "    'overall_metrics': {\n",
    "        'accuracy': float(overall_accuracy),\n",
    "        'precision': float(overall_precision),\n",
    "        'recall': float(overall_recall),\n",
    "        'f1': float(overall_f1),\n",
    "        'auc': float(overall_auc)\n",
    "    },\n",
    "    \n",
    "    'per_fold_stats': {\n",
    "        'mean_accuracy': float(mean_accuracy),\n",
    "        'std_accuracy': float(std_accuracy),\n",
    "        'min_accuracy': float(min(fold_accuracies)),\n",
    "        'max_accuracy': float(max(fold_accuracies))\n",
    "    },\n",
    "    \n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    \n",
    "    'fold_results': [\n",
    "        {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in r.items()}\n",
    "        for r in fold_results\n",
    "    ],\n",
    "    \n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'elapsed_time': str(elapsed)\n",
    "}\n",
    "\n",
    "# save to json\n",
    "results_path = output_dir / 'wav2vec2_loso_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# save subject-level results\n",
    "subject_path = output_dir / 'wav2vec2_subject_accuracy.csv'\n",
    "subject_df.to_csv(subject_path, index=False)\n",
    "\n",
    "# also save to main results folder for easy access\n",
    "main_results_path = project_root / 'results' / 'wav2vec2_loso_results.json'\n",
    "with open(main_results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"results saved to:\")\n",
    "print(f\"  {results_path}\")\n",
    "print(f\"  {subject_path}\")\n",
    "print(f\"  {main_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# add latex to path\n",
    "os.environ['PATH'] = '/Library/TeX/texbin:' + os.environ.get('PATH', '')\n",
    "\n",
    "# publication-quality style with latex and times new roman\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{amsmath}\\usepackage{amssymb}',\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 11,\n",
    "    'axes.labelsize': 10,\n",
    "    'axes.linewidth': 0.8,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'xtick.direction': 'out',\n",
    "    'ytick.direction': 'out',\n",
    "    'legend.fontsize': 9,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# fold accuracy distribution\n",
    "ax1 = axes[0]\n",
    "ax1.bar(range(1, len(fold_accuracies) + 1), fold_accuracies, color='#3498db', alpha=0.8, edgecolor='white')\n",
    "ax1.axhline(y=mean_accuracy, color='#e74c3c', linestyle='--', linewidth=2, \n",
    "            label=rf'Mean: {mean_accuracy:.1%}')\n",
    "ax1.set_xlabel(r'Fold')\n",
    "ax1.set_ylabel(r'Accuracy')\n",
    "ax1.set_title(r'Per-Fold Accuracy (LOSO CV)')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# confusion matrix\n",
    "ax2 = axes[1]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=[r'HC', r'PD'], yticklabels=[r'HC', r'PD'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "ax2.set_xlabel(r'Predicted')\n",
    "ax2.set_ylabel(r'Actual')\n",
    "ax2.set_title(rf'Confusion Matrix (Accuracy: {overall_accuracy:.1%})')\n",
    "\n",
    "# subject accuracy histogram\n",
    "ax3 = axes[2]\n",
    "ax3.hist(subject_accuracies, bins=10, color='#3498db', alpha=0.8, edgecolor='white')\n",
    "ax3.axvline(x=np.mean(subject_accuracies), color='#e74c3c', linestyle='--', linewidth=2,\n",
    "            label=rf'Mean: {np.mean(subject_accuracies):.1%}')\n",
    "ax3.set_xlabel(r'Accuracy')\n",
    "ax3.set_ylabel(r'Count')\n",
    "ax3.set_title(r'Per-Subject Accuracy Distribution')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# save to both experiment dir and main figures dir\n",
    "plt.savefig(output_dir / 'wav2vec2_results_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(output_dir / 'wav2vec2_results_summary.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# also save to main figures folder\n",
    "main_fig_dir = project_root / 'results' / 'figures'\n",
    "plt.savefig(main_fig_dir / 'fig_p3_01_wav2vec2_loso_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(main_fig_dir / 'fig_p3_01_wav2vec2_loso_summary.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"figures saved to {output_dir} and {main_fig_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison bar chart with clinical baseline\n",
    "if baseline_path.exists():\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    models = [r'Clinical Baseline' + '\\n' + r'(SVM, 17 features)', \n",
    "              r'Wav2Vec2' + '\\n' + r'(Fine-tuned)']\n",
    "    accuracies = [clinical_acc, overall_accuracy]\n",
    "    stds = [clinical_std, std_accuracy]\n",
    "    colors = ['#2ecc71', '#3498db']\n",
    "    \n",
    "    bars = ax.bar(models, accuracies, yerr=stds, capsize=8, color=colors, alpha=0.8,\n",
    "                  edgecolor='white', linewidth=1.5)\n",
    "    \n",
    "    for bar, acc, std in zip(bars, accuracies, stds):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.02,\n",
    "                rf'{acc:.1%}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel(r'Accuracy')\n",
    "    ax.set_title(r'Model Comparison: LOSO Cross-Validation')\n",
    "    ax.set_ylim(0, 1.15)\n",
    "    ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5, label=r'Chance Level')\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save figures\n",
    "    plt.savefig(output_dir / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(output_dir / 'model_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    main_fig_dir = project_root / 'results' / 'figures'\n",
    "    plt.savefig(main_fig_dir / 'fig_p3_02_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(main_fig_dir / 'fig_p3_02_model_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"comparison figures saved\")\n",
    "else:\n",
    "    print(\"clinical baseline results not found - skipping comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. summary and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 3 COMPLETE: WAV2VEC2 FINE-TUNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nmodel: {config['model_name']}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"loso cv folds: {len(fold_results)}\")\n",
    "print(f\"training time: {elapsed}\")\n",
    "\n",
    "print(f\"\\nresults:\")\n",
    "print(f\"  accuracy: {overall_accuracy:.1%}\")\n",
    "print(f\"  precision: {overall_precision:.3f}\")\n",
    "print(f\"  recall: {overall_recall:.3f}\")\n",
    "print(f\"  f1 score: {overall_f1:.3f}\")\n",
    "print(f\"  auc-roc: {overall_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nper-fold accuracy: {mean_accuracy:.1%} ± {std_accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\nnext steps:\")\n",
    "print(f\"  1. phase 4: activation extraction (notebook 04)\")\n",
    "print(f\"  2. phase 5: probing experiments (notebook 05)\")\n",
    "print(f\"  3. phase 6: activation patching (notebook 06)\")\n",
    "\n",
    "print(f\"\\noutputs saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. train final model for activation extraction\n",
    "\n",
    "train a single model on all data for use in probing and patching experiments.\n",
    "this model will be used to extract activations in phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on 80% of data (hold out 20% for testing)\n",
    "train_subset, _, test_subset = dataset.get_subject_split(\n",
    "    test_size=0.2,\n",
    "    val_size=0.0,\n",
    "    random_state=config['random_seed']\n",
    ")\n",
    "\n",
    "print(f\"training final model...\")\n",
    "print(f\"  train samples: {len(train_subset)}\")\n",
    "print(f\"  test samples: {len(test_subset)}\")\n",
    "\n",
    "# create model\n",
    "final_model = create_model(config, device)\n",
    "\n",
    "# feature extractor and data collator\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config['model_name'])\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    feature_extractor=feature_extractor,\n",
    "    max_length=int(config['max_duration'] * config['target_sr'])\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device == 'cuda')\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=config['batch_size'] * 2,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device == 'cuda')\n",
    ")\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = AdamW(\n",
    "    [p for p in final_model.parameters() if p.requires_grad],\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "steps_per_epoch = max(1, len(train_loader) // config['gradient_accumulation_steps'])\n",
    "total_steps = steps_per_epoch * config['num_epochs']\n",
    "warmup_steps = int(total_steps * config['warmup_ratio'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() if config['fp16'] and device == 'cuda' else None\n",
    "\n",
    "# training loop\n",
    "best_acc = 0\n",
    "for epoch in range(config['num_epochs']):\n",
    "    train_loss = train_epoch(\n",
    "        final_model, train_loader, optimizer, scheduler, scaler,\n",
    "        device, config['gradient_accumulation_steps']\n",
    "    )\n",
    "    \n",
    "    test_metrics = evaluate(final_model, test_loader, device)\n",
    "    \n",
    "    if test_metrics['accuracy'] > best_acc:\n",
    "        best_acc = test_metrics['accuracy']\n",
    "        # save checkpoint\n",
    "        checkpoint_path = output_dir / 'final_model'\n",
    "        final_model.save_pretrained(checkpoint_path)\n",
    "        feature_extractor.save_pretrained(checkpoint_path)\n",
    "    \n",
    "    print(f\"epoch {epoch+1}/{config['num_epochs']}: loss={train_loss:.4f}, acc={test_metrics['accuracy']:.1%}\")\n",
    "\n",
    "print(f\"\\nfinal model saved to: {checkpoint_path}\")\n",
    "print(f\"test accuracy: {best_acc:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
